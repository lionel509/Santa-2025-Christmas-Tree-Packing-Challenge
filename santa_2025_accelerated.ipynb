{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6323ed",
   "metadata": {},
   "source": [
    "# Santa 2025 - Accelerated Solution\n",
    "This notebook uses **Numba** JIT compilation to accelerate the geometric calculations and Simulated Annealing process.\n",
    "It is designed to run significantly faster than the pure Python baseline, allowing for millions of iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Numba Acceleration Status\n",
    "import numba\n",
    "print(f\"Numba Version: {numba.__version__}\")\n",
    "\n",
    "# Check if CUDA is available (for information purposes, though we use CPU JIT)\n",
    "try:\n",
    "    from numba import cuda\n",
    "    if cuda.is_available():\n",
    "        print(\"CUDA GPU is available!\")\n",
    "        cuda.detect()\n",
    "    else:\n",
    "        print(\"CUDA GPU is NOT available. Using CPU acceleration.\")\n",
    "except ImportError:\n",
    "    print(\"Numba CUDA support not installed. Using CPU acceleration.\")\n",
    "\n",
    "# Print Threading Layer Info\n",
    "try:\n",
    "    import numba.threading_layer\n",
    "    print(\"Threading Layer:\", numba.threading_layer.threading_layer())\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Setup\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.strtree import STRtree\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2025\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# High precision for coordinates\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(\"Libraries imported and seed set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Advanced Features\n",
    "CONFIG = {\n",
    "    # Hybrid Search Approach\n",
    "    'hybrid_search': {\n",
    "        'enabled': True,\n",
    "        'switch_n': 25,  # Use forward building for N <= 25\n",
    "    },\n",
    "    \n",
    "    # Dynamic Beam Width\n",
    "    'dynamic_beam_width': {\n",
    "        'enabled': True,\n",
    "        'base_width': 12,\n",
    "        'critical_n_multiplier': 2.0, # Wider for critical sizes\n",
    "    },\n",
    "    \n",
    "    # Beam Search Diversity\n",
    "    'beam_diversity': {\n",
    "        'enabled': True,\n",
    "        'max_children_per_parent': 3, # Prevent one parent from dominating the next generation\n",
    "    },\n",
    "    \n",
    "    # Multi-Start Optimization\n",
    "    'multi_start': {\n",
    "        'enabled': True,\n",
    "        'n_starts': 3,\n",
    "    },\n",
    "    \n",
    "    # Optimization Function Enhancements\n",
    "    'optimization': {\n",
    "        'adaptive_temperature': True,\n",
    "        'smart_move_selection': True, # Bias moves toward boundary\n",
    "        'batch_moves': False, # Try moving multiple trees (complex)\n",
    "        'boundary_bias_strength': 0.7, # 70% chance to pick boundary tree\n",
    "        'reheating': True, # Restart SA if stuck\n",
    "        'compaction_pass': True, # Pure translation pass to close gaps\n",
    "    },\n",
    "    \n",
    "    # Post-Processing & Polishing\n",
    "    'post_processing': {\n",
    "        'polishing': True, # Run a low-temp refinement phase at the end\n",
    "        'polishing_iterations': 2000,\n",
    "    },\n",
    "    \n",
    "    # Geometric & Heuristic Improvements\n",
    "    'heuristics': {\n",
    "        'corner_filling': True,\n",
    "        'symmetry_breaking': True,\n",
    "        'boundary_alignment': True,\n",
    "    },\n",
    "    \n",
    "    # Validation\n",
    "    'validation': {\n",
    "        'strict_boundary': True,\n",
    "        'collision_check': True,\n",
    "    },\n",
    "    \n",
    "    # Debugging\n",
    "    'debug': {\n",
    "        'verbose_logging': True,\n",
    "        'plot_convergence': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\", CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load Data\n",
    "\n",
    "# Load the sample submission to understand the required output format\n",
    "try:\n",
    "    sample_sub = pd.read_csv('test.csv')\n",
    "    print(\"Sample Submission Shape:\", sample_sub.shape)\n",
    "    print(sample_sub.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Sample submission not found, proceeding without it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02218ccb",
   "metadata": {},
   "source": [
    "## 4. Baseline Strategy\n",
    "\n",
    "We define the `GreedyPacker` class here. It encapsulates the logic for placing a single tree into an existing configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPacker:\n",
    "    def __init__(self, n_trials=100, step_size=0.2, fine_step=0.02):\n",
    "        self.n_trials = n_trials\n",
    "        self.step_size = step_size\n",
    "        self.fine_step = fine_step\n",
    "\n",
    "    def _generate_weighted_angle(self):\n",
    "        \"\"\"\n",
    "        Generates a random angle with a distribution weighted by abs(sin(2*angle)).\n",
    "        This helps place more trees in corners (diagonals).\n",
    "        \"\"\"\n",
    "        if not CONFIG['heuristics']['corner_filling']:\n",
    "            return random.uniform(0, 2 * math.pi)\n",
    "            \n",
    "        while True:\n",
    "            angle = random.uniform(0, 2 * math.pi)\n",
    "            if random.uniform(0, 1) < abs(math.sin(2 * angle)):\n",
    "                return angle\n",
    "\n",
    "    def place_next_tree(self, existing_trees, tree_class):\n",
    "        \"\"\"Finds the best position for the next tree given existing trees.\"\"\"\n",
    "        if not existing_trees:\n",
    "            return tree_class(0, 0, 0)\n",
    "\n",
    "        existing_polys = [t.polygon for t in existing_trees]\n",
    "        tree_index = STRtree(existing_polys)\n",
    "        \n",
    "        # Calculate current bounds and center\n",
    "        minx, miny, maxx, maxy = unary_union(existing_polys).bounds\n",
    "        center_x = (minx + maxx) / 2\n",
    "        center_y = (miny + maxy) / 2\n",
    "        \n",
    "        best_tree = None\n",
    "        min_metric = float('inf')\n",
    "\n",
    "        for _ in range(self.n_trials):\n",
    "            # Random angle for the tree itself\n",
    "            angle = random.uniform(0, 360)\n",
    "            \n",
    "            # Weighted approach angle (bias towards diagonals)\n",
    "            approach_angle = self._generate_weighted_angle()\n",
    "            vx, vy = math.cos(approach_angle), math.sin(approach_angle)\n",
    "            \n",
    "            # Start far away\n",
    "            radius = max(maxx - minx, maxy - miny) + 10.0\n",
    "            candidate = tree_class(0, 0, angle)\n",
    "            \n",
    "            # Move in\n",
    "            current_r = radius\n",
    "            collision = False\n",
    "            \n",
    "            # Coarse search\n",
    "            while current_r > 0:\n",
    "                px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                candidate.update_position(px, py, angle)\n",
    "                \n",
    "                query_indices = tree_index.query(candidate.polygon)\n",
    "                if any(candidate.polygon.intersects(existing_polys[i]) for i in query_indices):\n",
    "                    collision = True\n",
    "                    break\n",
    "                current_r -= self.step_size\n",
    "            \n",
    "            # Fine tune\n",
    "            if collision:\n",
    "                current_r += self.step_size\n",
    "                while True:\n",
    "                    current_r -= self.fine_step\n",
    "                    px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                    candidate.update_position(px, py, angle)\n",
    "                    \n",
    "                    query_indices = tree_index.query(candidate.polygon)\n",
    "                    if any(candidate.polygon.intersects(existing_polys[i]) for i in query_indices):\n",
    "                        # Collision found, step back once and stop\n",
    "                        current_r += self.fine_step\n",
    "                        px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                        candidate.update_position(px, py, angle)\n",
    "                        break\n",
    "            else:\n",
    "                candidate.update_position(center_x, center_y, angle)\n",
    "\n",
    "            # Metric: Minimize the side length of the new bounding box\n",
    "            t_minx, t_miny, t_maxx, t_maxy = candidate.polygon.bounds\n",
    "            new_minx = min(minx, t_minx)\n",
    "            new_miny = min(miny, t_miny)\n",
    "            new_maxx = max(maxx, t_maxx)\n",
    "            new_maxy = max(maxy, t_maxy)\n",
    "            \n",
    "            new_side = max(new_maxx - new_minx, new_maxy - new_miny)\n",
    "            \n",
    "            # Tie-breaker: distance to center\n",
    "            dist_sq = (px - center_x)**2 + (py - center_y)**2\n",
    "            \n",
    "            metric = new_side + (dist_sq * 1e-6)\n",
    "            \n",
    "            if metric < min_metric:\n",
    "                min_metric = metric\n",
    "                best_tree = tree_class(px, py, angle)\n",
    "                \n",
    "        return best_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df33791",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Module\n",
    "\n",
    "Here we define the geometric features of the problem: the `ChristmasTree` class and helper functions for bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChristmasTree:\n",
    "    \"\"\"Represents a single, rotatable Christmas tree.\"\"\"\n",
    "    def __init__(self, center_x=0, center_y=0, angle=0):\n",
    "        self.center_x = float(center_x)\n",
    "        self.center_y = float(center_y)\n",
    "        self.angle = float(angle)\n",
    "        self.polygon = self._create_polygon()\n",
    "\n",
    "    def _create_polygon(self):\n",
    "        # Tree dimensions\n",
    "        coords = [\n",
    "            (0.0, 0.8), (0.125, 0.5), (0.0625, 0.5), (0.2, 0.25), (0.1, 0.25),\n",
    "            (0.35, 0.0), (0.075, 0.0), (0.075, -0.2), (-0.075, -0.2), (-0.075, 0.0),\n",
    "            (-0.35, 0.0), (-0.1, 0.25), (-0.2, 0.25), (-0.0625, 0.5), (-0.125, 0.5)\n",
    "        ]\n",
    "        poly = Polygon(coords)\n",
    "        rotated = affinity.rotate(poly, self.angle, origin=(0, 0))\n",
    "        return affinity.translate(rotated, xoff=self.center_x, yoff=self.center_y)\n",
    "\n",
    "    def update_position(self, x, y, angle):\n",
    "        self.center_x = x\n",
    "        self.center_y = y\n",
    "        self.angle = angle\n",
    "        self.polygon = self._create_polygon()\n",
    "\n",
    "def get_bounds(trees):\n",
    "    if not trees: return 0\n",
    "    minx, miny, maxx, maxy = unary_union([t.polygon for t in trees]).bounds\n",
    "    return max(maxx - minx, maxy - miny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NUMBA ACCELERATED GEOMETRY KERNEL ---\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "# Tree polygon vertices (Same as defined in ChristmasTree class)\n",
    "TREE_X = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075,\n",
    "                   -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125], dtype=np.float64)\n",
    "TREE_Y = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2,\n",
    "                   -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5], dtype=np.float64)\n",
    "NV = 15\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def get_poly(cx, cy, deg):\n",
    "    rad = deg * np.pi / 180.0\n",
    "    c, s = np.cos(rad), np.sin(rad)\n",
    "    px = TREE_X * c - TREE_Y * s + cx\n",
    "    py = TREE_X * s + TREE_Y * c + cy\n",
    "    return px, py\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def get_bbox(px, py):\n",
    "    return px.min(), py.min(), px.max(), py.max()\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def pip(px_pt, py_pt, poly_x, poly_y):\n",
    "    inside = False\n",
    "    j = NV - 1\n",
    "    for i in range(NV):\n",
    "        if ((poly_y[i] > py_pt) != (poly_y[j] > py_pt) and\n",
    "            px_pt < (poly_x[j] - poly_x[i]) * (py_pt - poly_y[i]) / (poly_y[j] - poly_y[i]) + poly_x[i]):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "    return inside\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def seg_intersect(ax, ay, bx, by, cx, cy, dx, dy):\n",
    "    def ccw(p1x, p1y, p2x, p2y, p3x, p3y):\n",
    "        return (p3y - p1y) * (p2x - p1x) > (p2y - p1y) * (p3x - p1x)\n",
    "    return ccw(ax, ay, cx, cy, dx, dy) != ccw(bx, by, cx, cy, dx, dy) and \\\n",
    "           ccw(ax, ay, bx, by, cx, cy) != ccw(ax, ay, bx, by, dx, dy)\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def overlap(px1, py1, bb1, px2, py2, bb2):\n",
    "    # Fast BBox check\n",
    "    if bb1[2] < bb2[0] or bb2[2] < bb1[0] or bb1[3] < bb2[1] or bb2[3] < bb1[1]:\n",
    "        return False\n",
    "    # Point in Polygon check\n",
    "    for i in range(NV):\n",
    "        if pip(px1[i], py1[i], px2, py2): return True\n",
    "        if pip(px2[i], py2[i], px1, py1): return True\n",
    "    # Edge Intersection check\n",
    "    for i in range(NV):\n",
    "        ni = (i + 1) % NV\n",
    "        for j in range(NV):\n",
    "            nj = (j + 1) % NV\n",
    "            if seg_intersect(px1[i], py1[i], px1[ni], py1[ni],\n",
    "                           px2[j], py2[j], px2[nj], py2[nj]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def check_overlap_single(idx, xs, ys, angs, n):\n",
    "    px1, py1 = get_poly(xs[idx], ys[idx], angs[idx])\n",
    "    bb1 = get_bbox(px1, py1)\n",
    "    for j in range(n):\n",
    "        if j != idx:\n",
    "            px2, py2 = get_poly(xs[j], ys[j], angs[j])\n",
    "            bb2 = get_bbox(px2, py2)\n",
    "            if overlap(px1, py1, bb1, px2, py2, bb2):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def check_overlap_pair(i, j, xs, ys, angs, n):\n",
    "    pxi, pyi = get_poly(xs[i], ys[i], angs[i])\n",
    "    pxj, pyj = get_poly(xs[j], ys[j], angs[j])\n",
    "    bbi = get_bbox(pxi, pyi)\n",
    "    bbj = get_bbox(pxj, pyj)\n",
    "    if overlap(pxi, pyi, bbi, pxj, pyj, bbj):\n",
    "        return True\n",
    "    for k in range(n):\n",
    "        if k != i and k != j:\n",
    "            pxk, pyk = get_poly(xs[k], ys[k], angs[k])\n",
    "            bbk = get_bbox(pxk, pyk)\n",
    "            if overlap(pxi, pyi, bbi, pxk, pyk, bbk):\n",
    "                return True\n",
    "            if overlap(pxj, pyj, bbj, pxk, pyk, bbk):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def calc_side(xs, ys, angs, n):\n",
    "    if n == 0: return 0.0\n",
    "    gx0, gy0, gx1, gy1 = 1e9, 1e9, -1e9, -1e9\n",
    "    for i in range(n):\n",
    "        px, py = get_poly(xs[i], ys[i], angs[i])\n",
    "        x0, y0, x1, y1 = get_bbox(px, py)\n",
    "        gx0, gy0 = min(gx0, x0), min(gy0, y0)\n",
    "        gx1, gy1 = max(gx1, x1), max(gy1, y1)\n",
    "    return max(gx1 - gx0, gy1 - gy0)\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def get_global_bbox(xs, ys, angs, n):\n",
    "    gx0, gy0, gx1, gy1 = 1e9, 1e9, -1e9, -1e9\n",
    "    for i in range(n):\n",
    "        px, py = get_poly(xs[i], ys[i], angs[i])\n",
    "        x0, y0, x1, y1 = get_bbox(px, py)\n",
    "        gx0, gy0 = min(gx0, x0), min(gy0, y0)\n",
    "        gx1, gy1 = max(gx1, x1), max(gy1, y1)\n",
    "    return gx0, gy0, gx1, gy1\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def find_corner_trees(xs, ys, angs, n):\n",
    "    gx0, gy0, gx1, gy1 = get_global_bbox(xs, ys, angs, n)\n",
    "    eps = 0.01\n",
    "    # We can't return dynamic arrays easily in njit without some work, \n",
    "    # so we return a fixed size array and a count, or just use a list\n",
    "    # For simplicity, let's return indices in a fixed buffer\n",
    "    corner_indices = np.zeros(n, dtype=np.int32)\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        px, py = get_poly(xs[i], ys[i], angs[i])\n",
    "        x0, y0, x1, y1 = get_bbox(px, py)\n",
    "        if abs(x0 - gx0) < eps or abs(x1 - gx1) < eps or \\\n",
    "           abs(y0 - gy0) < eps or abs(y1 - gy1) < eps:\n",
    "            corner_indices[count] = i\n",
    "            count += 1\n",
    "    return corner_indices, count\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def sa_numba(xs, ys, angs, n, iterations, T0, Tmin, move_scale, rot_scale, seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    bxs, bys, bangs = xs.copy(), ys.copy(), angs.copy()\n",
    "    cxs, cys, cangs = xs.copy(), ys.copy(), angs.copy()\n",
    "\n",
    "    bs = calc_side(bxs, bys, bangs, n)\n",
    "    cs = bs\n",
    "    T = T0\n",
    "    alpha = (Tmin / T0) ** (1.0 / iterations) if iterations > 0 else 0.99\n",
    "    no_imp = 0\n",
    "\n",
    "    for it in range(iterations):\n",
    "        move_type = np.random.randint(0, 8)  # 8 move types\n",
    "        sc = T / T0\n",
    "\n",
    "        if move_type < 4:\n",
    "            # Single tree moves\n",
    "            i = np.random.randint(0, n)\n",
    "            ox, oy, oa = cxs[i], cys[i], cangs[i]\n",
    "\n",
    "            cx = np.mean(cxs[:n])\n",
    "            cy = np.mean(cys[:n])\n",
    "\n",
    "            if move_type == 0: # Random translation\n",
    "                cxs[i] += (np.random.random() - 0.5) * 2 * move_scale * sc\n",
    "                cys[i] += (np.random.random() - 0.5) * 2 * move_scale * sc\n",
    "            elif move_type == 1: # Move towards center\n",
    "                dx, dy = cx - cxs[i], cy - cys[i]\n",
    "                d = np.sqrt(dx*dx + dy*dy)\n",
    "                if d > 1e-6:\n",
    "                    step = np.random.random() * move_scale * sc\n",
    "                    cxs[i] += dx / d * step\n",
    "                    cys[i] += dy / d * step\n",
    "            elif move_type == 2: # Rotation\n",
    "                cangs[i] += (np.random.random() - 0.5) * 2 * rot_scale * sc\n",
    "                cangs[i] = cangs[i] % 360\n",
    "            else: # Mixed\n",
    "                cxs[i] += (np.random.random() - 0.5) * move_scale * sc\n",
    "                cys[i] += (np.random.random() - 0.5) * move_scale * sc\n",
    "                cangs[i] += (np.random.random() - 0.5) * rot_scale * sc\n",
    "                cangs[i] = cangs[i] % 360\n",
    "\n",
    "            if check_overlap_single(i, cxs, cys, cangs, n):\n",
    "                cxs[i], cys[i], cangs[i] = ox, oy, oa\n",
    "                no_imp += 1\n",
    "                T *= alpha\n",
    "                if T < Tmin: T = Tmin\n",
    "                continue\n",
    "\n",
    "        elif move_type == 4 and n > 1:\n",
    "            # Swap\n",
    "            i = np.random.randint(0, n)\n",
    "            j = np.random.randint(0, n)\n",
    "            while j == i: j = np.random.randint(0, n)\n",
    "\n",
    "            oxi, oyi = cxs[i], cys[i]\n",
    "            oxj, oyj = cxs[j], cys[j]\n",
    "\n",
    "            cxs[i], cys[i] = oxj, oyj\n",
    "            cxs[j], cys[j] = oxi, oyi\n",
    "\n",
    "            if check_overlap_pair(i, j, cxs, cys, cangs, n):\n",
    "                cxs[i], cys[i] = oxi, oyi\n",
    "                cxs[j], cys[j] = oxj, oyj\n",
    "                no_imp += 1\n",
    "                T *= alpha\n",
    "                if T < Tmin: T = Tmin\n",
    "                continue\n",
    "\n",
    "        elif move_type == 5:\n",
    "            # Bbox center move\n",
    "            i = np.random.randint(0, n)\n",
    "            ox, oy = cxs[i], cys[i]\n",
    "\n",
    "            gx0, gy0, gx1, gy1 = get_global_bbox(cxs, cys, cangs, n)\n",
    "            bcx, bcy = (gx0 + gx1) / 2, (gy0 + gy1) / 2\n",
    "            dx, dy = bcx - cxs[i], bcy - cys[i]\n",
    "            d = np.sqrt(dx*dx + dy*dy)\n",
    "            if d > 1e-6:\n",
    "                step = np.random.random() * move_scale * sc * 0.5\n",
    "                cxs[i] += dx / d * step\n",
    "                cys[i] += dy / d * step\n",
    "\n",
    "            if check_overlap_single(i, cxs, cys, cangs, n):\n",
    "                cxs[i], cys[i] = ox, oy\n",
    "                no_imp += 1\n",
    "                T *= alpha\n",
    "                if T < Tmin: T = Tmin\n",
    "                continue\n",
    "\n",
    "        elif move_type == 6:\n",
    "            # Corner tree focus - move trees that define bbox inward\n",
    "            corner_indices, count = find_corner_trees(cxs, cys, cangs, n)\n",
    "            if count > 0:\n",
    "                idx = corner_indices[np.random.randint(0, count)]\n",
    "                ox, oy, oa = cxs[idx], cys[idx], cangs[idx]\n",
    "\n",
    "                gx0, gy0, gx1, gy1 = get_global_bbox(cxs, cys, cangs, n)\n",
    "                bcx, bcy = (gx0 + gx1) / 2, (gy0 + gy1) / 2\n",
    "                dx, dy = bcx - cxs[idx], bcy - cys[idx]\n",
    "                d = np.sqrt(dx*dx + dy*dy)\n",
    "                if d > 1e-6:\n",
    "                    step = np.random.random() * move_scale * sc * 0.3\n",
    "                    cxs[idx] += dx / d * step\n",
    "                    cys[idx] += dy / d * step\n",
    "                    cangs[idx] += (np.random.random() - 0.5) * rot_scale * sc * 0.5\n",
    "                    cangs[idx] = cangs[idx] % 360\n",
    "\n",
    "                if check_overlap_single(idx, cxs, cys, cangs, n):\n",
    "                    cxs[idx], cys[idx], cangs[idx] = ox, oy, oa\n",
    "                    no_imp += 1\n",
    "                    T *= alpha\n",
    "                    if T < Tmin: T = Tmin\n",
    "                    continue\n",
    "            else:\n",
    "                no_imp += 1\n",
    "                T *= alpha\n",
    "                if T < Tmin: T = Tmin\n",
    "                continue\n",
    "        else:\n",
    "            # Coordinated move - shift two adjacent trees together\n",
    "            i = np.random.randint(0, n)\n",
    "            j = (i + 1) % n\n",
    "\n",
    "            oxi, oyi = cxs[i], cys[i]\n",
    "            oxj, oyj = cxs[j], cys[j]\n",
    "\n",
    "            dx = (np.random.random() - 0.5) * move_scale * sc * 0.5\n",
    "            dy = (np.random.random() - 0.5) * move_scale * sc * 0.5\n",
    "\n",
    "            cxs[i] += dx\n",
    "            cys[i] += dy\n",
    "            cxs[j] += dx\n",
    "            cys[j] += dy\n",
    "\n",
    "            if check_overlap_pair(i, j, cxs, cys, cangs, n):\n",
    "                cxs[i], cys[i] = oxi, oyi\n",
    "                cxs[j], cys[j] = oxj, oyj\n",
    "                no_imp += 1\n",
    "                T *= alpha\n",
    "                if T < Tmin: T = Tmin\n",
    "                continue\n",
    "\n",
    "        ns = calc_side(cxs, cys, cangs, n)\n",
    "        delta = ns - cs\n",
    "\n",
    "        if delta < 0 or np.random.random() < np.exp(-delta / T):\n",
    "            cs = ns\n",
    "            if ns < bs:\n",
    "                bs = ns\n",
    "                bxs[:] = cxs\n",
    "                bys[:] = cys\n",
    "                bangs[:] = cangs\n",
    "                no_imp = 0\n",
    "            else:\n",
    "                no_imp += 1\n",
    "        else:\n",
    "            cxs[:] = bxs\n",
    "            cys[:] = bys\n",
    "            cangs[:] = bangs\n",
    "            cs = bs\n",
    "            no_imp += 1\n",
    "\n",
    "        # Reheat\n",
    "        if no_imp > 600:\n",
    "            T = min(T * 3.0, T0 * 0.7)\n",
    "            no_imp = 0\n",
    "\n",
    "        T *= alpha\n",
    "        if T < Tmin:\n",
    "            T = Tmin\n",
    "\n",
    "    return bxs, bys, bangs, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CUDA GPU ACCELERATED KERNEL (OPTIONAL) ---\n",
    "# This cell defines CUDA kernels for running Simulated Annealing on NVIDIA GPUs.\n",
    "# It will only be used if a CUDA-compatible GPU is detected.\n",
    "\n",
    "try:\n",
    "    from numba import cuda\n",
    "    from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "    \n",
    "    # Constant memory for tree vertices\n",
    "    # We can't easily use global constants in device functions without some setup, \n",
    "    # so we'll define them inside the device function or pass them.\n",
    "    # For performance, hardcoding in the device function is often fastest for small arrays.\n",
    "    \n",
    "    @cuda.jit(device=True)\n",
    "    def gpu_get_poly(cx, cy, deg, px_out, py_out):\n",
    "        # Hardcoded vertices for the Christmas Tree\n",
    "        # X: [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "        # Y: [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "        \n",
    "        rad = deg * 3.141592653589793 / 180.0\n",
    "        c = math.cos(rad)\n",
    "        s = math.sin(rad)\n",
    "        \n",
    "        # Unrolled loop for 15 vertices\n",
    "        # Vertex 0: (0, 0.8)\n",
    "        px_out[0] = 0 * c - 0.8 * s + cx\n",
    "        py_out[0] = 0 * s + 0.8 * c + cy\n",
    "        # Vertex 1: (0.125, 0.5)\n",
    "        px_out[1] = 0.125 * c - 0.5 * s + cx\n",
    "        py_out[1] = 0.125 * s + 0.5 * c + cy\n",
    "        # Vertex 2: (0.0625, 0.5)\n",
    "        px_out[2] = 0.0625 * c - 0.5 * s + cx\n",
    "        py_out[2] = 0.0625 * s + 0.5 * c + cy\n",
    "        # Vertex 3: (0.2, 0.25)\n",
    "        px_out[3] = 0.2 * c - 0.25 * s + cx\n",
    "        py_out[3] = 0.2 * s + 0.25 * c + cy\n",
    "        # Vertex 4: (0.1, 0.25)\n",
    "        px_out[4] = 0.1 * c - 0.25 * s + cx\n",
    "        py_out[4] = 0.1 * s + 0.25 * c + cy\n",
    "        # Vertex 5: (0.35, 0.0)\n",
    "        px_out[5] = 0.35 * c - 0.0 * s + cx\n",
    "        py_out[5] = 0.35 * s + 0.0 * c + cy\n",
    "        # Vertex 6: (0.075, 0.0)\n",
    "        px_out[6] = 0.075 * c - 0.0 * s + cx\n",
    "        py_out[6] = 0.075 * s + 0.0 * c + cy\n",
    "        # Vertex 7: (0.075, -0.2)\n",
    "        px_out[7] = 0.075 * c - (-0.2) * s + cx\n",
    "        py_out[7] = 0.075 * s + (-0.2) * c + cy\n",
    "        # Vertex 8: (-0.075, -0.2)\n",
    "        px_out[8] = -0.075 * c - (-0.2) * s + cx\n",
    "        py_out[8] = -0.075 * s + (-0.2) * c + cy\n",
    "        # Vertex 9: (-0.075, 0.0)\n",
    "        px_out[9] = -0.075 * c - 0.0 * s + cx\n",
    "        py_out[9] = -0.075 * s + 0.0 * c + cy\n",
    "        # Vertex 10: (-0.35, 0.0)\n",
    "        px_out[10] = -0.35 * c - 0.0 * s + cx\n",
    "        py_out[10] = -0.35 * s + 0.0 * c + cy\n",
    "        # Vertex 11: (-0.1, 0.25)\n",
    "        px_out[11] = -0.1 * c - 0.25 * s + cx\n",
    "        py_out[11] = -0.1 * s + 0.25 * c + cy\n",
    "        # Vertex 12: (-0.2, 0.25)\n",
    "        px_out[12] = -0.2 * c - 0.25 * s + cx\n",
    "        py_out[12] = -0.2 * s + 0.25 * c + cy\n",
    "        # Vertex 13: (-0.0625, 0.5)\n",
    "        px_out[13] = -0.0625 * c - 0.5 * s + cx\n",
    "        py_out[13] = -0.0625 * s + 0.5 * c + cy\n",
    "        # Vertex 14: (-0.125, 0.5)\n",
    "        px_out[14] = -0.125 * c - 0.5 * s + cx\n",
    "        py_out[14] = -0.125 * s + 0.5 * c + cy\n",
    "\n",
    "    @cuda.jit(device=True)\n",
    "    def gpu_get_bbox(px, py):\n",
    "        minx = 1e9\n",
    "        miny = 1e9\n",
    "        maxx = -1e9\n",
    "        maxy = -1e9\n",
    "        for i in range(15):\n",
    "            if px[i] < minx: minx = px[i]\n",
    "            if px[i] > maxx: maxx = px[i]\n",
    "            if py[i] < miny: miny = py[i]\n",
    "            if py[i] > maxy: maxy = py[i]\n",
    "        return minx, miny, maxx, maxy\n",
    "\n",
    "    @cuda.jit(device=True)\n",
    "    def gpu_pip(px_pt, py_pt, poly_x, poly_y):\n",
    "        inside = False\n",
    "        j = 14\n",
    "        for i in range(15):\n",
    "            if ((poly_y[i] > py_pt) != (poly_y[j] > py_pt) and\n",
    "                px_pt < (poly_x[j] - poly_x[i]) * (py_pt - poly_y[i]) / (poly_y[j] - poly_y[i]) + poly_x[i]):\n",
    "                inside = not inside\n",
    "            j = i\n",
    "        return inside\n",
    "\n",
    "    @cuda.jit(device=True)\n",
    "    def gpu_seg_intersect(ax, ay, bx, by, cx, cy, dx, dy):\n",
    "        # CCW function inline\n",
    "        ccw1 = (cy - ay) * (bx - ax) > (by - ay) * (cx - ax)\n",
    "        ccw2 = (dy - ay) * (bx - ax) > (by - ay) * (dx - ax)\n",
    "        ccw3 = (cy - cx) * (dx - cx) > (dy - cx) * (ax - cx)\n",
    "        ccw4 = (cy - cx) * (dx - cx) > (dy - cx) * (bx - cx)\n",
    "        return (ccw1 != ccw2) and (ccw3 != ccw4)\n",
    "\n",
    "    @cuda.jit(device=True)\n",
    "    def gpu_overlap(px1, py1, minx1, miny1, maxx1, maxy1, px2, py2, minx2, miny2, maxx2, maxy2):\n",
    "        # BBox check\n",
    "        if maxx1 < minx2 or maxx2 < minx1 or maxy1 < miny2 or maxy2 < miny1:\n",
    "            return False\n",
    "            \n",
    "        # Point in Polygon\n",
    "        for i in range(15):\n",
    "            if gpu_pip(px1[i], py1[i], px2, py2): return True\n",
    "            if gpu_pip(px2[i], py2[i], px1, py1): return True\n",
    "            \n",
    "        # Edge Intersection\n",
    "        for i in range(15):\n",
    "            ni = (i + 1) % 15\n",
    "            for j in range(15):\n",
    "                nj = (j + 1) % 15\n",
    "                if gpu_seg_intersect(px1[i], py1[i], px1[ni], py1[ni],\n",
    "                                   px2[j], py2[j], px2[nj], py2[nj]):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    @cuda.jit\n",
    "    def sa_gpu_kernel(states_x, states_y, states_ang, rng_states, iterations, T0, Tmin, move_scale, rot_scale, scores_out):\n",
    "        # Each thread handles one configuration (one row in states)\n",
    "        tid = cuda.grid(1)\n",
    "        if tid >= states_x.shape[0]:\n",
    "            return\n",
    "            \n",
    "        n = states_x.shape[1]\n",
    "        \n",
    "        # Local arrays for geometry (stack allocated)\n",
    "        px1 = cuda.local.array(15, dtype=np.float64)\n",
    "        py1 = cuda.local.array(15, dtype=np.float64)\n",
    "        px2 = cuda.local.array(15, dtype=np.float64)\n",
    "        py2 = cuda.local.array(15, dtype=np.float64)\n",
    "        \n",
    "        # Load state into registers/local memory if possible, but for N=200 it's too big for registers.\n",
    "        # We will operate directly on global memory or cache.\n",
    "        # To avoid global memory latency, we could cache, but N varies.\n",
    "        # For simplicity, we operate on global memory `states_x[tid, :]`.\n",
    "        \n",
    "        # Calculate initial score\n",
    "        gx0, gy0, gx1, gy1 = 1e9, 1e9, -1e9, -1e9\n",
    "        for i in range(n):\n",
    "            gpu_get_poly(states_x[tid, i], states_y[tid, i], states_ang[tid, i], px1, py1)\n",
    "            minx, miny, maxx, maxy = gpu_get_bbox(px1, py1)\n",
    "            if minx < gx0: gx0 = minx\n",
    "            if miny < gy0: gy0 = miny\n",
    "            if maxx > gx1: gx1 = maxx\n",
    "            if maxy > gy1: gy1 = maxy\n",
    "            \n",
    "        current_side = max(gx1 - gx0, gy1 - gy0)\n",
    "        best_side = current_side\n",
    "        \n",
    "        # Save best state (we can just overwrite if we improve, or keep a separate best buffer)\n",
    "        # For this kernel, we'll just update the state in place to the current state.\n",
    "        # If we want to track \"best ever\", we need more memory. \n",
    "        # Standard SA tracks \"current\" and \"best\". \n",
    "        # Let's assume states_x is \"current\" and we just return the final \"current\".\n",
    "        \n",
    "        T = T0\n",
    "        alpha = (Tmin / T0) ** (1.0 / iterations)\n",
    "        \n",
    "        for it in range(iterations):\n",
    "            # Pick a move\n",
    "            move_type = int(xoroshiro128p_uniform_float32(rng_states, tid) * 4) # 0-3\n",
    "            \n",
    "            # Select tree\n",
    "            idx = int(xoroshiro128p_uniform_float32(rng_states, tid) * n)\n",
    "            if idx >= n: idx = n - 1\n",
    "            \n",
    "            old_x = states_x[tid, idx]\n",
    "            old_y = states_y[tid, idx]\n",
    "            old_ang = states_ang[tid, idx]\n",
    "            \n",
    "            # Propose move\n",
    "            sc = T / T0\n",
    "            if move_type == 0: # Translate\n",
    "                states_x[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * 2 * move_scale * sc\n",
    "                states_y[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * 2 * move_scale * sc\n",
    "            elif move_type == 1: # Rotate\n",
    "                states_ang[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * 2 * rot_scale * sc\n",
    "            else: # Mixed\n",
    "                states_x[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * move_scale * sc\n",
    "                states_y[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * move_scale * sc\n",
    "                states_ang[tid, idx] += (xoroshiro128p_uniform_float32(rng_states, tid) - 0.5) * rot_scale * sc\n",
    "                \n",
    "            # Check overlap\n",
    "            overlap_found = False\n",
    "            gpu_get_poly(states_x[tid, idx], states_y[tid, idx], states_ang[tid, idx], px1, py1)\n",
    "            minx1, miny1, maxx1, maxy1 = gpu_get_bbox(px1, py1)\n",
    "            \n",
    "            for j in range(n):\n",
    "                if idx == j: continue\n",
    "                gpu_get_poly(states_x[tid, j], states_y[tid, j], states_ang[tid, j], px2, py2)\n",
    "                minx2, miny2, maxx2, maxy2 = gpu_get_bbox(px2, py2)\n",
    "                \n",
    "                if gpu_overlap(px1, py1, minx1, miny1, maxx1, maxy1, px2, py2, minx2, miny2, maxx2, maxy2):\n",
    "                    overlap_found = True\n",
    "                    break\n",
    "            \n",
    "            if overlap_found:\n",
    "                # Revert\n",
    "                states_x[tid, idx] = old_x\n",
    "                states_y[tid, idx] = old_y\n",
    "                states_ang[tid, idx] = old_ang\n",
    "            else:\n",
    "                # Calculate new score\n",
    "                # This is expensive (O(N)), but necessary for exact SA. \n",
    "                # Optimization: Update bounds incrementally? Hard with rotation.\n",
    "                # We do full recalc.\n",
    "                gx0, gy0, gx1, gy1 = 1e9, 1e9, -1e9, -1e9\n",
    "                for i in range(n):\n",
    "                    gpu_get_poly(states_x[tid, i], states_y[tid, i], states_ang[tid, i], px1, py1)\n",
    "                    minx, miny, maxx, maxy = gpu_get_bbox(px1, py1)\n",
    "                    if minx < gx0: gx0 = minx\n",
    "                    if miny < gy0: gy0 = miny\n",
    "                    if maxx > gx1: gx1 = maxx\n",
    "                    if maxy > gy1: gy1 = maxy\n",
    "                \n",
    "                new_side = max(gx1 - gx0, gy1 - gy0)\n",
    "                delta = new_side - current_side\n",
    "                \n",
    "                if delta < 0 or xoroshiro128p_uniform_float32(rng_states, tid) < math.exp(-delta / T):\n",
    "                    current_side = new_side\n",
    "                    if current_side < best_side:\n",
    "                        best_side = current_side\n",
    "                else:\n",
    "                    # Revert\n",
    "                    states_x[tid, idx] = old_x\n",
    "                    states_y[tid, idx] = old_y\n",
    "                    states_ang[tid, idx] = old_ang\n",
    "            \n",
    "            T *= alpha\n",
    "            if T < Tmin: T = Tmin\n",
    "            \n",
    "        scores_out[tid] = best_side\n",
    "\n",
    "    print(\"CUDA Kernels compiled successfully.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"CUDA not available. GPU kernels skipped.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error compiling CUDA kernels: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the existing test.csv to verify the score\n",
    "import pandas as pd\n",
    "try:\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    print(\"Loaded test.csv\")\n",
    "    \n",
    "    # Parse the 's' prefix\n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    test_df['x'] = test_df['x'].apply(parse_s)\n",
    "    test_df['y'] = test_df['y'].apply(parse_s)\n",
    "    test_df['deg'] = test_df['deg'].apply(parse_s)\n",
    "    \n",
    "    # Reconstruct trees and calculate score\n",
    "    total_test_score = 0\n",
    "    for n in range(1, 201):\n",
    "        # Get rows for this N\n",
    "        # The ID format is N_i, e.g., 001_0\n",
    "        # We need to filter by the prefix\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = test_df[test_df['id'].str.startswith(prefix)]\n",
    "        \n",
    "        if len(rows) != n:\n",
    "            print(f\"Warning: N={n} has {len(rows)} rows, expected {n}\")\n",
    "            continue\n",
    "            \n",
    "        trees = []\n",
    "        for _, row in rows.iterrows():\n",
    "            trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            \n",
    "        side = get_bounds(trees)\n",
    "        score_n = (side ** 2) / n\n",
    "        total_test_score += score_n\n",
    "        \n",
    "    print(f\"Score of test.csv: {total_test_score:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not evaluate test.csv: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e333f7c",
   "metadata": {},
   "source": [
    "## 6. Model Training (Optional)\n",
    "\n",
    "For this geometric packing problem, standard supervised learning is less applicable than search algorithms. However, one could train a model to predict the optimal *order* of placement or the optimal *angle* given the current boundary shape. We skip this for the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for ML model training\n",
    "# model = LGBMRegressor(...)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a7494",
   "metadata": {},
   "source": [
    "## 7. Optimization Strategy\n",
    "\n",
    "We define a modular optimization function. Currently, it's a placeholder for a more advanced local search (e.g., trying to wiggle trees after placement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_packing(trees):\n",
    "    \"\"\"Centers the packing at (0,0) based on the bounding box center.\"\"\"\n",
    "    if not trees: return trees\n",
    "    minx, miny, maxx, maxy = unary_union([t.polygon for t in trees]).bounds\n",
    "    cx = (minx + maxx) / 2\n",
    "    cy = (miny + maxy) / 2\n",
    "    \n",
    "    # If already centered (small epsilon), skip\n",
    "    if abs(cx) < 1e-9 and abs(cy) < 1e-9:\n",
    "        return trees\n",
    "        \n",
    "    for t in trees:\n",
    "        t.update_position(t.center_x - cx, t.center_y - cy, t.angle)\n",
    "    return trees\n",
    "\n",
    "def optimize_packing(trees, params, target_side=None):\n",
    "    \"\"\"\n",
    "    Simulated Annealing with Numba Acceleration.\n",
    "    \"\"\"\n",
    "    if not trees: return trees\n",
    "    \n",
    "    n = len(trees)\n",
    "    \n",
    "    # Extract data for Numba\n",
    "    xs = np.array([t.center_x for t in trees], dtype=np.float64)\n",
    "    ys = np.array([t.center_y for t in trees], dtype=np.float64)\n",
    "    angs = np.array([t.angle for t in trees], dtype=np.float64)\n",
    "    \n",
    "    # Parameters\n",
    "    iterations = params.get('iterations', 10000)\n",
    "    T0 = params.get('initial_temp', 1.0)\n",
    "    Tmin = params.get('final_temp', 1e-6)\n",
    "    move_scale = params.get('step_size', 0.5)\n",
    "    rot_scale = params.get('angle_step', 10.0)\n",
    "    \n",
    "    # Generate a random seed for this run\n",
    "    seed = np.random.randint(0, 1000000)\n",
    "    \n",
    "    # Run Numba SA\n",
    "    # First run might be slow due to JIT compilation\n",
    "    best_xs, best_ys, best_angs, best_side = sa_numba(\n",
    "        xs, ys, angs, n, iterations, T0, Tmin, move_scale, rot_scale, seed\n",
    "    )\n",
    "    \n",
    "    # Update trees\n",
    "    for i in range(n):\n",
    "        trees[i].update_position(best_xs[i], best_ys[i], best_angs[i])\n",
    "        \n",
    "    return center_packing(trees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23543b68",
   "metadata": {},
   "source": [
    "## 8. Submission Generation\n",
    "\n",
    "This section runs the full pipeline and generates the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ce042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Load baseline from test.csv\n",
    "known_solutions = {}\n",
    "try:\n",
    "    print(\"Loading baseline from test.csv...\")\n",
    "    baseline_df = pd.read_csv('test.csv')\n",
    "    \n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    baseline_df['x'] = baseline_df['x'].apply(parse_s)\n",
    "    baseline_df['y'] = baseline_df['y'].apply(parse_s)\n",
    "    baseline_df['deg'] = baseline_df['deg'].apply(parse_s)\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = baseline_df[baseline_df['id'].str.startswith(prefix)]\n",
    "        if len(rows) == n:\n",
    "            trees = []\n",
    "            for _, row in rows.iterrows():\n",
    "                trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            known_solutions[n] = trees\n",
    "            \n",
    "    print(f\"Loaded {len(known_solutions)} configurations from test.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load baseline: {e}\")\n",
    "\n",
    "# --- GPU HELPER FUNCTIONS ---\n",
    "def run_gpu_batch_optimization(candidates, n, iterations=10000):\n",
    "    \"\"\"\n",
    "    Runs SA on a batch of candidates using the GPU.\n",
    "    candidates: List of list of ChristmasTree objects.\n",
    "    Returns: List of (score, trees) tuples.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from numba import cuda\n",
    "        from numba.cuda.random import create_xoroshiro128p_states\n",
    "        \n",
    "        batch_size = len(candidates)\n",
    "        if batch_size == 0: return []\n",
    "        \n",
    "        # Prepare data arrays\n",
    "        # Shape: (batch_size, n)\n",
    "        h_xs = np.zeros((batch_size, n), dtype=np.float64)\n",
    "        h_ys = np.zeros((batch_size, n), dtype=np.float64)\n",
    "        h_angs = np.zeros((batch_size, n), dtype=np.float64)\n",
    "        \n",
    "        for i, trees in enumerate(candidates):\n",
    "            for j, tree in enumerate(trees):\n",
    "                h_xs[i, j] = tree.center_x\n",
    "                h_ys[i, j] = tree.center_y\n",
    "                h_angs[i, j] = tree.angle\n",
    "                \n",
    "        # Copy to device\n",
    "        d_xs = cuda.to_device(h_xs)\n",
    "        d_ys = cuda.to_device(h_ys)\n",
    "        d_angs = cuda.to_device(h_angs)\n",
    "        d_scores = cuda.device_array(batch_size, dtype=np.float64)\n",
    "        \n",
    "        # RNG States\n",
    "        rng_states = create_xoroshiro128p_states(batch_size, seed=random.randint(0, 1000000))\n",
    "        \n",
    "        # Launch Kernel\n",
    "        threads_per_block = 64\n",
    "        blocks = (batch_size + threads_per_block - 1) // threads_per_block\n",
    "        \n",
    "        # Params\n",
    "        T0 = 1.0\n",
    "        Tmin = 1e-5\n",
    "        move_scale = 0.5\n",
    "        rot_scale = 10.0\n",
    "        \n",
    "        sa_gpu_kernel[blocks, threads_per_block](\n",
    "            d_xs, d_ys, d_angs, rng_states, iterations, T0, Tmin, move_scale, rot_scale, d_scores\n",
    "        )\n",
    "        cuda.synchronize()\n",
    "        \n",
    "        # Copy back\n",
    "        h_xs_out = d_xs.copy_to_host()\n",
    "        h_ys_out = d_ys.copy_to_host()\n",
    "        h_angs_out = d_angs.copy_to_host()\n",
    "        h_scores_out = d_scores.copy_to_host()\n",
    "        \n",
    "        results = []\n",
    "        for i in range(batch_size):\n",
    "            new_trees = []\n",
    "            for j in range(n):\n",
    "                new_trees.append(ChristmasTree(h_xs_out[i, j], h_ys_out[i, j], h_angs_out[i, j]))\n",
    "            results.append((h_scores_out[i], new_trees))\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GPU Execution Failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- CPU HELPER FUNCTIONS ---\n",
    "def process_beam_candidate_cpu(base_trees, n, packer_params, target_side=None, remove_idx=None, parent_id=None):\n",
    "    # Re-seed random\n",
    "    seed_val = (int(time.time() * 1000000) + os.getpid() + (remove_idx if remove_idx is not None else 0)) % (2**32)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    \n",
    "    current_trees = [ChristmasTree(t.center_x, t.center_y, t.angle) for t in base_trees]\n",
    "    \n",
    "    # Remove trees if needed\n",
    "    while len(current_trees) > n:\n",
    "        if remove_idx is not None and remove_idx < len(current_trees):\n",
    "            current_trees.pop(remove_idx)\n",
    "            remove_idx = None\n",
    "        else:\n",
    "            # Fallback removal\n",
    "            idx = random.randint(0, len(current_trees) - 1)\n",
    "            current_trees.pop(idx)\n",
    "            \n",
    "    # Optimize\n",
    "    iterations = max(200000, min(1000000, int(n * 5000)))\n",
    "    candidate_trees = optimize_packing(current_trees, {\n",
    "        'iterations': iterations,\n",
    "        'step_size': 1.0,\n",
    "        'angle_step': 45.0,\n",
    "        'initial_temp': 2.0,\n",
    "        'final_temp': 1e-5,\n",
    "        'compression': 0.1\n",
    "    }, target_side=target_side)\n",
    "        \n",
    "    side_candidate = get_bounds(candidate_trees)\n",
    "    score_candidate = (side_candidate ** 2) / n\n",
    "    \n",
    "    return (score_candidate, candidate_trees, parent_id)\n",
    "\n",
    "# BEAM SEARCH SETUP\n",
    "BASE_BEAM_WIDTH = CONFIG['dynamic_beam_width']['base_width']\n",
    "BRANCH_FACTOR = 8\n",
    "n_jobs = multiprocessing.cpu_count()\n",
    "\n",
    "# Check for GPU\n",
    "USE_GPU = False\n",
    "try:\n",
    "    from numba import cuda\n",
    "    if cuda.is_available():\n",
    "        USE_GPU = True\n",
    "        print(f\"CUDA GPU Detected: {cuda.get_current_device().name}\")\n",
    "        print(\"Using GPU for optimization batching.\")\n",
    "    else:\n",
    "        print(\"No CUDA GPU detected. Using CPU multiprocessing.\")\n",
    "except:\n",
    "    print(\"No CUDA GPU detected. Using CPU multiprocessing.\")\n",
    "\n",
    "packer_params = {'n_trials': 200, 'step_size': 0.2, 'fine_step': 0.01}\n",
    "submission_rows = []\n",
    "improvements = 0\n",
    "all_solutions = {}\n",
    "\n",
    "# Initialize candidates\n",
    "if 200 in known_solutions:\n",
    "    current_candidates = [(known_solutions[200], \"init\")]\n",
    "else:\n",
    "    current_candidates = []\n",
    "\n",
    "# Metrics Tracking\n",
    "history_n = []\n",
    "history_improvement = []\n",
    "history_total_score = []\n",
    "current_total_score = 0\n",
    "\n",
    "# Setup Metrics File\n",
    "os.makedirs('Data', exist_ok=True)\n",
    "timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "metrics_file = f'Data/run_metrics_advanced_{timestamp_str}.csv'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    f.write('n,score,baseline,improvement,source\\n')\n",
    "\n",
    "# Setup Realtime Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "plt.close(fig)\n",
    "plot_display_id = \"metrics_plot_advanced\"\n",
    "display(fig, display_id=plot_display_id)\n",
    "\n",
    "# REVERSE LOOP\n",
    "for n in tqdm(range(200, 0, -1), desc=\"Processing Reverse\"):\n",
    "    print(f\"\\n--- Processing N={n} ---\")\n",
    "\n",
    "    # Dynamic Beam Width\n",
    "    current_beam_width = BASE_BEAM_WIDTH\n",
    "    if CONFIG['dynamic_beam_width']['enabled']:\n",
    "        if n in [100, 50, 25, 10] or n <= 5:\n",
    "            current_beam_width = int(BASE_BEAM_WIDTH * CONFIG['dynamic_beam_width']['critical_n_multiplier'])\n",
    "\n",
    "    # 1. Generate Candidates (Removal Phase)\n",
    "    # We do this on CPU because it's fast and requires complex logic (shapely)\n",
    "    candidates_to_optimize = [] # List of (trees, parent_id)\n",
    "    \n",
    "    for p_idx, (base_trees, _) in enumerate(current_candidates):\n",
    "        # Identify boundary trees\n",
    "        minx, miny, maxx, maxy = unary_union([t.polygon for t in base_trees]).bounds\n",
    "        boundary_indices = []\n",
    "        for i, t in enumerate(base_trees):\n",
    "            tb = t.polygon.bounds\n",
    "            if (abs(tb[0] - minx) < 1e-2 or abs(tb[1] - miny) < 1e-2 or \n",
    "                abs(tb[2] - maxx) < 1e-2 or abs(tb[3] - maxy) < 1e-2):\n",
    "                boundary_indices.append(i)\n",
    "        \n",
    "        indices_to_try = boundary_indices[:BRANCH_FACTOR]\n",
    "        while len(indices_to_try) < BRANCH_FACTOR:\n",
    "            indices_to_try.append(None)\n",
    "            \n",
    "        for idx in indices_to_try:\n",
    "            # Create removed version\n",
    "            temp_trees = [ChristmasTree(t.center_x, t.center_y, t.angle) for t in base_trees]\n",
    "            if idx is not None and idx < len(temp_trees):\n",
    "                temp_trees.pop(idx)\n",
    "            else:\n",
    "                # Random removal\n",
    "                temp_trees.pop(random.randint(0, len(temp_trees)-1))\n",
    "            \n",
    "            # Ensure size is n (handle case where base was > n+1)\n",
    "            while len(temp_trees) > n:\n",
    "                temp_trees.pop()\n",
    "                \n",
    "            candidates_to_optimize.append((temp_trees, p_idx))\n",
    "\n",
    "    # 2. Optimize Candidates (GPU or CPU)\n",
    "    results = []\n",
    "    \n",
    "    if USE_GPU:\n",
    "        # GPU Batch Optimization\n",
    "        # We can run multiple restarts for each candidate to fill the GPU\n",
    "        gpu_batch = []\n",
    "        gpu_metadata = [] # (parent_id)\n",
    "        \n",
    "        RESTARTS_PER_CANDIDATE = 16 # Increase parallelism\n",
    "        \n",
    "        for trees, pid in candidates_to_optimize:\n",
    "            for _ in range(RESTARTS_PER_CANDIDATE):\n",
    "                # Deep copy for restart\n",
    "                gpu_batch.append([ChristmasTree(t.center_x, t.center_y, t.angle) for t in trees])\n",
    "                gpu_metadata.append(pid)\n",
    "                \n",
    "        print(f\"  [N={n}] Launching GPU Kernel with {len(gpu_batch)} threads...\")\n",
    "        gpu_results = run_gpu_batch_optimization(gpu_batch, n, iterations=200000)\n",
    "        \n",
    "        for i, (score, trees) in enumerate(gpu_results):\n",
    "            results.append((score, trees, gpu_metadata[i]))\n",
    "            \n",
    "    else:\n",
    "        # CPU Parallel Optimization\n",
    "        print(f\"  [N={n}] Launching {len(candidates_to_optimize)} CPU tasks...\")\n",
    "        tasks = []\n",
    "        for trees, pid in candidates_to_optimize:\n",
    "            tasks.append((trees, n, packer_params, None, None, pid))\n",
    "            \n",
    "        # Note: process_beam_candidate_cpu expects base_trees > n, but we already reduced them.\n",
    "        # We need a slight adapter or just use optimize_packing directly in parallel.\n",
    "        # Let's use a simple wrapper.\n",
    "        def run_cpu_opt(trees, pid):\n",
    "            opt_trees = optimize_packing(trees, {\n",
    "                'iterations': 200000,\n",
    "                'step_size': 1.0,\n",
    "                'angle_step': 45.0,\n",
    "                'initial_temp': 2.0,\n",
    "                'final_temp': 1e-5\n",
    "            })\n",
    "            s = get_bounds(opt_trees)\n",
    "            return ((s**2)/n, opt_trees, pid)\n",
    "            \n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(run_cpu_opt)(t[0], t[1]) for t in candidates_to_optimize\n",
    "        )\n",
    "\n",
    "    # 3. Sort and Select\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    if not results:\n",
    "        print(f\"  [N={n}] No results!\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  [N={n}] Best candidate score: {results[0][0]:.6f}\")\n",
    "    \n",
    "    # Diversity Selection\n",
    "    unique_candidates = []\n",
    "    seen_scores = set()\n",
    "    parent_counts = {}\n",
    "    max_children = CONFIG['beam_diversity']['max_children_per_parent']\n",
    "    \n",
    "    for res in results:\n",
    "        score = round(res[0], 6)\n",
    "        trees = res[1]\n",
    "        pid = res[2]\n",
    "        \n",
    "        if score in seen_scores: continue\n",
    "        if parent_counts.get(pid, 0) >= max_children: continue\n",
    "        \n",
    "        unique_candidates.append((trees, pid))\n",
    "        seen_scores.add(score)\n",
    "        parent_counts[pid] = parent_counts.get(pid, 0) + 1\n",
    "        \n",
    "        if len(unique_candidates) >= current_beam_width:\n",
    "            break\n",
    "            \n",
    "    current_candidates = unique_candidates\n",
    "    best_trees_n = results[0][1]\n",
    "    best_score_n = results[0][0]\n",
    "    source = \"Reverse\"\n",
    "    \n",
    "    # 4. Baseline Comparison\n",
    "    baseline_val = 0\n",
    "    if n in known_solutions:\n",
    "        known_trees = center_packing(known_solutions[n])\n",
    "        side_known = get_bounds(known_trees)\n",
    "        score_known = (side_known ** 2) / n\n",
    "        baseline_val = score_known\n",
    "        \n",
    "        if score_known < best_score_n - 1e-7:\n",
    "            print(f\"  [N={n}] Baseline is better ({score_known:.6f} < {best_score_n:.6f}).\")\n",
    "            best_trees_n = known_trees\n",
    "            best_score_n = score_known\n",
    "            source = \"Baseline\"\n",
    "            \n",
    "            # Try to optimize baseline on GPU/CPU\n",
    "            if USE_GPU:\n",
    "                # Run massive GPU optimization on baseline\n",
    "                print(f\"  [N={n}] Optimizing baseline on GPU...\")\n",
    "                base_batch = []\n",
    "                for _ in range(128): # 128 restarts\n",
    "                    base_batch.append([ChristmasTree(t.center_x, t.center_y, t.angle) for t in known_trees])\n",
    "                \n",
    "                base_results = run_gpu_batch_optimization(base_batch, n, iterations=500000)\n",
    "                base_results.sort(key=lambda x: x[0])\n",
    "                if base_results[0][0] < score_known - 1e-7:\n",
    "                    best_trees_n = base_results[0][1]\n",
    "                    best_score_n = base_results[0][0]\n",
    "                    source = \"Baseline+GPU\"\n",
    "                    improvements += 1\n",
    "                    print(f\"  [N={n}] GPU Improved Baseline! -> {best_score_n:.6f}\")\n",
    "            else:\n",
    "                # CPU Optimization\n",
    "                opt_known = optimize_packing(known_trees, {'iterations': 500000, 'step_size': 0.8})\n",
    "                s_opt = (get_bounds(opt_known)**2)/n\n",
    "                if s_opt < score_known - 1e-7:\n",
    "                    best_trees_n = opt_known\n",
    "                    best_score_n = s_opt\n",
    "                    source = \"Baseline+CPU\"\n",
    "                    improvements += 1\n",
    "                    print(f\"  [N={n}] CPU Improved Baseline! -> {best_score_n:.6f}\")\n",
    "                    \n",
    "            # Inject back into beam\n",
    "            current_candidates.append((best_trees_n, \"baseline\"))\n",
    "            \n",
    "        elif best_score_n < score_known - 1e-7:\n",
    "            print(f\"  [N={n}] Improvement found! {score_known:.6f} -> {best_score_n:.6f}\")\n",
    "            improvements += 1\n",
    "            \n",
    "    # 5. Save & Plot\n",
    "    all_solutions[n] = best_trees_n\n",
    "    current_total_score += best_score_n\n",
    "    imp = max(0, baseline_val - best_score_n) if baseline_val > 0 else 0\n",
    "    \n",
    "    with open(metrics_file, 'a') as f:\n",
    "        f.write(f\"{n},{best_score_n:.10f},{baseline_val:.10f},{imp:.10f},{source}\\n\")\n",
    "        \n",
    "    if n % 5 == 0 or n == 1:\n",
    "        ax1.clear(); ax2.clear()\n",
    "        history_n.append(n); history_improvement.append(imp); history_total_score.append(current_total_score)\n",
    "        ax1.plot(history_n, history_improvement, 'g-'); ax1.set_title(f'Improvement (Total: {improvements})'); ax1.invert_xaxis()\n",
    "        ax2.plot(history_n, history_total_score, 'b-'); ax2.set_title(f'Score: {current_total_score:.4f}'); ax2.invert_xaxis()\n",
    "        display(fig, display_id=plot_display_id, update=True)\n",
    "        \n",
    "    # Prepare submission rows\n",
    "    for i, tree in enumerate(best_trees_n):\n",
    "        submission_rows.append([f\"{n:03d}_{i}\", f\"s{tree.center_x:.10f}\", f\"s{tree.center_y:.10f}\", f\"s{tree.angle:.10f}\"])\n",
    "\n",
    "print(f\"Processing complete. Improvements: {improvements}\")\n",
    "df_sub = pd.DataFrame(submission_rows, columns=['id', 'x', 'y', 'deg'])\n",
    "df_sub.sort_values('id', inplace=True)\n",
    "df_sub.to_csv('submission.csv', index=False)\n",
    "print(\"Submission generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a5fc2",
   "metadata": {},
   "source": [
    "## 10. Evaluation Helper\n",
    "\n",
    "Calculate the local score to estimate leaderboard performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b62dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Polishing & Refinement\n",
    "# Run this cell to further optimize the existing submission using the new Numba engine.\n",
    "# This is much faster than the full search and can squeeze out extra points.\n",
    "\n",
    "print(\"Starting Polishing Phase...\")\n",
    "try:\n",
    "    # Load current best submission\n",
    "    if os.path.exists('submission.csv'):\n",
    "        polish_df = pd.read_csv('submission.csv')\n",
    "        print(\"Loaded submission.csv for polishing.\")\n",
    "    else:\n",
    "        polish_df = pd.read_csv('test.csv')\n",
    "        print(\"Loaded test.csv for polishing.\")\n",
    "\n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    polish_df['x'] = polish_df['x'].apply(parse_s)\n",
    "    polish_df['y'] = polish_df['y'].apply(parse_s)\n",
    "    polish_df['deg'] = polish_df['deg'].apply(parse_s)\n",
    "    \n",
    "    polish_solutions = {}\n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = polish_df[polish_df['id'].str.startswith(prefix)]\n",
    "        if len(rows) == n:\n",
    "            trees = []\n",
    "            for _, row in rows.iterrows():\n",
    "                trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            polish_solutions[n] = trees\n",
    "\n",
    "    total_score_before = 0\n",
    "    total_score_after = 0\n",
    "    \n",
    "    # Polish each N\n",
    "    for n in tqdm(range(1, 201), desc=\"Polishing\"):\n",
    "        if n not in polish_solutions: continue\n",
    "        \n",
    "        trees = polish_solutions[n]\n",
    "        side_before = get_bounds(trees)\n",
    "        score_before = (side_before ** 2) / n\n",
    "        total_score_before += score_before\n",
    "        \n",
    "        # Run Numba Optimization\n",
    "        # High iterations because it's fast!\n",
    "        iters = 200000 if n < 50 else 500000\n",
    "        \n",
    "        optimized_trees = optimize_packing(trees, {\n",
    "            'iterations': iters,\n",
    "            'step_size': 0.5,\n",
    "            'angle_step': 15.0,\n",
    "            'initial_temp': 1.0,\n",
    "            'final_temp': 1e-6\n",
    "        })\n",
    "        \n",
    "        side_after = get_bounds(optimized_trees)\n",
    "        score_after = (side_after ** 2) / n\n",
    "        \n",
    "        if score_after < score_before - 1e-9:\n",
    "            polish_solutions[n] = optimized_trees\n",
    "            total_score_after += score_after\n",
    "            # print(f\"  N={n} Improved: {score_before:.6f} -> {score_after:.6f}\")\n",
    "        else:\n",
    "            total_score_after += score_before # Keep original\n",
    "            \n",
    "    print(f\"Polishing Complete.\")\n",
    "    print(f\"Score Before: {total_score_before:.6f}\")\n",
    "    print(f\"Score After:  {total_score_after:.6f}\")\n",
    "    print(f\"Improvement:  {total_score_before - total_score_after:.6f}\")\n",
    "    \n",
    "    # Save if improved\n",
    "    if total_score_after < total_score_before:\n",
    "        new_rows = []\n",
    "        for n in range(1, 201):\n",
    "            if n in polish_solutions:\n",
    "                for i, tree in enumerate(polish_solutions[n]):\n",
    "                    new_rows.append([\n",
    "                        f\"{n:03d}_{i}\", \n",
    "                        f\"s{tree.center_x:.10f}\", \n",
    "                        f\"s{tree.center_y:.10f}\", \n",
    "                        f\"s{tree.angle:.10f}\"\n",
    "                    ])\n",
    "        \n",
    "        df_polished = pd.DataFrame(new_rows, columns=['id', 'x', 'y', 'deg'])\n",
    "        df_polished.sort_values('id', inplace=True)\n",
    "        df_polished.to_csv('submission_polished.csv', index=False)\n",
    "        df_polished.to_csv('submission.csv', index=False) # Overwrite main\n",
    "        print(\"Saved polished submission to submission.csv\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Polishing failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8122a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "# Calculate final score\n",
    "final_score = 0\n",
    "for n, trees in all_solutions.items():\n",
    "    side = get_bounds(trees)\n",
    "    final_score += (side ** 2) / n\n",
    "\n",
    "print(f\"Final Score: {final_score:.10f}\")\n",
    "\n",
    "# Compare with original\n",
    "if 'total_test_score' in globals():\n",
    "    print(f\"Original Score: {total_test_score:.10f}\")\n",
    "    if final_score < total_test_score:\n",
    "        diff = total_test_score - final_score\n",
    "        print(f\"SUCCESS: Score improved by {diff:.10f}!\")\n",
    "        \n",
    "        # 1. Save copy with detailed name\n",
    "        os.makedirs('Data', exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        detailed_name = f\"Data/submission_score{final_score:.2f}_improved{diff:.2f}_{timestamp}.csv\"\n",
    "        df_sub.to_csv(detailed_name, index=False)\n",
    "        print(f\"Saved backup: {detailed_name}\")\n",
    "        \n",
    "        # 2. Overwrite test.csv\n",
    "        df_sub.to_csv('test.csv', index=False)\n",
    "        print(\"Overwrote test.csv\")\n",
    "        \n",
    "        # 3. Submit to Kaggle\n",
    "        message = f\"Improved score {final_score:.6f} (was {total_test_score:.6f})\"\n",
    "        print(\"Submitting to Kaggle...\")\n",
    "        !kaggle competitions submit -c santa-2025 -f submission.csv -m \"{message}\"\n",
    "\n",
    "        # 4. Git Commit and Push\n",
    "        print(\"Committing and pushing to Git...\")\n",
    "        !git add .\n",
    "        !git commit -m \"{message}\"\n",
    "        !git push\n",
    "        \n",
    "    else:\n",
    "        print(f\"No improvement (Current: {final_score:.10f} >= Original: {total_test_score:.10f}).\")\n",
    "else:\n",
    "    print(\"Original score not found. Run the first cell to load test.csv baseline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
