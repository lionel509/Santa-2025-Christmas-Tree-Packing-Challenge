{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Setup\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.strtree import STRtree\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2025\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# High precision for coordinates\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(\"Libraries imported and seed set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde65439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA parameter normalization helper\n",
    "def normalize_sa_params(params: dict):\n",
    "    \"\"\"Return canonical SA parameters with robust fallbacks.\n",
    "    Supports multiple naming conventions to avoid KeyError.\n",
    "    Keys mapped: T0, Tmin, move_scale, rot_scale, compression, iterations.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    T0 = (params.get('initial_temp') or params.get('T0') or params.get('start_temp') or 1.0)\n",
    "    Tmin = (params.get('min_temp') or params.get('Tmin') or params.get('final_temp') or params.get('end_temp') or 0.001)\n",
    "    move_scale = (params.get('move_scale') or params.get('move') or 0.5)\n",
    "    rot_scale = (params.get('rot_scale') or params.get('rotation_scale') or params.get('rotate_scale') or 30.0)\n",
    "    compression = (params.get('compression') or params.get('compress') or 0.05)\n",
    "    iterations = (params.get('iterations') or params.get('iters') or params.get('n_iterations') or 50000)\n",
    "    base_seed = params.get('base_seed', 2025)\n",
    "    return {\n",
    "        'T0': float(T0),\n",
    "        'Tmin': float(Tmin),\n",
    "        'move_scale': float(move_scale),\n",
    "        'rot_scale': float(rot_scale),\n",
    "        'compression': float(compression),\n",
    "        'iterations': int(iterations),\n",
    "        'base_seed': int(base_seed)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Advanced Features\n",
    "CONFIG = {\n",
    "    # Hybrid Search Approach\n",
    "    'hybrid_search': {\n",
    "        'enabled': True,\n",
    "        'switch_n': 25,  # Use forward building for N <= 25\n",
    "    },\n",
    "    \n",
    "    # Dynamic Beam Width\n",
    "    'dynamic_beam_width': {\n",
    "        'enabled': True,\n",
    "        'base_width': 12,\n",
    "        'critical_n_multiplier': 2.0, # Wider for critical sizes\n",
    "    },\n",
    "    \n",
    "    # Beam Search Diversity\n",
    "    'beam_diversity': {\n",
    "        'enabled': True,\n",
    "        'max_children_per_parent': 3, # Prevent one parent from dominating the next generation\n",
    "    },\n",
    "    \n",
    "    # Multi-Start Optimization\n",
    "    'multi_start': {\n",
    "        'enabled': True,\n",
    "        'n_starts': 3,\n",
    "    },\n",
    "    \n",
    "    # Optimization Function Enhancements\n",
    "    'optimization': {\n",
    "        'adaptive_temperature': True,\n",
    "        'smart_move_selection': True, # Bias moves toward boundary\n",
    "        'batch_moves': False, # Try moving multiple trees (complex)\n",
    "        'boundary_bias_strength': 0.7, # 70% chance to pick boundary tree\n",
    "        'reheating': True, # Restart SA if stuck\n",
    "        'compaction_pass': True, # Pure translation pass to close gaps\n",
    "    },\n",
    "    \n",
    "    # Post-Processing & Polishing\n",
    "    'post_processing': {\n",
    "        'polishing': True, # Run a low-temp refinement phase at the end\n",
    "        'polishing_iterations': 2000,\n",
    "    },\n",
    "    \n",
    "    # Geometric & Heuristic Improvements\n",
    "    'heuristics': {\n",
    "        'corner_filling': True,\n",
    "        'symmetry_breaking': True,\n",
    "        'boundary_alignment': True,\n",
    "    },\n",
    "    \n",
    "    # Validation\n",
    "    'validation': {\n",
    "        'strict_boundary': True,\n",
    "        'collision_check': True,\n",
    "    },\n",
    "    \n",
    "    # Debugging\n",
    "    'debug': {\n",
    "        'verbose_logging': True,\n",
    "        'plot_convergence': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Bucketed SA Parameters\n",
    "SA_PARAMS = {\n",
    "    'large': { # N >= 150\n",
    "        'iterations': 1000000, # 1M+\n",
    "        'step_size': 0.5,\n",
    "        'angle_step': 5.0, # Restricted rotation\n",
    "        'initial_temp': 1.0,\n",
    "        'final_temp': 1e-6,\n",
    "        'compression': 0.2, # Strong compression\n",
    "    },\n",
    "    'medium': { # 50 <= N < 150\n",
    "        'iterations': 500000,\n",
    "        'step_size': 0.8,\n",
    "        'angle_step': 15.0,\n",
    "        'initial_temp': 1.5,\n",
    "        'final_temp': 1e-6,\n",
    "        'compression': 0.1,\n",
    "    },\n",
    "    'small': { # N < 50\n",
    "        'iterations': 200000,\n",
    "        'step_size': 1.0,\n",
    "        'angle_step': 360.0, # Full rotation\n",
    "        'initial_temp': 2.0,\n",
    "        'final_temp': 1e-6,\n",
    "        'compression': 0.05,\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_sa_params(n):\n",
    "    if n >= 150:\n",
    "        return SA_PARAMS['large']\n",
    "    elif n >= 50:\n",
    "        return SA_PARAMS['medium']\n",
    "    else:\n",
    "        return SA_PARAMS['small']\n",
    "\n",
    "print(\"Configuration loaded:\", CONFIG)\n",
    "print(\"SA Parameters loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load Data\n",
    "\n",
    "# Load the sample submission to understand the required output format\n",
    "try:\n",
    "    sample_sub = pd.read_csv('test.csv')\n",
    "    print(\"Sample Submission Shape:\", sample_sub.shape)\n",
    "    print(sample_sub.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Sample submission not found, proceeding without it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02218ccb",
   "metadata": {},
   "source": [
    "## 4. Baseline Strategy\n",
    "\n",
    "We define the `GreedyPacker` class here. It encapsulates the logic for placing a single tree into an existing configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPacker:\n",
    "    def __init__(self, n_trials=100, step_size=0.2, fine_step=0.02):\n",
    "        self.n_trials = n_trials\n",
    "        self.step_size = step_size\n",
    "        self.fine_step = fine_step\n",
    "\n",
    "    def _generate_weighted_angle(self):\n",
    "        \"\"\"\n",
    "        Generates a random angle with a distribution weighted by abs(sin(2*angle)).\n",
    "        This helps place more trees in corners (diagonals).\n",
    "        \"\"\"\n",
    "        if not CONFIG['heuristics']['corner_filling']:\n",
    "            return random.uniform(0, 2 * math.pi)\n",
    "            \n",
    "        while True:\n",
    "            angle = random.uniform(0, 2 * math.pi)\n",
    "            if random.uniform(0, 1) < abs(math.sin(2 * angle)):\n",
    "                return angle\n",
    "\n",
    "    def place_next_tree(self, existing_trees, tree_class):\n",
    "        \"\"\"Finds the best position for the next tree given existing trees.\"\"\"\n",
    "        if not existing_trees:\n",
    "            return tree_class(0, 0, 0)\n",
    "\n",
    "        existing_polys = [t.polygon for t in existing_trees]\n",
    "        tree_index = STRtree(existing_polys)\n",
    "        \n",
    "        # Calculate current bounds and center\n",
    "        minx, miny, maxx, maxy = unary_union(existing_polys).bounds\n",
    "        center_x = (minx + maxx) / 2\n",
    "        center_y = (miny + maxy) / 2\n",
    "        \n",
    "        best_tree = None\n",
    "        min_metric = float('inf')\n",
    "\n",
    "        for _ in range(self.n_trials):\n",
    "            # Random angle for the tree itself\n",
    "            angle = random.uniform(0, 360)\n",
    "            \n",
    "            # Weighted approach angle (bias towards diagonals)\n",
    "            approach_angle = self._generate_weighted_angle()\n",
    "            vx, vy = math.cos(approach_angle), math.sin(approach_angle)\n",
    "            \n",
    "            # Start far away\n",
    "            radius = max(maxx - minx, maxy - miny) + 10.0\n",
    "            candidate = tree_class(0, 0, angle)\n",
    "            \n",
    "            # Move in\n",
    "            current_r = radius\n",
    "            collision = False\n",
    "            \n",
    "            # Coarse search\n",
    "            while current_r > 0:\n",
    "                px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                candidate.update_position(px, py, angle)\n",
    "                \n",
    "                query_indices = tree_index.query(candidate.polygon)\n",
    "                if any(candidate.polygon.intersects(existing_polys[i]) for i in query_indices):\n",
    "                    collision = True\n",
    "                    break\n",
    "                current_r -= self.step_size\n",
    "            \n",
    "            # Fine tune\n",
    "            if collision:\n",
    "                current_r += self.step_size\n",
    "                while True:\n",
    "                    current_r -= self.fine_step\n",
    "                    px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                    candidate.update_position(px, py, angle)\n",
    "                    \n",
    "                    query_indices = tree_index.query(candidate.polygon)\n",
    "                    if any(candidate.polygon.intersects(existing_polys[i]) for i in query_indices):\n",
    "                        # Collision found, step back once and stop\n",
    "                        current_r += self.fine_step\n",
    "                        px, py = center_x + current_r * vx, center_y + current_r * vy\n",
    "                        candidate.update_position(px, py, angle)\n",
    "                        break\n",
    "            else:\n",
    "                candidate.update_position(center_x, center_y, angle)\n",
    "\n",
    "            # Metric: Minimize the side length of the new bounding box\n",
    "            t_minx, t_miny, t_maxx, t_maxy = candidate.polygon.bounds\n",
    "            new_minx = min(minx, t_minx)\n",
    "            new_miny = min(miny, t_miny)\n",
    "            new_maxx = max(maxx, t_maxx)\n",
    "            new_maxy = max(maxy, t_maxy)\n",
    "            \n",
    "            new_side = max(new_maxx - new_minx, new_maxy - new_miny)\n",
    "            \n",
    "            # Tie-breaker: distance to center\n",
    "            dist_sq = (px - center_x)**2 + (py - center_y)**2\n",
    "            \n",
    "            metric = new_side + (dist_sq * 1e-6)\n",
    "            \n",
    "            if metric < min_metric:\n",
    "                min_metric = metric\n",
    "                best_tree = tree_class(px, py, angle)\n",
    "                \n",
    "        return best_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df33791",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Module\n",
    "\n",
    "Here we define the geometric features of the problem: the `ChristmasTree` class and helper functions for bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChristmasTree:\n",
    "    \"\"\"Represents a single, rotatable Christmas tree.\"\"\"\n",
    "    def __init__(self, center_x=0, center_y=0, angle=0):\n",
    "        self.center_x = float(center_x)\n",
    "        self.center_y = float(center_y)\n",
    "        self.angle = float(angle)\n",
    "        self.polygon = self._create_polygon()\n",
    "\n",
    "    def _create_polygon(self):\n",
    "        # Tree dimensions\n",
    "        coords = [\n",
    "            (0.0, 0.8), (0.125, 0.5), (0.0625, 0.5), (0.2, 0.25), (0.1, 0.25),\n",
    "            (0.35, 0.0), (0.075, 0.0), (0.075, -0.2), (-0.075, -0.2), (-0.075, 0.0),\n",
    "            (-0.35, 0.0), (-0.1, 0.25), (-0.2, 0.25), (-0.0625, 0.5), (-0.125, 0.5)\n",
    "        ]\n",
    "        poly = Polygon(coords)\n",
    "        rotated = affinity.rotate(poly, self.angle, origin=(0, 0))\n",
    "        return affinity.translate(rotated, xoff=self.center_x, yoff=self.center_y)\n",
    "\n",
    "    def update_position(self, x, y, angle):\n",
    "        self.center_x = x\n",
    "        self.center_y = y\n",
    "        self.angle = angle\n",
    "        self.polygon = self._create_polygon()\n",
    "\n",
    "def get_bounds(trees):\n",
    "    if not trees: return 0\n",
    "    minx, miny, maxx, maxy = unary_union([t.polygon for t in trees]).bounds\n",
    "    return max(maxx - minx, maxy - miny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NUMBA ACCELERATED GEOMETRY KERNEL ---\n",
    "# Refactored to optimization_utils.py for performance and caching\n",
    "import importlib\n",
    "import optimization_utils\n",
    "importlib.reload(optimization_utils)\n",
    "\n",
    "from optimization_utils import (\n",
    "    get_poly, get_bbox, pip, seg_intersect, overlap, \n",
    "    check_overlap_single_cached, check_overlap_pair_cached, \n",
    "    calc_side, calc_side_cached, get_global_bbox, get_global_bbox_cached, \n",
    "    find_corner_trees, find_corner_trees_cached, sa_numba\n",
    ")\n",
    "\n",
    "# get_bounds is defined in the previous cell (Cell 7) using Shapely.\n",
    "# calc_side is the Numba equivalent for the optimization loop.\n",
    "\n",
    "print(\"Imported optimized Numba kernel from optimization_utils.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the existing test.csv to verify the score\n",
    "import pandas as pd\n",
    "try:\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    print(\"Loaded test.csv\")\n",
    "    \n",
    "    # Parse the 's' prefix\n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    test_df['x'] = test_df['x'].apply(parse_s)\n",
    "    test_df['y'] = test_df['y'].apply(parse_s)\n",
    "    test_df['deg'] = test_df['deg'].apply(parse_s)\n",
    "    \n",
    "    # Reconstruct trees and calculate score\n",
    "    total_test_score = 0\n",
    "    for n in range(1, 201):\n",
    "        # Get rows for this N\n",
    "        # The ID format is N_i, e.g., 001_0\n",
    "        # We need to filter by the prefix\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = test_df[test_df['id'].str.startswith(prefix)]\n",
    "        \n",
    "        if len(rows) != n:\n",
    "            print(f\"Warning: N={n} has {len(rows)} rows, expected {n}\")\n",
    "            continue\n",
    "            \n",
    "        trees = []\n",
    "        for _, row in rows.iterrows():\n",
    "            trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            \n",
    "        side = get_bounds(trees)\n",
    "        score_n = (side ** 2) / n\n",
    "        total_test_score += score_n\n",
    "        \n",
    "    print(f\"Score of test.csv: {total_test_score:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not evaluate test.csv: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Compare all_solutions dict vs submission_rows scoring\n",
    "# This helps identify why scores might differ\n",
    "\n",
    "if 'all_solutions' in globals() and 'submission_rows' in globals():\n",
    "    print(\"Comparing scoring methods...\\n\")\n",
    "    \n",
    "    # Method 1: all_solutions dict\n",
    "    score_method1 = 0\n",
    "    for n, trees in all_solutions.items():\n",
    "        side = get_bounds(trees)\n",
    "        score_method1 += (side ** 2) / n\n",
    "    \n",
    "    # Method 2: submission_rows\n",
    "    score_method2 = 0\n",
    "    configs = {}\n",
    "    for row in submission_rows:\n",
    "        n = int(row[0].split('_')[0])\n",
    "        if n not in configs:\n",
    "            configs[n] = []\n",
    "        x = float(row[1].replace('s', ''))\n",
    "        y = float(row[2].replace('s', ''))\n",
    "        deg = float(row[3].replace('s', ''))\n",
    "        configs[n].append(ChristmasTree(x, y, deg))\n",
    "    \n",
    "    for n, trees in configs.items():\n",
    "        side = get_bounds(trees)\n",
    "        score_method2 += (side ** 2) / n\n",
    "    \n",
    "    print(f\"Method 1 (all_solutions dict): {score_method1:.6f} ({len(all_solutions)} configs)\")\n",
    "    print(f\"Method 2 (submission_rows):    {score_method2:.6f} ({len(configs)} configs)\")\n",
    "    print(f\"Difference: {abs(score_method1 - score_method2):.6f}\")\n",
    "    \n",
    "    if len(all_solutions) != len(configs):\n",
    "        print(f\"\\n⚠️ WARNING: Config count mismatch!\")\n",
    "        missing_in_dict = set(configs.keys()) - set(all_solutions.keys())\n",
    "        missing_in_rows = set(all_solutions.keys()) - set(configs.keys())\n",
    "        if missing_in_dict:\n",
    "            print(f\"  Missing in all_solutions: {sorted(missing_in_dict)}\")\n",
    "        if missing_in_rows:\n",
    "            print(f\"  Missing in submission_rows: {sorted(missing_in_rows)}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Both methods have same number of configurations\")\n",
    "else:\n",
    "    print(\"Run the main processing cell first to populate variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e333f7c",
   "metadata": {},
   "source": [
    "## 6. Model Training (Optional)\n",
    "\n",
    "For this geometric packing problem, standard supervised learning is less applicable than search algorithms. However, one could train a model to predict the optimal *order* of placement or the optimal *angle* given the current boundary shape. We skip this for the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for ML model training\n",
    "# model = LGBMRegressor(...)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a7494",
   "metadata": {},
   "source": [
    "## 7. Optimization Strategy\n",
    "\n",
    "We define a modular optimization function. Currently, it's a placeholder for a more advanced local search (e.g., trying to wiggle trees after placement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_packing(trees):\n",
    "    \"\"\"Centers the packing at (0,0) based on the bounding box center.\"\"\"\n",
    "    if not trees: return trees\n",
    "    minx, miny, maxx, maxy = unary_union([t.polygon for t in trees]).bounds\n",
    "    cx = (minx + maxx) / 2\n",
    "    cy = (miny + maxy) / 2\n",
    "    \n",
    "    # If already centered (small epsilon), skip\n",
    "    if abs(cx) < 1e-9 and abs(cy) < 1e-9:\n",
    "        return trees\n",
    "        \n",
    "    for t in trees:\n",
    "        t.update_position(t.center_x - cx, t.center_y - cy, t.angle)\n",
    "    return trees\n",
    "\n",
    "def optimize_packing(trees, params, target_side=None):\n",
    "    \"\"\"\n",
    "    Simulated Annealing with Numba Acceleration.\n",
    "    OPTIMIZED: Using collision_scale=1.0 for accurate and faster collision detection.\n",
    "    \"\"\"\n",
    "    if not trees: return trees\n",
    "    \n",
    "    n = len(trees)\n",
    "    \n",
    "    # Extract data for Numba\n",
    "    xs = np.array([t.center_x for t in trees], dtype=np.float64)\n",
    "    ys = np.array([t.center_y for t in trees], dtype=np.float64)\n",
    "    angs = np.array([t.angle for t in trees], dtype=np.float64)\n",
    "    \n",
    "    # Parameters\n",
    "    iterations = params.get('iterations', 10000)\n",
    "    T0 = params.get('initial_temp', 1.0)\n",
    "    Tmin = params.get('final_temp', 1e-6)\n",
    "    move_scale = params.get('step_size', 0.5)\n",
    "    rot_scale = params.get('angle_step', 10.0)\n",
    "    compression = params.get('compression', 0.0)\n",
    "    \n",
    "    # Generate a random seed for this run\n",
    "    seed = np.random.randint(0, 1000000)\n",
    "    \n",
    "    # Handle target_side default for Numba\n",
    "    ts = target_side if target_side is not None else 0.0\n",
    "    \n",
    "    # Run Numba SA with collision_scale=1.0 (exact collision detection)\n",
    "    # This is faster and more accurate than using a buffer\n",
    "    best_xs, best_ys, best_angs, best_side = sa_numba(\n",
    "        xs, ys, angs, n, iterations, T0, Tmin, move_scale, rot_scale, seed, compression, \n",
    "        collision_scale=1.0, target_side=ts\n",
    "    )\n",
    "    \n",
    "    # Update trees\n",
    "    for i in range(n):\n",
    "        trees[i].update_position(best_xs[i], best_ys[i], best_angs[i])\n",
    "        \n",
    "    return center_packing(trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lattice(n=200):\n",
    "    \"\"\"\n",
    "    Generates a structured lattice packing for N=200.\n",
    "    Uses a brick/triangular layout with alternating orientations.\n",
    "    \"\"\"\n",
    "    print(f\"Generating Lattice Initialization for N={n}...\")\n",
    "    \n",
    "    # Approximate dimensions of the tree bounding box\n",
    "    # Tree is roughly 0.5 wide and 1.0 tall (centered at 0,0)\n",
    "    # But effective packing width/height is smaller due to shape\n",
    "    dx = 0.25  # Horizontal spacing\n",
    "    dy = 0.45  # Vertical spacing\n",
    "    \n",
    "    # Calculate grid size\n",
    "    # We want a roughly square aspect ratio\n",
    "    cols = int(math.sqrt(n * (dy/dx)))\n",
    "    rows = math.ceil(n / cols)\n",
    "    \n",
    "    trees = []\n",
    "    count = 0\n",
    "    \n",
    "    # Center the grid\n",
    "    start_x = -((cols - 1) * dx) / 2\n",
    "    start_y = -((rows - 1) * dy) / 2\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if count >= n: break\n",
    "            \n",
    "            x = start_x + c * dx\n",
    "            y = start_y + r * dy\n",
    "            \n",
    "            # Offset every other row for triangular/brick pattern\n",
    "            if r % 2 == 1:\n",
    "                x += dx / 2\n",
    "                \n",
    "            # Alternating orientation (Checkerboard or Row-based)\n",
    "            # Row-based alternation:\n",
    "            angle = 0 if r % 2 == 0 else 180\n",
    "            \n",
    "            # Checkerboard alternation (optional, uncomment to try):\n",
    "            # angle = 0 if (r + c) % 2 == 0 else 180\n",
    "            \n",
    "            trees.append(ChristmasTree(x, y, angle))\n",
    "            count += 1\n",
    "            \n",
    "    return center_packing(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23543b68",
   "metadata": {},
   "source": [
    "## 8. Submission Generation\n",
    "\n",
    "This section runs the full pipeline and generates the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "492ce042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [N=190] Best candidate score: 0.168013\n",
      "  [N=190] Baseline score: 0.367121, Candidate score: 0.168013\n",
      "  [N=190] ✓ IMPROVED over baseline: 0.367121 -> 0.168013 (Δ=0.199108, 54.23%)\n",
      "⚠️  Collision at N=190 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=190] Found 810 collision(s)\n",
      "  [N=190] Too many collisions - reverting to baseline\n",
      "  [N=190] Cumulative Score: 2.211179 | Total Improvements: 11\n",
      "\n",
      "--- Processing N=189 ---\n",
      "  [N=189] Launching 5 parallel tasks...\n",
      "\n",
      "--- Processing N=189 ---\n",
      "  [N=189] Launching 5 parallel tasks...\n",
      "  [N=189] Best candidate score: 0.168902\n",
      "  [N=189] Baseline score: 0.369011, Candidate score: 0.168902\n",
      "  [N=189] ✓ IMPROVED over baseline: 0.369011 -> 0.168902 (Δ=0.200109, 54.23%)\n",
      "  [N=189] Cumulative Score: 2.380081 | Total Improvements: 12\n",
      "\n",
      "--- Processing N=188 ---\n",
      "  [N=188] Launching 5 parallel tasks...\n",
      "  [N=189] Best candidate score: 0.168902\n",
      "  [N=189] Baseline score: 0.369011, Candidate score: 0.168902\n",
      "  [N=189] ✓ IMPROVED over baseline: 0.369011 -> 0.168902 (Δ=0.200109, 54.23%)\n",
      "  [N=189] Cumulative Score: 2.380081 | Total Improvements: 12\n",
      "\n",
      "--- Processing N=188 ---\n",
      "  [N=188] Launching 5 parallel tasks...\n",
      "  [N=188] Best candidate score: 0.169801\n",
      "  [N=188] Baseline score: 0.370974, Candidate score: 0.169801\n",
      "  [N=188] ✓ IMPROVED over baseline: 0.370974 -> 0.169801 (Δ=0.201173, 54.23%)\n",
      "  [N=188] Cumulative Score: 2.549881 | Total Improvements: 13\n",
      "\n",
      "--- Processing N=187 ---\n",
      "  [N=187] Launching 5 parallel tasks...\n",
      "  [N=188] Best candidate score: 0.169801\n",
      "  [N=188] Baseline score: 0.370974, Candidate score: 0.169801\n",
      "  [N=188] ✓ IMPROVED over baseline: 0.370974 -> 0.169801 (Δ=0.201173, 54.23%)\n",
      "  [N=188] Cumulative Score: 2.549881 | Total Improvements: 13\n",
      "\n",
      "--- Processing N=187 ---\n",
      "  [N=187] Launching 5 parallel tasks...\n",
      "  [N=187] Best candidate score: 0.170709\n",
      "  [N=187] Baseline score: 0.372957, Candidate score: 0.170709\n",
      "  [N=187] ✓ IMPROVED over baseline: 0.372957 -> 0.170709 (Δ=0.202249, 54.23%)\n",
      "  [N=187] Cumulative Score: 2.720590 | Total Improvements: 14\n",
      "\n",
      "--- Processing N=186 ---\n",
      "  [N=186] Launching 5 parallel tasks...\n",
      "  [N=187] Best candidate score: 0.170709\n",
      "  [N=187] Baseline score: 0.372957, Candidate score: 0.170709\n",
      "  [N=187] ✓ IMPROVED over baseline: 0.372957 -> 0.170709 (Δ=0.202249, 54.23%)\n",
      "  [N=187] Cumulative Score: 2.720590 | Total Improvements: 14\n",
      "\n",
      "--- Processing N=186 ---\n",
      "  [N=186] Launching 5 parallel tasks...\n",
      "  [N=186] Best candidate score: 0.171626\n",
      "  [N=186] Baseline score: 0.373822, Candidate score: 0.171626\n",
      "  [N=186] ✓ IMPROVED over baseline: 0.373822 -> 0.171626 (Δ=0.202195, 54.09%)\n",
      "  [N=186] Cumulative Score: 2.892216 | Total Improvements: 15\n",
      "\n",
      "--- Processing N=185 ---\n",
      "  [N=185] Launching 5 parallel tasks...\n",
      "  [N=186] Best candidate score: 0.171626\n",
      "  [N=186] Baseline score: 0.373822, Candidate score: 0.171626\n",
      "  [N=186] ✓ IMPROVED over baseline: 0.373822 -> 0.171626 (Δ=0.202195, 54.09%)\n",
      "  [N=186] Cumulative Score: 2.892216 | Total Improvements: 15\n",
      "\n",
      "--- Processing N=185 ---\n",
      "  [N=185] Launching 5 parallel tasks...\n",
      "  [N=185] Best candidate score: 0.172554\n",
      "  [N=185] Baseline score: 0.370834, Candidate score: 0.172554\n",
      "  [N=185] ✓ IMPROVED over baseline: 0.370834 -> 0.172554 (Δ=0.198280, 53.47%)\n",
      "  [N=185] Cumulative Score: 3.064770 | Total Improvements: 16\n",
      "  [N=185] Best candidate score: 0.172554\n",
      "  [N=185] Baseline score: 0.370834, Candidate score: 0.172554\n",
      "  [N=185] ✓ IMPROVED over baseline: 0.370834 -> 0.172554 (Δ=0.198280, 53.47%)\n",
      "  [N=185] Cumulative Score: 3.064770 | Total Improvements: 16\n",
      "\n",
      "--- Processing N=184 ---\n",
      "  [N=184] Launching 5 parallel tasks...\n",
      "\n",
      "--- Processing N=184 ---\n",
      "  [N=184] Launching 5 parallel tasks...\n",
      "  [N=184] Best candidate score: 0.173492\n",
      "  [N=184] Baseline score: 0.368265, Candidate score: 0.173492\n",
      "  [N=184] ✓ IMPROVED over baseline: 0.368265 -> 0.173492 (Δ=0.194773, 52.89%)\n",
      "  [N=184] Cumulative Score: 3.238262 | Total Improvements: 17\n",
      "\n",
      "--- Processing N=183 ---\n",
      "  [N=183] Launching 5 parallel tasks...\n",
      "  [N=184] Best candidate score: 0.173492\n",
      "  [N=184] Baseline score: 0.368265, Candidate score: 0.173492\n",
      "  [N=184] ✓ IMPROVED over baseline: 0.368265 -> 0.173492 (Δ=0.194773, 52.89%)\n",
      "  [N=184] Cumulative Score: 3.238262 | Total Improvements: 17\n",
      "\n",
      "--- Processing N=183 ---\n",
      "  [N=183] Launching 5 parallel tasks...\n",
      "  [N=183] Best candidate score: 0.174440\n",
      "  [N=183] Baseline score: 0.370274, Candidate score: 0.174440\n",
      "  [N=183] ✓ IMPROVED over baseline: 0.370274 -> 0.174440 (Δ=0.195834, 52.89%)\n",
      "  [N=183] Cumulative Score: 3.412702 | Total Improvements: 18\n",
      "\n",
      "--- Processing N=182 ---\n",
      "  [N=182] Launching 5 parallel tasks...\n",
      "  [N=183] Best candidate score: 0.174440\n",
      "  [N=183] Baseline score: 0.370274, Candidate score: 0.174440\n",
      "  [N=183] ✓ IMPROVED over baseline: 0.370274 -> 0.174440 (Δ=0.195834, 52.89%)\n",
      "  [N=183] Cumulative Score: 3.412702 | Total Improvements: 18\n",
      "\n",
      "--- Processing N=182 ---\n",
      "  [N=182] Launching 5 parallel tasks...\n",
      "  [N=182] Best candidate score: 0.175398\n",
      "  [N=182] Baseline score: 0.367528, Candidate score: 0.175398\n",
      "  [N=182] ✓ IMPROVED over baseline: 0.367528 -> 0.175398 (Δ=0.192130, 52.28%)\n",
      "  [N=182] Cumulative Score: 3.588100 | Total Improvements: 19\n",
      "\n",
      "--- Processing N=181 ---\n",
      "  [N=181] Launching 5 parallel tasks...\n",
      "  [N=182] Best candidate score: 0.175398\n",
      "  [N=182] Baseline score: 0.367528, Candidate score: 0.175398\n",
      "  [N=182] ✓ IMPROVED over baseline: 0.367528 -> 0.175398 (Δ=0.192130, 52.28%)\n",
      "  [N=182] Cumulative Score: 3.588100 | Total Improvements: 19\n",
      "\n",
      "--- Processing N=181 ---\n",
      "  [N=181] Launching 5 parallel tasks...\n",
      "  [N=181] Best candidate score: 0.167127\n",
      "  [N=181] Baseline score: 0.369485, Candidate score: 0.167127\n",
      "  [N=181] ✓ IMPROVED over baseline: 0.369485 -> 0.167127 (Δ=0.202358, 54.77%)\n",
      "  [N=181] Cumulative Score: 3.755227 | Total Improvements: 20\n",
      "\n",
      "--- Processing N=180 ---\n",
      "  [N=180] Launching 10 parallel tasks...\n",
      "  [N=181] Best candidate score: 0.167127\n",
      "  [N=181] Baseline score: 0.369485, Candidate score: 0.167127\n",
      "  [N=181] ✓ IMPROVED over baseline: 0.369485 -> 0.167127 (Δ=0.202358, 54.77%)\n",
      "  [N=181] Cumulative Score: 3.755227 | Total Improvements: 20\n",
      "\n",
      "--- Processing N=180 ---\n",
      "  [N=180] Launching 10 parallel tasks...\n",
      "  [N=180] Best candidate score: 0.168056\n",
      "  [N=180] Baseline score: 0.366735, Candidate score: 0.168056\n",
      "  [N=180] ✓ IMPROVED over baseline: 0.366735 -> 0.168056 (Δ=0.198679, 54.18%)\n",
      "⚠️  Collision at N=180 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=180] Found 750 collision(s)\n",
      "  [N=180] Too many collisions - reverting to baseline\n",
      "  [N=180] Cumulative Score: 4.121962 | Total Improvements: 21\n",
      "  [N=180] Best candidate score: 0.168056\n",
      "  [N=180] Baseline score: 0.366735, Candidate score: 0.168056\n",
      "  [N=180] ✓ IMPROVED over baseline: 0.366735 -> 0.168056 (Δ=0.198679, 54.18%)\n",
      "⚠️  Collision at N=180 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=180] Found 750 collision(s)\n",
      "  [N=180] Too many collisions - reverting to baseline\n",
      "  [N=180] Cumulative Score: 4.121962 | Total Improvements: 21\n",
      "\n",
      "--- Processing N=179 ---\n",
      "\n",
      "--- Processing N=179 ---\n",
      "  [N=179] Launching 10 parallel tasks...\n",
      "  [N=179] Launching 10 parallel tasks...\n",
      "  [N=179] Best candidate score: 0.168994\n",
      "  [N=179] Baseline score: 0.368784, Candidate score: 0.168994\n",
      "  [N=179] ✓ IMPROVED over baseline: 0.368784 -> 0.168994 (Δ=0.199789, 54.18%)\n",
      "  [N=179] Cumulative Score: 4.290957 | Total Improvements: 22\n",
      "\n",
      "--- Processing N=178 ---\n",
      "  [N=178] Launching 10 parallel tasks...\n",
      "  [N=179] Best candidate score: 0.168994\n",
      "  [N=179] Baseline score: 0.368784, Candidate score: 0.168994\n",
      "  [N=179] ✓ IMPROVED over baseline: 0.368784 -> 0.168994 (Δ=0.199789, 54.18%)\n",
      "  [N=179] Cumulative Score: 4.290957 | Total Improvements: 22\n",
      "\n",
      "--- Processing N=178 ---\n",
      "  [N=178] Launching 10 parallel tasks...\n",
      "  [N=178] Best candidate score: 0.169944\n",
      "  [N=178] Baseline score: 0.370856, Candidate score: 0.169944\n",
      "  [N=178] ✓ IMPROVED over baseline: 0.370856 -> 0.169944 (Δ=0.200912, 54.18%)\n",
      "  [N=178] Cumulative Score: 4.460901 | Total Improvements: 23\n",
      "\n",
      "--- Processing N=177 ---\n",
      "  [N=177] Launching 10 parallel tasks...\n",
      "  [N=178] Best candidate score: 0.169944\n",
      "  [N=178] Baseline score: 0.370856, Candidate score: 0.169944\n",
      "  [N=178] ✓ IMPROVED over baseline: 0.370856 -> 0.169944 (Δ=0.200912, 54.18%)\n",
      "  [N=178] Cumulative Score: 4.460901 | Total Improvements: 23\n",
      "\n",
      "--- Processing N=177 ---\n",
      "  [N=177] Launching 10 parallel tasks...\n",
      "  [N=177] Best candidate score: 0.170904\n",
      "  [N=177] Baseline score: 0.368054, Candidate score: 0.170904\n",
      "  [N=177] ✓ IMPROVED over baseline: 0.368054 -> 0.170904 (Δ=0.197150, 53.57%)\n",
      "  [N=177] Cumulative Score: 4.631805 | Total Improvements: 24\n",
      "\n",
      "--- Processing N=176 ---\n",
      "  [N=176] Launching 10 parallel tasks...\n",
      "  [N=177] Best candidate score: 0.170904\n",
      "  [N=177] Baseline score: 0.368054, Candidate score: 0.170904\n",
      "  [N=177] ✓ IMPROVED over baseline: 0.368054 -> 0.170904 (Δ=0.197150, 53.57%)\n",
      "  [N=177] Cumulative Score: 4.631805 | Total Improvements: 24\n",
      "\n",
      "--- Processing N=176 ---\n",
      "  [N=176] Launching 10 parallel tasks...\n",
      "  [N=176] Best candidate score: 0.171875\n",
      "  [N=176] Baseline score: 0.368781, Candidate score: 0.171875\n",
      "  [N=176] ✓ IMPROVED over baseline: 0.368781 -> 0.171875 (Δ=0.196906, 53.39%)\n",
      "  [N=176] Cumulative Score: 4.803680 | Total Improvements: 25\n",
      "\n",
      "--- Processing N=175 ---\n",
      "  [N=175] Launching 10 parallel tasks...\n",
      "  [N=176] Best candidate score: 0.171875\n",
      "  [N=176] Baseline score: 0.368781, Candidate score: 0.171875\n",
      "  [N=176] ✓ IMPROVED over baseline: 0.368781 -> 0.171875 (Δ=0.196906, 53.39%)\n",
      "  [N=176] Cumulative Score: 4.803680 | Total Improvements: 25\n",
      "\n",
      "--- Processing N=175 ---\n",
      "  [N=175] Launching 10 parallel tasks...\n",
      "  [N=175] Best candidate score: 0.172857\n",
      "  [N=175] Baseline score: 0.370756, Candidate score: 0.172857\n",
      "  [N=175] ✓ IMPROVED over baseline: 0.370756 -> 0.172857 (Δ=0.197899, 53.38%)\n",
      "  [N=175] Cumulative Score: 4.976537 | Total Improvements: 26\n",
      "  [N=175] Best candidate score: 0.172857\n",
      "  [N=175] Baseline score: 0.370756, Candidate score: 0.172857\n",
      "  [N=175] ✓ IMPROVED over baseline: 0.370756 -> 0.172857 (Δ=0.197899, 53.38%)\n",
      "  [N=175] Cumulative Score: 4.976537 | Total Improvements: 26\n",
      "\n",
      "--- Processing N=174 ---\n",
      "  [N=174] Launching 10 parallel tasks...\n",
      "\n",
      "--- Processing N=174 ---\n",
      "  [N=174] Launching 10 parallel tasks...\n",
      "  [N=174] Best candidate score: 0.173851\n",
      "  [N=174] Baseline score: 0.368262, Candidate score: 0.173851\n",
      "  [N=174] ✓ IMPROVED over baseline: 0.368262 -> 0.173851 (Δ=0.194412, 52.79%)\n",
      "  [N=174] Cumulative Score: 5.150387 | Total Improvements: 27\n",
      "\n",
      "--- Processing N=173 ---\n",
      "  [N=173] Launching 10 parallel tasks...\n",
      "  [N=174] Best candidate score: 0.173851\n",
      "  [N=174] Baseline score: 0.368262, Candidate score: 0.173851\n",
      "  [N=174] ✓ IMPROVED over baseline: 0.368262 -> 0.173851 (Δ=0.194412, 52.79%)\n",
      "  [N=174] Cumulative Score: 5.150387 | Total Improvements: 27\n",
      "\n",
      "--- Processing N=173 ---\n",
      "  [N=173] Launching 10 parallel tasks...\n",
      "  [N=173] Best candidate score: 0.174855\n",
      "  [N=173] Baseline score: 0.369976, Candidate score: 0.174855\n",
      "  [N=173] ✓ IMPROVED over baseline: 0.369976 -> 0.174855 (Δ=0.195120, 52.74%)\n",
      "  [N=173] Cumulative Score: 5.325243 | Total Improvements: 28\n",
      "\n",
      "--- Processing N=172 ---\n",
      "  [N=172] Launching 10 parallel tasks...\n",
      "  [N=173] Best candidate score: 0.174855\n",
      "  [N=173] Baseline score: 0.369976, Candidate score: 0.174855\n",
      "  [N=173] ✓ IMPROVED over baseline: 0.369976 -> 0.174855 (Δ=0.195120, 52.74%)\n",
      "  [N=173] Cumulative Score: 5.325243 | Total Improvements: 28\n",
      "\n",
      "--- Processing N=172 ---\n",
      "  [N=172] Launching 10 parallel tasks...\n",
      "  [N=172] Best candidate score: 0.175872\n",
      "  [N=172] Baseline score: 0.371947, Candidate score: 0.175872\n",
      "  [N=172] ✓ IMPROVED over baseline: 0.371947 -> 0.175872 (Δ=0.196075, 52.72%)\n",
      "  [N=172] Cumulative Score: 5.501115 | Total Improvements: 29\n",
      "\n",
      "--- Processing N=171 ---\n",
      "  [N=171] Launching 10 parallel tasks...\n",
      "  [N=172] Best candidate score: 0.175872\n",
      "  [N=172] Baseline score: 0.371947, Candidate score: 0.175872\n",
      "  [N=172] ✓ IMPROVED over baseline: 0.371947 -> 0.175872 (Δ=0.196075, 52.72%)\n",
      "  [N=172] Cumulative Score: 5.501115 | Total Improvements: 29\n",
      "\n",
      "--- Processing N=171 ---\n",
      "  [N=171] Launching 10 parallel tasks...\n",
      "  [N=171] Best candidate score: 0.176901\n",
      "  [N=171] Baseline score: 0.373556, Candidate score: 0.176901\n",
      "  [N=171] ✓ IMPROVED over baseline: 0.373556 -> 0.176901 (Δ=0.196655, 52.64%)\n",
      "  [N=171] Cumulative Score: 5.678016 | Total Improvements: 30\n",
      "\n",
      "--- Processing N=170 ---\n",
      "  [N=170] Launching 10 parallel tasks...\n",
      "  [N=171] Best candidate score: 0.176901\n",
      "  [N=171] Baseline score: 0.373556, Candidate score: 0.176901\n",
      "  [N=171] ✓ IMPROVED over baseline: 0.373556 -> 0.176901 (Δ=0.196655, 52.64%)\n",
      "  [N=171] Cumulative Score: 5.678016 | Total Improvements: 30\n",
      "\n",
      "--- Processing N=170 ---\n",
      "  [N=170] Launching 10 parallel tasks...\n",
      "  [N=170] Best candidate score: 0.177941\n",
      "  [N=170] Baseline score: 0.366368, Candidate score: 0.177941\n",
      "  [N=170] ✓ IMPROVED over baseline: 0.366368 -> 0.177941 (Δ=0.188427, 51.43%)\n",
      "⚠️  Collision at N=170 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=170] Found 720 collision(s)\n",
      "  [N=170] Too many collisions - reverting to baseline\n",
      "  [N=170] Cumulative Score: 6.044384 | Total Improvements: 31\n",
      "  [N=170] Best candidate score: 0.177941\n",
      "  [N=170] Baseline score: 0.366368, Candidate score: 0.177941\n",
      "  [N=170] ✓ IMPROVED over baseline: 0.366368 -> 0.177941 (Δ=0.188427, 51.43%)\n",
      "⚠️  Collision at N=170 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=170] Found 720 collision(s)\n",
      "  [N=170] Too many collisions - reverting to baseline\n",
      "  [N=170] Cumulative Score: 6.044384 | Total Improvements: 31\n",
      "\n",
      "--- Processing N=169 ---\n",
      "\n",
      "--- Processing N=169 ---\n",
      "  [N=169] Launching 10 parallel tasks...\n",
      "  [N=169] Launching 10 parallel tasks...\n",
      "  [N=169] Best candidate score: 0.178994\n",
      "  [N=169] Baseline score: 0.366929, Candidate score: 0.178994\n",
      "  [N=169] ✓ IMPROVED over baseline: 0.366929 -> 0.178994 (Δ=0.187935, 51.22%)\n",
      "  [N=169] Cumulative Score: 6.223378 | Total Improvements: 32\n",
      "\n",
      "--- Processing N=168 ---\n",
      "  [N=168] Launching 10 parallel tasks...\n",
      "  [N=169] Best candidate score: 0.178994\n",
      "  [N=169] Baseline score: 0.366929, Candidate score: 0.178994\n",
      "  [N=169] ✓ IMPROVED over baseline: 0.366929 -> 0.178994 (Δ=0.187935, 51.22%)\n",
      "  [N=169] Cumulative Score: 6.223378 | Total Improvements: 32\n",
      "\n",
      "--- Processing N=168 ---\n",
      "  [N=168] Launching 10 parallel tasks...\n",
      "  [N=168] Best candidate score: 0.180060\n",
      "  [N=168] Baseline score: 0.369102, Candidate score: 0.180060\n",
      "  [N=168] ✓ IMPROVED over baseline: 0.369102 -> 0.180060 (Δ=0.189043, 51.22%)\n",
      "  [N=168] Cumulative Score: 6.403438 | Total Improvements: 33\n",
      "\n",
      "--- Processing N=167 ---\n",
      "  [N=167] Launching 10 parallel tasks...\n",
      "  [N=168] Best candidate score: 0.180060\n",
      "  [N=168] Baseline score: 0.369102, Candidate score: 0.180060\n",
      "  [N=168] ✓ IMPROVED over baseline: 0.369102 -> 0.180060 (Δ=0.189043, 51.22%)\n",
      "  [N=168] Cumulative Score: 6.403438 | Total Improvements: 33\n",
      "\n",
      "--- Processing N=167 ---\n",
      "  [N=167] Launching 10 parallel tasks...\n",
      "  [N=167] Best candidate score: 0.181138\n",
      "  [N=167] Baseline score: 0.368311, Candidate score: 0.181138\n",
      "  [N=167] ✓ IMPROVED over baseline: 0.368311 -> 0.181138 (Δ=0.187173, 50.82%)\n",
      "  [N=167] Cumulative Score: 6.584575 | Total Improvements: 34\n",
      "\n",
      "--- Processing N=166 ---\n",
      "  [N=166] Launching 10 parallel tasks...\n",
      "  [N=167] Best candidate score: 0.181138\n",
      "  [N=167] Baseline score: 0.368311, Candidate score: 0.181138\n",
      "  [N=167] ✓ IMPROVED over baseline: 0.368311 -> 0.181138 (Δ=0.187173, 50.82%)\n",
      "  [N=167] Cumulative Score: 6.584575 | Total Improvements: 34\n",
      "\n",
      "--- Processing N=166 ---\n",
      "  [N=166] Launching 10 parallel tasks...\n",
      "  [N=166] Best candidate score: 0.182229\n",
      "  [N=166] Baseline score: 0.366886, Candidate score: 0.182229\n",
      "  [N=166] ✓ IMPROVED over baseline: 0.366886 -> 0.182229 (Δ=0.184657, 50.33%)\n",
      "  [N=166] Cumulative Score: 6.766804 | Total Improvements: 35\n",
      "\n",
      "--- Processing N=165 ---\n",
      "  [N=165] Launching 10 parallel tasks...\n",
      "  [N=166] Best candidate score: 0.182229\n",
      "  [N=166] Baseline score: 0.366886, Candidate score: 0.182229\n",
      "  [N=166] ✓ IMPROVED over baseline: 0.366886 -> 0.182229 (Δ=0.184657, 50.33%)\n",
      "  [N=166] Cumulative Score: 6.766804 | Total Improvements: 35\n",
      "\n",
      "--- Processing N=165 ---\n",
      "  [N=165] Launching 10 parallel tasks...\n",
      "  [N=165] Best candidate score: 0.183333\n",
      "  [N=165] Baseline score: 0.369094, Candidate score: 0.183333\n",
      "  [N=165] ✓ IMPROVED over baseline: 0.369094 -> 0.183333 (Δ=0.185760, 50.33%)\n",
      "  [N=165] Cumulative Score: 6.950138 | Total Improvements: 36\n",
      "  [N=165] Best candidate score: 0.183333\n",
      "  [N=165] Baseline score: 0.369094, Candidate score: 0.183333\n",
      "  [N=165] ✓ IMPROVED over baseline: 0.369094 -> 0.183333 (Δ=0.185760, 50.33%)\n",
      "  [N=165] Cumulative Score: 6.950138 | Total Improvements: 36\n",
      "\n",
      "--- Processing N=164 ---\n",
      "  [N=164] Launching 10 parallel tasks...\n",
      "\n",
      "--- Processing N=164 ---\n",
      "  [N=164] Launching 10 parallel tasks...\n",
      "  [N=164] Best candidate score: 0.157046\n",
      "  [N=164] Baseline score: 0.366244, Candidate score: 0.157046\n",
      "  [N=164] ✓ IMPROVED over baseline: 0.366244 -> 0.157046 (Δ=0.209198, 57.12%)\n",
      "  [N=164] Cumulative Score: 7.107184 | Total Improvements: 37\n",
      "\n",
      "--- Processing N=163 ---\n",
      "  [N=163] Launching 15 parallel tasks...\n",
      "  [N=164] Best candidate score: 0.157046\n",
      "  [N=164] Baseline score: 0.366244, Candidate score: 0.157046\n",
      "  [N=164] ✓ IMPROVED over baseline: 0.366244 -> 0.157046 (Δ=0.209198, 57.12%)\n",
      "  [N=164] Cumulative Score: 7.107184 | Total Improvements: 37\n",
      "\n",
      "--- Processing N=163 ---\n",
      "  [N=163] Launching 15 parallel tasks...\n",
      "  [N=163] Best candidate score: 0.158010\n",
      "  [N=163] Baseline score: 0.368356, Candidate score: 0.158010\n",
      "  [N=163] ✓ IMPROVED over baseline: 0.368356 -> 0.158010 (Δ=0.210346, 57.10%)\n",
      "  [N=163] Cumulative Score: 7.265194 | Total Improvements: 38\n",
      "\n",
      "--- Processing N=162 ---\n",
      "  [N=162] Launching 15 parallel tasks...\n",
      "  [N=163] Best candidate score: 0.158010\n",
      "  [N=163] Baseline score: 0.368356, Candidate score: 0.158010\n",
      "  [N=163] ✓ IMPROVED over baseline: 0.368356 -> 0.158010 (Δ=0.210346, 57.10%)\n",
      "  [N=163] Cumulative Score: 7.265194 | Total Improvements: 38\n",
      "\n",
      "--- Processing N=162 ---\n",
      "  [N=162] Launching 15 parallel tasks...\n",
      "  [N=162] Best candidate score: 0.158985\n",
      "  [N=162] Baseline score: 0.367133, Candidate score: 0.158985\n",
      "  [N=162] ✓ IMPROVED over baseline: 0.367133 -> 0.158985 (Δ=0.208148, 56.70%)\n",
      "  [N=162] Cumulative Score: 7.424179 | Total Improvements: 39\n",
      "\n",
      "--- Processing N=161 ---\n",
      "  [N=161] Launching 15 parallel tasks...\n",
      "  [N=162] Best candidate score: 0.158985\n",
      "  [N=162] Baseline score: 0.367133, Candidate score: 0.158985\n",
      "  [N=162] ✓ IMPROVED over baseline: 0.367133 -> 0.158985 (Δ=0.208148, 56.70%)\n",
      "  [N=162] Cumulative Score: 7.424179 | Total Improvements: 39\n",
      "\n",
      "--- Processing N=161 ---\n",
      "  [N=161] Launching 15 parallel tasks...\n",
      "  [N=161] Best candidate score: 0.159973\n",
      "  [N=161] Baseline score: 0.369414, Candidate score: 0.159973\n",
      "  [N=161] ✓ IMPROVED over baseline: 0.369414 -> 0.159973 (Δ=0.209441, 56.70%)\n",
      "  [N=161] Cumulative Score: 7.584152 | Total Improvements: 40\n",
      "\n",
      "--- Processing N=160 ---\n",
      "  [N=160] Launching 15 parallel tasks...\n",
      "  [N=161] Best candidate score: 0.159973\n",
      "  [N=161] Baseline score: 0.369414, Candidate score: 0.159973\n",
      "  [N=161] ✓ IMPROVED over baseline: 0.369414 -> 0.159973 (Δ=0.209441, 56.70%)\n",
      "  [N=161] Cumulative Score: 7.584152 | Total Improvements: 40\n",
      "\n",
      "--- Processing N=160 ---\n",
      "  [N=160] Launching 15 parallel tasks...\n",
      "  [N=160] Best candidate score: 0.160973\n",
      "  [N=160] Baseline score: 0.367976, Candidate score: 0.160973\n",
      "  [N=160] ✓ IMPROVED over baseline: 0.367976 -> 0.160973 (Δ=0.207003, 56.25%)\n",
      "⚠️  Collision at N=160 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=160] Found 682 collision(s)\n",
      "  [N=160] Too many collisions - reverting to baseline\n",
      "  [N=160] Cumulative Score: 7.952128 | Total Improvements: 41\n",
      "  [N=160] Best candidate score: 0.160973\n",
      "  [N=160] Baseline score: 0.367976, Candidate score: 0.160973\n",
      "  [N=160] ✓ IMPROVED over baseline: 0.367976 -> 0.160973 (Δ=0.207003, 56.25%)\n",
      "⚠️  Collision at N=160 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=160] Found 682 collision(s)\n",
      "  [N=160] Too many collisions - reverting to baseline\n",
      "  [N=160] Cumulative Score: 7.952128 | Total Improvements: 41\n",
      "\n",
      "--- Processing N=159 ---\n",
      "\n",
      "--- Processing N=159 ---\n",
      "  [N=159] Launching 15 parallel tasks...\n",
      "  [N=159] Launching 15 parallel tasks...\n",
      "  [N=159] Best candidate score: 0.161985\n",
      "  [N=159] Baseline score: 0.370130, Candidate score: 0.161985\n",
      "  [N=159] ✓ IMPROVED over baseline: 0.370130 -> 0.161985 (Δ=0.208145, 56.24%)\n",
      "  [N=159] Cumulative Score: 8.114113 | Total Improvements: 42\n",
      "\n",
      "--- Processing N=158 ---\n",
      "  [N=158] Launching 15 parallel tasks...\n",
      "  [N=159] Best candidate score: 0.161985\n",
      "  [N=159] Baseline score: 0.370130, Candidate score: 0.161985\n",
      "  [N=159] ✓ IMPROVED over baseline: 0.370130 -> 0.161985 (Δ=0.208145, 56.24%)\n",
      "  [N=159] Cumulative Score: 8.114113 | Total Improvements: 42\n",
      "\n",
      "--- Processing N=158 ---\n",
      "  [N=158] Launching 15 parallel tasks...\n",
      "  [N=158] Best candidate score: 0.163010\n",
      "  [N=158] Baseline score: 0.368423, Candidate score: 0.163010\n",
      "  [N=158] ✓ IMPROVED over baseline: 0.368423 -> 0.163010 (Δ=0.205412, 55.75%)\n",
      "  [N=158] Cumulative Score: 8.277123 | Total Improvements: 43\n",
      "\n",
      "--- Processing N=157 ---\n",
      "  [N=157] Launching 15 parallel tasks...\n",
      "  [N=158] Best candidate score: 0.163010\n",
      "  [N=158] Baseline score: 0.368423, Candidate score: 0.163010\n",
      "  [N=158] ✓ IMPROVED over baseline: 0.368423 -> 0.163010 (Δ=0.205412, 55.75%)\n",
      "  [N=158] Cumulative Score: 8.277123 | Total Improvements: 43\n",
      "\n",
      "--- Processing N=157 ---\n",
      "  [N=157] Launching 15 parallel tasks...\n",
      "  [N=157] Best candidate score: 0.164049\n",
      "  [N=157] Baseline score: 0.370599, Candidate score: 0.164049\n",
      "  [N=157] ✓ IMPROVED over baseline: 0.370599 -> 0.164049 (Δ=0.206551, 55.73%)\n",
      "  [N=157] Cumulative Score: 8.441172 | Total Improvements: 44\n",
      "\n",
      "--- Processing N=156 ---\n",
      "  [N=156] Launching 15 parallel tasks...\n",
      "  [N=157] Best candidate score: 0.164049\n",
      "  [N=157] Baseline score: 0.370599, Candidate score: 0.164049\n",
      "  [N=157] ✓ IMPROVED over baseline: 0.370599 -> 0.164049 (Δ=0.206551, 55.73%)\n",
      "  [N=157] Cumulative Score: 8.441172 | Total Improvements: 44\n",
      "\n",
      "--- Processing N=156 ---\n",
      "  [N=156] Launching 15 parallel tasks...\n",
      "  [N=156] Best candidate score: 0.157067\n",
      "  [N=156] Baseline score: 0.363657, Candidate score: 0.157067\n",
      "  [N=156] ✓ IMPROVED over baseline: 0.363657 -> 0.157067 (Δ=0.206590, 56.81%)\n",
      "  [N=156] Cumulative Score: 8.598239 | Total Improvements: 45\n",
      "\n",
      "--- Processing N=155 ---\n",
      "  [N=155] Launching 20 parallel tasks...\n",
      "  [N=156] Best candidate score: 0.157067\n",
      "  [N=156] Baseline score: 0.363657, Candidate score: 0.157067\n",
      "  [N=156] ✓ IMPROVED over baseline: 0.363657 -> 0.157067 (Δ=0.206590, 56.81%)\n",
      "  [N=156] Cumulative Score: 8.598239 | Total Improvements: 45\n",
      "\n",
      "--- Processing N=155 ---\n",
      "  [N=155] Launching 20 parallel tasks...\n",
      "  [N=155] Best candidate score: 0.158081\n",
      "  [N=155] Baseline score: 0.366003, Candidate score: 0.158081\n",
      "  [N=155] ✓ IMPROVED over baseline: 0.366003 -> 0.158081 (Δ=0.207923, 56.81%)\n",
      "  [N=155] Cumulative Score: 8.756320 | Total Improvements: 46\n",
      "  [N=155] Best candidate score: 0.158081\n",
      "  [N=155] Baseline score: 0.366003, Candidate score: 0.158081\n",
      "  [N=155] ✓ IMPROVED over baseline: 0.366003 -> 0.158081 (Δ=0.207923, 56.81%)\n",
      "  [N=155] Cumulative Score: 8.756320 | Total Improvements: 46\n",
      "\n",
      "--- Processing N=154 ---\n",
      "\n",
      "--- Processing N=154 ---\n",
      "  [N=154] Launching 20 parallel tasks...\n",
      "  [N=154] Launching 20 parallel tasks...\n",
      "  [N=154] Best candidate score: 0.159107\n",
      "  [N=154] Baseline score: 0.368380, Candidate score: 0.159107\n",
      "  [N=154] ✓ IMPROVED over baseline: 0.368380 -> 0.159107 (Δ=0.209273, 56.81%)\n",
      "  [N=154] Cumulative Score: 8.915427 | Total Improvements: 47\n",
      "\n",
      "--- Processing N=153 ---\n",
      "  [N=153] Launching 20 parallel tasks...\n",
      "  [N=154] Best candidate score: 0.159107\n",
      "  [N=154] Baseline score: 0.368380, Candidate score: 0.159107\n",
      "  [N=154] ✓ IMPROVED over baseline: 0.368380 -> 0.159107 (Δ=0.209273, 56.81%)\n",
      "  [N=154] Cumulative Score: 8.915427 | Total Improvements: 47\n",
      "\n",
      "--- Processing N=153 ---\n",
      "  [N=153] Launching 20 parallel tasks...\n",
      "  [N=153] Best candidate score: 0.160147\n",
      "  [N=153] Baseline score: 0.367571, Candidate score: 0.160147\n",
      "  [N=153] ✓ IMPROVED over baseline: 0.367571 -> 0.160147 (Δ=0.207424, 56.43%)\n",
      "  [N=153] Cumulative Score: 9.075574 | Total Improvements: 48\n",
      "\n",
      "--- Processing N=152 ---\n",
      "  [N=152] Launching 20 parallel tasks...\n",
      "  [N=153] Best candidate score: 0.160147\n",
      "  [N=153] Baseline score: 0.367571, Candidate score: 0.160147\n",
      "  [N=153] ✓ IMPROVED over baseline: 0.367571 -> 0.160147 (Δ=0.207424, 56.43%)\n",
      "  [N=153] Cumulative Score: 9.075574 | Total Improvements: 48\n",
      "\n",
      "--- Processing N=152 ---\n",
      "  [N=152] Launching 20 parallel tasks...\n",
      "  [N=152] Best candidate score: 0.161201\n",
      "  [N=152] Baseline score: 0.369989, Candidate score: 0.161201\n",
      "  [N=152] ✓ IMPROVED over baseline: 0.369989 -> 0.161201 (Δ=0.208788, 56.43%)\n",
      "  [N=152] Cumulative Score: 9.236775 | Total Improvements: 49\n",
      "\n",
      "--- Processing N=151 ---\n",
      "  [N=151] Launching 20 parallel tasks...\n",
      "  [N=152] Best candidate score: 0.161201\n",
      "  [N=152] Baseline score: 0.369989, Candidate score: 0.161201\n",
      "  [N=152] ✓ IMPROVED over baseline: 0.369989 -> 0.161201 (Δ=0.208788, 56.43%)\n",
      "  [N=152] Cumulative Score: 9.236775 | Total Improvements: 49\n",
      "\n",
      "--- Processing N=151 ---\n",
      "  [N=151] Launching 20 parallel tasks...\n",
      "  [N=151] Best candidate score: 0.154176\n",
      "  [N=151] Baseline score: 0.368178, Candidate score: 0.154176\n",
      "  [N=151] ✓ IMPROVED over baseline: 0.368178 -> 0.154176 (Δ=0.214001, 58.12%)\n",
      "  [N=151] Cumulative Score: 9.390951 | Total Improvements: 50\n",
      "\n",
      "--- Processing N=150 ---\n",
      "  [N=150] Launching 25 parallel tasks...\n",
      "  [N=151] Best candidate score: 0.154176\n",
      "  [N=151] Baseline score: 0.368178, Candidate score: 0.154176\n",
      "  [N=151] ✓ IMPROVED over baseline: 0.368178 -> 0.154176 (Δ=0.214001, 58.12%)\n",
      "  [N=151] Cumulative Score: 9.390951 | Total Improvements: 50\n",
      "\n",
      "--- Processing N=150 ---\n",
      "  [N=150] Launching 25 parallel tasks...\n",
      "  [N=150] Best candidate score: 0.155204\n",
      "  [N=150] Baseline score: 0.368752, Candidate score: 0.155204\n",
      "  [N=150] ✓ IMPROVED over baseline: 0.368752 -> 0.155204 (Δ=0.213548, 57.91%)\n",
      "⚠️  Collision at N=150 between trees 0 and 16 (overlap area=1.182419e-01)\n",
      "  [N=150] Found 637 collision(s)\n",
      "  [N=150] Too many collisions - reverting to baseline\n",
      "  [N=150] Cumulative Score: 9.759703 | Total Improvements: 51\n",
      "  [N=150] Best candidate score: 0.155204\n",
      "  [N=150] Baseline score: 0.368752, Candidate score: 0.155204\n",
      "  [N=150] ✓ IMPROVED over baseline: 0.368752 -> 0.155204 (Δ=0.213548, 57.91%)\n",
      "⚠️  Collision at N=150 between trees 0 and 16 (overlap area=1.182419e-01)\n",
      "  [N=150] Found 637 collision(s)\n",
      "  [N=150] Too many collisions - reverting to baseline\n",
      "  [N=150] Cumulative Score: 9.759703 | Total Improvements: 51\n",
      "\n",
      "--- Processing N=149 ---\n",
      "\n",
      "--- Processing N=149 ---\n",
      "  [N=149] Launching 25 parallel tasks...\n",
      "  [N=149] Launching 25 parallel tasks...\n",
      "  [N=149] Best candidate score: 0.156246\n",
      "  [N=149] Baseline score: 0.371103, Candidate score: 0.156246\n",
      "  [N=149] ✓ IMPROVED over baseline: 0.371103 -> 0.156246 (Δ=0.214857, 57.90%)\n",
      "  [N=149] Cumulative Score: 9.915949 | Total Improvements: 52\n",
      "\n",
      "--- Processing N=148 ---\n",
      "  [N=148] Launching 45 parallel tasks...\n",
      "  [N=149] Best candidate score: 0.156246\n",
      "  [N=149] Baseline score: 0.371103, Candidate score: 0.156246\n",
      "  [N=149] ✓ IMPROVED over baseline: 0.371103 -> 0.156246 (Δ=0.214857, 57.90%)\n",
      "  [N=149] Cumulative Score: 9.915949 | Total Improvements: 52\n",
      "\n",
      "--- Processing N=148 ---\n",
      "  [N=148] Launching 45 parallel tasks...\n",
      "  [N=148] Best candidate score: 0.157302\n",
      "  [N=148] Baseline score: 0.367241, Candidate score: 0.157302\n",
      "  [N=148] ✓ IMPROVED over baseline: 0.367241 -> 0.157302 (Δ=0.209940, 57.17%)\n",
      "  [N=148] Cumulative Score: 10.073251 | Total Improvements: 53\n",
      "\n",
      "--- Processing N=147 ---\n",
      "  [N=148] Best candidate score: 0.157302\n",
      "  [N=148] Baseline score: 0.367241, Candidate score: 0.157302\n",
      "  [N=148] ✓ IMPROVED over baseline: 0.367241 -> 0.157302 (Δ=0.209940, 57.17%)\n",
      "  [N=148] Cumulative Score: 10.073251 | Total Improvements: 53\n",
      "\n",
      "--- Processing N=147 ---\n",
      "  [N=147] Launching 60 parallel tasks...\n",
      "  [N=147] Launching 60 parallel tasks...\n",
      "  [N=147] Best candidate score: 0.158372\n",
      "  [N=147] Baseline score: 0.368257, Candidate score: 0.158372\n",
      "  [N=147] ✓ IMPROVED over baseline: 0.368257 -> 0.158372 (Δ=0.209885, 56.99%)\n",
      "  [N=147] Cumulative Score: 10.231622 | Total Improvements: 54\n",
      "\n",
      "--- Processing N=146 ---\n",
      "  [N=147] Best candidate score: 0.158372\n",
      "  [N=147] Baseline score: 0.368257, Candidate score: 0.158372\n",
      "  [N=147] ✓ IMPROVED over baseline: 0.368257 -> 0.158372 (Δ=0.209885, 56.99%)\n",
      "  [N=147] Cumulative Score: 10.231622 | Total Improvements: 54\n",
      "\n",
      "--- Processing N=146 ---\n",
      "  [N=146] Launching 60 parallel tasks...\n",
      "  [N=146] Launching 60 parallel tasks...\n",
      "  [N=146] Best candidate score: 0.159456\n",
      "  [N=146] Baseline score: 0.369450, Candidate score: 0.159456\n",
      "  [N=146] ✓ IMPROVED over baseline: 0.369450 -> 0.159456 (Δ=0.209993, 56.84%)\n",
      "  [N=146] Cumulative Score: 10.391079 | Total Improvements: 55\n",
      "\n",
      "--- Processing N=145 ---\n",
      "  [N=146] Best candidate score: 0.159456\n",
      "  [N=146] Baseline score: 0.369450, Candidate score: 0.159456\n",
      "  [N=146] ✓ IMPROVED over baseline: 0.369450 -> 0.159456 (Δ=0.209993, 56.84%)\n",
      "  [N=146] Cumulative Score: 10.391079 | Total Improvements: 55\n",
      "\n",
      "--- Processing N=145 ---\n",
      "  [N=145] Launching 60 parallel tasks...\n",
      "  [N=145] Launching 60 parallel tasks...\n",
      "  [N=145] Best candidate score: 0.160556\n",
      "  [N=145] Baseline score: 0.367660, Candidate score: 0.160556\n",
      "  [N=145] ✓ IMPROVED over baseline: 0.367660 -> 0.160556 (Δ=0.207104, 56.33%)\n",
      "  [N=145] Cumulative Score: 10.551635 | Total Improvements: 56\n",
      "  [N=145] Best candidate score: 0.160556\n",
      "  [N=145] Baseline score: 0.367660, Candidate score: 0.160556\n",
      "  [N=145] ✓ IMPROVED over baseline: 0.367660 -> 0.160556 (Δ=0.207104, 56.33%)\n",
      "  [N=145] Cumulative Score: 10.551635 | Total Improvements: 56\n",
      "\n",
      "--- Processing N=144 ---\n",
      "\n",
      "--- Processing N=144 ---\n",
      "  [N=144] Launching 60 parallel tasks...\n",
      "  [N=144] Launching 60 parallel tasks...\n",
      "  [N=144] Best candidate score: 0.161671\n",
      "  [N=144] Baseline score: 0.365276, Candidate score: 0.161671\n",
      "  [N=144] ✓ IMPROVED over baseline: 0.365276 -> 0.161671 (Δ=0.203605, 55.74%)\n",
      "  [N=144] Cumulative Score: 10.713306 | Total Improvements: 57\n",
      "\n",
      "--- Processing N=143 ---\n",
      "  [N=144] Best candidate score: 0.161671\n",
      "  [N=144] Baseline score: 0.365276, Candidate score: 0.161671\n",
      "  [N=144] ✓ IMPROVED over baseline: 0.365276 -> 0.161671 (Δ=0.203605, 55.74%)\n",
      "  [N=144] Cumulative Score: 10.713306 | Total Improvements: 57\n",
      "\n",
      "--- Processing N=143 ---\n",
      "  [N=143] Launching 60 parallel tasks...\n",
      "  [N=143] Launching 60 parallel tasks...\n",
      "  [N=143] Best candidate score: 0.162802\n",
      "  [N=143] Baseline score: 0.367831, Candidate score: 0.162802\n",
      "  [N=143] ✓ IMPROVED over baseline: 0.367831 -> 0.162802 (Δ=0.205029, 55.74%)\n",
      "  [N=143] Cumulative Score: 10.876107 | Total Improvements: 58\n",
      "\n",
      "--- Processing N=142 ---\n",
      "  [N=143] Best candidate score: 0.162802\n",
      "  [N=143] Baseline score: 0.367831, Candidate score: 0.162802\n",
      "  [N=143] ✓ IMPROVED over baseline: 0.367831 -> 0.162802 (Δ=0.205029, 55.74%)\n",
      "  [N=143] Cumulative Score: 10.876107 | Total Improvements: 58\n",
      "\n",
      "--- Processing N=142 ---\n",
      "  [N=142] Launching 60 parallel tasks...\n",
      "  [N=142] Launching 60 parallel tasks...\n",
      "  [N=142] Best candidate score: 0.163948\n",
      "  [N=142] Baseline score: 0.368807, Candidate score: 0.163948\n",
      "  [N=142] ✓ IMPROVED over baseline: 0.368807 -> 0.163948 (Δ=0.204859, 55.55%)\n",
      "  [N=142] Cumulative Score: 11.040055 | Total Improvements: 59\n",
      "\n",
      "--- Processing N=141 ---\n",
      "  [N=142] Best candidate score: 0.163948\n",
      "  [N=142] Baseline score: 0.368807, Candidate score: 0.163948\n",
      "  [N=142] ✓ IMPROVED over baseline: 0.368807 -> 0.163948 (Δ=0.204859, 55.55%)\n",
      "  [N=142] Cumulative Score: 11.040055 | Total Improvements: 59\n",
      "\n",
      "--- Processing N=141 ---\n",
      "  [N=141] Launching 60 parallel tasks...\n",
      "  [N=141] Launching 60 parallel tasks...\n",
      "  [N=141] Best candidate score: 0.165111\n",
      "  [N=141] Baseline score: 0.371422, Candidate score: 0.165111\n",
      "  [N=141] ✓ IMPROVED over baseline: 0.371422 -> 0.165111 (Δ=0.206311, 55.55%)\n",
      "  [N=141] Cumulative Score: 11.205166 | Total Improvements: 60\n",
      "\n",
      "--- Processing N=140 ---\n",
      "  [N=141] Best candidate score: 0.165111\n",
      "  [N=141] Baseline score: 0.371422, Candidate score: 0.165111\n",
      "  [N=141] ✓ IMPROVED over baseline: 0.371422 -> 0.165111 (Δ=0.206311, 55.55%)\n",
      "  [N=141] Cumulative Score: 11.205166 | Total Improvements: 60\n",
      "\n",
      "--- Processing N=140 ---\n",
      "  [N=140] Launching 60 parallel tasks...\n",
      "  [N=140] Launching 60 parallel tasks...\n",
      "  [N=140] Best candidate score: 0.166290\n",
      "  [N=140] Baseline score: 0.369140, Candidate score: 0.166290\n",
      "  [N=140] ✓ IMPROVED over baseline: 0.369140 -> 0.166290 (Δ=0.202850, 54.95%)\n",
      "⚠️  Collision at N=140 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=140] Found 568 collision(s)\n",
      "  [N=140] Too many collisions - reverting to baseline\n",
      "  [N=140] Cumulative Score: 11.574307 | Total Improvements: 61\n",
      "  [N=140] Best candidate score: 0.166290\n",
      "  [N=140] Baseline score: 0.369140, Candidate score: 0.166290\n",
      "  [N=140] ✓ IMPROVED over baseline: 0.369140 -> 0.166290 (Δ=0.202850, 54.95%)\n",
      "⚠️  Collision at N=140 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=140] Found 568 collision(s)\n",
      "  [N=140] Too many collisions - reverting to baseline\n",
      "  [N=140] Cumulative Score: 11.574307 | Total Improvements: 61\n",
      "\n",
      "--- Processing N=139 ---\n",
      "\n",
      "--- Processing N=139 ---\n",
      "  [N=139] Launching 60 parallel tasks...\n",
      "  [N=139] Launching 60 parallel tasks...\n",
      "  [N=139] Best candidate score: 0.167487\n",
      "  [N=139] Baseline score: 0.371706, Candidate score: 0.167487\n",
      "  [N=139] ✓ IMPROVED over baseline: 0.371706 -> 0.167487 (Δ=0.204219, 54.94%)\n",
      "  [N=139] Cumulative Score: 11.741793 | Total Improvements: 62\n",
      "\n",
      "--- Processing N=138 ---\n",
      "  [N=139] Best candidate score: 0.167487\n",
      "  [N=139] Baseline score: 0.371706, Candidate score: 0.167487\n",
      "  [N=139] ✓ IMPROVED over baseline: 0.371706 -> 0.167487 (Δ=0.204219, 54.94%)\n",
      "  [N=139] Cumulative Score: 11.741793 | Total Improvements: 62\n",
      "\n",
      "--- Processing N=138 ---\n",
      "  [N=138] Launching 60 parallel tasks...\n",
      "  [N=138] Launching 60 parallel tasks...\n",
      "  [N=138] Best candidate score: 0.168700\n",
      "  [N=138] Baseline score: 0.369763, Candidate score: 0.168700\n",
      "  [N=138] ✓ IMPROVED over baseline: 0.369763 -> 0.168700 (Δ=0.201063, 54.38%)\n",
      "  [N=138] Cumulative Score: 11.910493 | Total Improvements: 63\n",
      "\n",
      "--- Processing N=137 ---\n",
      "  [N=138] Best candidate score: 0.168700\n",
      "  [N=138] Baseline score: 0.369763, Candidate score: 0.168700\n",
      "  [N=138] ✓ IMPROVED over baseline: 0.369763 -> 0.168700 (Δ=0.201063, 54.38%)\n",
      "  [N=138] Cumulative Score: 11.910493 | Total Improvements: 63\n",
      "\n",
      "--- Processing N=137 ---\n",
      "  [N=137] Launching 60 parallel tasks...\n",
      "  [N=137] Launching 60 parallel tasks...\n",
      "  [N=137] Best candidate score: 0.169932\n",
      "  [N=137] Baseline score: 0.370281, Candidate score: 0.169932\n",
      "  [N=137] ✓ IMPROVED over baseline: 0.370281 -> 0.169932 (Δ=0.200349, 54.11%)\n",
      "  [N=137] Cumulative Score: 12.080425 | Total Improvements: 64\n",
      "\n",
      "--- Processing N=136 ---\n",
      "  [N=136] Launching 60 parallel tasks...\n",
      "  [N=137] Best candidate score: 0.169932\n",
      "  [N=137] Baseline score: 0.370281, Candidate score: 0.169932\n",
      "  [N=137] ✓ IMPROVED over baseline: 0.370281 -> 0.169932 (Δ=0.200349, 54.11%)\n",
      "  [N=137] Cumulative Score: 12.080425 | Total Improvements: 64\n",
      "\n",
      "--- Processing N=136 ---\n",
      "  [N=136] Launching 60 parallel tasks...\n",
      "  [N=136] Best candidate score: 0.171181\n",
      "  [N=136] Baseline score: 0.368448, Candidate score: 0.171181\n",
      "  [N=136] ✓ IMPROVED over baseline: 0.368448 -> 0.171181 (Δ=0.197267, 53.54%)\n",
      "  [N=136] Cumulative Score: 12.251606 | Total Improvements: 65\n",
      "\n",
      "--- Processing N=135 ---\n",
      "  [N=135] Launching 60 parallel tasks...\n",
      "  [N=136] Best candidate score: 0.171181\n",
      "  [N=136] Baseline score: 0.368448, Candidate score: 0.171181\n",
      "  [N=136] ✓ IMPROVED over baseline: 0.368448 -> 0.171181 (Δ=0.197267, 53.54%)\n",
      "  [N=136] Cumulative Score: 12.251606 | Total Improvements: 65\n",
      "\n",
      "--- Processing N=135 ---\n",
      "  [N=135] Launching 60 parallel tasks...\n",
      "  [N=135] Best candidate score: 0.172449\n",
      "  [N=135] Baseline score: 0.371120, Candidate score: 0.172449\n",
      "  [N=135] ✓ IMPROVED over baseline: 0.371120 -> 0.172449 (Δ=0.198671, 53.53%)\n",
      "  [N=135] Cumulative Score: 12.424055 | Total Improvements: 66\n",
      "  [N=135] Best candidate score: 0.172449\n",
      "  [N=135] Baseline score: 0.371120, Candidate score: 0.172449\n",
      "  [N=135] ✓ IMPROVED over baseline: 0.371120 -> 0.172449 (Δ=0.198671, 53.53%)\n",
      "  [N=135] Cumulative Score: 12.424055 | Total Improvements: 66\n",
      "\n",
      "--- Processing N=134 ---\n",
      "\n",
      "--- Processing N=134 ---\n",
      "  [N=134] Launching 60 parallel tasks...\n",
      "  [N=134] Launching 60 parallel tasks...\n",
      "  [N=134] Best candidate score: 0.173736\n",
      "  [N=134] Baseline score: 0.368144, Candidate score: 0.173736\n",
      "  [N=134] ✓ IMPROVED over baseline: 0.368144 -> 0.173736 (Δ=0.194408, 52.81%)\n",
      "  [N=134] Cumulative Score: 12.597791 | Total Improvements: 67\n",
      "\n",
      "--- Processing N=133 ---\n",
      "  [N=133] Launching 60 parallel tasks...\n",
      "  [N=134] Best candidate score: 0.173736\n",
      "  [N=134] Baseline score: 0.368144, Candidate score: 0.173736\n",
      "  [N=134] ✓ IMPROVED over baseline: 0.368144 -> 0.173736 (Δ=0.194408, 52.81%)\n",
      "  [N=134] Cumulative Score: 12.597791 | Total Improvements: 67\n",
      "\n",
      "--- Processing N=133 ---\n",
      "  [N=133] Launching 60 parallel tasks...\n",
      "  [N=133] Best candidate score: 0.175042\n",
      "  [N=133] Baseline score: 0.368779, Candidate score: 0.175042\n",
      "  [N=133] ✓ IMPROVED over baseline: 0.368779 -> 0.175042 (Δ=0.193737, 52.53%)\n",
      "  [N=133] Cumulative Score: 12.772833 | Total Improvements: 68\n",
      "\n",
      "--- Processing N=132 ---\n",
      "  [N=132] Launching 60 parallel tasks...\n",
      "  [N=133] Best candidate score: 0.175042\n",
      "  [N=133] Baseline score: 0.368779, Candidate score: 0.175042\n",
      "  [N=133] ✓ IMPROVED over baseline: 0.368779 -> 0.175042 (Δ=0.193737, 52.53%)\n",
      "  [N=133] Cumulative Score: 12.772833 | Total Improvements: 68\n",
      "\n",
      "--- Processing N=132 ---\n",
      "  [N=132] Launching 60 parallel tasks...\n",
      "  [N=132] Best candidate score: 0.176368\n",
      "  [N=132] Baseline score: 0.370298, Candidate score: 0.176368\n",
      "  [N=132] ✓ IMPROVED over baseline: 0.370298 -> 0.176368 (Δ=0.193930, 52.37%)\n",
      "  [N=132] Cumulative Score: 12.949202 | Total Improvements: 69\n",
      "\n",
      "--- Processing N=131 ---\n",
      "  [N=131] Launching 60 parallel tasks...\n",
      "  [N=132] Best candidate score: 0.176368\n",
      "  [N=132] Baseline score: 0.370298, Candidate score: 0.176368\n",
      "  [N=132] ✓ IMPROVED over baseline: 0.370298 -> 0.176368 (Δ=0.193930, 52.37%)\n",
      "  [N=132] Cumulative Score: 12.949202 | Total Improvements: 69\n",
      "\n",
      "--- Processing N=131 ---\n",
      "  [N=131] Launching 60 parallel tasks...\n",
      "  [N=131] Best candidate score: 0.177715\n",
      "  [N=131] Baseline score: 0.369836, Candidate score: 0.177715\n",
      "  [N=131] ✓ IMPROVED over baseline: 0.369836 -> 0.177715 (Δ=0.192121, 51.95%)\n",
      "  [N=131] Cumulative Score: 13.126916 | Total Improvements: 70\n",
      "\n",
      "--- Processing N=130 ---\n",
      "  [N=130] Launching 60 parallel tasks...\n",
      "  [N=131] Best candidate score: 0.177715\n",
      "  [N=131] Baseline score: 0.369836, Candidate score: 0.177715\n",
      "  [N=131] ✓ IMPROVED over baseline: 0.369836 -> 0.177715 (Δ=0.192121, 51.95%)\n",
      "  [N=131] Cumulative Score: 13.126916 | Total Improvements: 70\n",
      "\n",
      "--- Processing N=130 ---\n",
      "  [N=130] Launching 60 parallel tasks...\n",
      "  [N=130] Best candidate score: 0.169588\n",
      "  [N=130] Baseline score: 0.366479, Candidate score: 0.169588\n",
      "  [N=130] ✓ IMPROVED over baseline: 0.366479 -> 0.169588 (Δ=0.196891, 53.73%)\n",
      "⚠️  Collision at N=130 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=130] Found 552 collision(s)\n",
      "  [N=130] Too many collisions - reverting to baseline\n",
      "  [N=130] Cumulative Score: 13.493395 | Total Improvements: 71\n",
      "  [N=130] Best candidate score: 0.169588\n",
      "  [N=130] Baseline score: 0.366479, Candidate score: 0.169588\n",
      "  [N=130] ✓ IMPROVED over baseline: 0.366479 -> 0.169588 (Δ=0.196891, 53.73%)\n",
      "⚠️  Collision at N=130 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=130] Found 552 collision(s)\n",
      "  [N=130] Too many collisions - reverting to baseline\n",
      "  [N=130] Cumulative Score: 13.493395 | Total Improvements: 71\n",
      "\n",
      "--- Processing N=129 ---\n",
      "\n",
      "--- Processing N=129 ---\n",
      "  [N=129] Launching 60 parallel tasks...\n",
      "  [N=129] Launching 60 parallel tasks...\n",
      "  [N=129] Best candidate score: 0.166630\n",
      "  [N=129] Baseline score: 0.369098, Candidate score: 0.166630\n",
      "  [N=129] ✓ IMPROVED over baseline: 0.369098 -> 0.166630 (Δ=0.202468, 54.85%)\n",
      "  [N=129] Cumulative Score: 13.660025 | Total Improvements: 72\n",
      "\n",
      "--- Processing N=128 ---\n",
      "  [N=128] Launching 60 parallel tasks...\n",
      "  [N=129] Best candidate score: 0.166630\n",
      "  [N=129] Baseline score: 0.369098, Candidate score: 0.166630\n",
      "  [N=129] ✓ IMPROVED over baseline: 0.369098 -> 0.166630 (Δ=0.202468, 54.85%)\n",
      "  [N=129] Cumulative Score: 13.660025 | Total Improvements: 72\n",
      "\n",
      "--- Processing N=128 ---\n",
      "  [N=128] Launching 60 parallel tasks...\n",
      "  [N=128] Best candidate score: 0.165312\n",
      "  [N=128] Baseline score: 0.367750, Candidate score: 0.165312\n",
      "  [N=128] ✓ IMPROVED over baseline: 0.367750 -> 0.165312 (Δ=0.202438, 55.05%)\n",
      "  [N=128] Cumulative Score: 13.825338 | Total Improvements: 73\n",
      "\n",
      "--- Processing N=127 ---\n",
      "  [N=127] Launching 60 parallel tasks...\n",
      "  [N=128] Best candidate score: 0.165312\n",
      "  [N=128] Baseline score: 0.367750, Candidate score: 0.165312\n",
      "  [N=128] ✓ IMPROVED over baseline: 0.367750 -> 0.165312 (Δ=0.202438, 55.05%)\n",
      "  [N=128] Cumulative Score: 13.825338 | Total Improvements: 73\n",
      "\n",
      "--- Processing N=127 ---\n",
      "  [N=127] Launching 60 parallel tasks...\n",
      "  [N=127] Best candidate score: 0.164808\n",
      "  [N=127] Baseline score: 0.369306, Candidate score: 0.164808\n",
      "  [N=127] ✓ IMPROVED over baseline: 0.369306 -> 0.164808 (Δ=0.204498, 55.37%)\n",
      "  [N=127] Cumulative Score: 13.990146 | Total Improvements: 74\n",
      "\n",
      "--- Processing N=126 ---\n",
      "  [N=126] Launching 60 parallel tasks...\n",
      "  [N=127] Best candidate score: 0.164808\n",
      "  [N=127] Baseline score: 0.369306, Candidate score: 0.164808\n",
      "  [N=127] ✓ IMPROVED over baseline: 0.369306 -> 0.164808 (Δ=0.204498, 55.37%)\n",
      "  [N=127] Cumulative Score: 13.990146 | Total Improvements: 74\n",
      "\n",
      "--- Processing N=126 ---\n",
      "  [N=126] Launching 60 parallel tasks...\n",
      "  [N=126] Best candidate score: 0.166116\n",
      "  [N=126] Baseline score: 0.370717, Candidate score: 0.166116\n",
      "  [N=126] ✓ IMPROVED over baseline: 0.370717 -> 0.166116 (Δ=0.204601, 55.19%)\n",
      "  [N=126] Cumulative Score: 14.156262 | Total Improvements: 75\n",
      "\n",
      "--- Processing N=125 ---\n",
      "  [N=125] Launching 60 parallel tasks...\n",
      "  [N=126] Best candidate score: 0.166116\n",
      "  [N=126] Baseline score: 0.370717, Candidate score: 0.166116\n",
      "  [N=126] ✓ IMPROVED over baseline: 0.370717 -> 0.166116 (Δ=0.204601, 55.19%)\n",
      "  [N=126] Cumulative Score: 14.156262 | Total Improvements: 75\n",
      "\n",
      "--- Processing N=125 ---\n",
      "  [N=125] Launching 60 parallel tasks...\n",
      "  [N=125] Best candidate score: 0.167445\n",
      "  [N=125] Baseline score: 0.370606, Candidate score: 0.167445\n",
      "  [N=125] ✓ IMPROVED over baseline: 0.370606 -> 0.167445 (Δ=0.203161, 54.82%)\n",
      "  [N=125] Cumulative Score: 14.323707 | Total Improvements: 76\n",
      "  [N=125] Best candidate score: 0.167445\n",
      "  [N=125] Baseline score: 0.370606, Candidate score: 0.167445\n",
      "  [N=125] ✓ IMPROVED over baseline: 0.370606 -> 0.167445 (Δ=0.203161, 54.82%)\n",
      "  [N=125] Cumulative Score: 14.323707 | Total Improvements: 76\n",
      "\n",
      "--- Processing N=124 ---\n",
      "\n",
      "--- Processing N=124 ---\n",
      "  [N=124] Launching 60 parallel tasks...\n",
      "  [N=124] Launching 60 parallel tasks...\n",
      "  [N=124] Best candidate score: 0.168795\n",
      "  [N=124] Baseline score: 0.370825, Candidate score: 0.168795\n",
      "  [N=124] ✓ IMPROVED over baseline: 0.370825 -> 0.168795 (Δ=0.202029, 54.48%)\n",
      "  [N=124] Cumulative Score: 14.492502 | Total Improvements: 77\n",
      "\n",
      "--- Processing N=123 ---\n",
      "  [N=123] Launching 60 parallel tasks...\n",
      "  [N=124] Best candidate score: 0.168795\n",
      "  [N=124] Baseline score: 0.370825, Candidate score: 0.168795\n",
      "  [N=124] ✓ IMPROVED over baseline: 0.370825 -> 0.168795 (Δ=0.202029, 54.48%)\n",
      "  [N=124] Cumulative Score: 14.492502 | Total Improvements: 77\n",
      "\n",
      "--- Processing N=123 ---\n",
      "  [N=123] Launching 60 parallel tasks...\n",
      "  [N=123] Best candidate score: 0.170168\n",
      "  [N=123] Baseline score: 0.369956, Candidate score: 0.170168\n",
      "  [N=123] ✓ IMPROVED over baseline: 0.369956 -> 0.170168 (Δ=0.199789, 54.00%)\n",
      "  [N=123] Cumulative Score: 14.662670 | Total Improvements: 78\n",
      "\n",
      "--- Processing N=122 ---\n",
      "  [N=122] Launching 55 parallel tasks...\n",
      "  [N=123] Best candidate score: 0.170168\n",
      "  [N=123] Baseline score: 0.369956, Candidate score: 0.170168\n",
      "  [N=123] ✓ IMPROVED over baseline: 0.369956 -> 0.170168 (Δ=0.199789, 54.00%)\n",
      "  [N=123] Cumulative Score: 14.662670 | Total Improvements: 78\n",
      "\n",
      "--- Processing N=122 ---\n",
      "  [N=122] Launching 55 parallel tasks...\n",
      "  [N=122] Best candidate score: 0.171563\n",
      "  [N=122] Baseline score: 0.369952, Candidate score: 0.171563\n",
      "  [N=122] ✓ IMPROVED over baseline: 0.369952 -> 0.171563 (Δ=0.198390, 53.63%)\n",
      "  [N=122] Cumulative Score: 14.834232 | Total Improvements: 79\n",
      "\n",
      "--- Processing N=121 ---\n",
      "  [N=121] Launching 55 parallel tasks...\n",
      "  [N=122] Best candidate score: 0.171563\n",
      "  [N=122] Baseline score: 0.369952, Candidate score: 0.171563\n",
      "  [N=122] ✓ IMPROVED over baseline: 0.369952 -> 0.171563 (Δ=0.198390, 53.63%)\n",
      "  [N=122] Cumulative Score: 14.834232 | Total Improvements: 79\n",
      "\n",
      "--- Processing N=121 ---\n",
      "  [N=121] Launching 55 parallel tasks...\n",
      "  [N=121] Best candidate score: 0.172980\n",
      "  [N=121] Baseline score: 0.366734, Candidate score: 0.172980\n",
      "  [N=121] ✓ IMPROVED over baseline: 0.366734 -> 0.172980 (Δ=0.193753, 52.83%)\n",
      "  [N=121] Cumulative Score: 15.007213 | Total Improvements: 80\n",
      "\n",
      "--- Processing N=120 ---\n",
      "  [N=120] Launching 55 parallel tasks...\n",
      "  [N=121] Best candidate score: 0.172980\n",
      "  [N=121] Baseline score: 0.366734, Candidate score: 0.172980\n",
      "  [N=121] ✓ IMPROVED over baseline: 0.366734 -> 0.172980 (Δ=0.193753, 52.83%)\n",
      "  [N=121] Cumulative Score: 15.007213 | Total Improvements: 80\n",
      "\n",
      "--- Processing N=120 ---\n",
      "  [N=120] Launching 55 parallel tasks...\n",
      "  [N=120] Best candidate score: 0.174422\n",
      "  [N=120] Baseline score: 0.369695, Candidate score: 0.174422\n",
      "  [N=120] ✓ IMPROVED over baseline: 0.369695 -> 0.174422 (Δ=0.195274, 52.82%)\n",
      "⚠️  Collision at N=120 between trees 0 and 15 (overlap area=1.182419e-01)\n",
      "  [N=120] Found 518 collision(s)\n",
      "  [N=120] Too many collisions - reverting to baseline\n",
      "  [N=120] Cumulative Score: 15.376908 | Total Improvements: 81\n",
      "  [N=120] Best candidate score: 0.174422\n",
      "  [N=120] Baseline score: 0.369695, Candidate score: 0.174422\n",
      "  [N=120] ✓ IMPROVED over baseline: 0.369695 -> 0.174422 (Δ=0.195274, 52.82%)\n",
      "⚠️  Collision at N=120 between trees 0 and 15 (overlap area=1.182419e-01)\n",
      "  [N=120] Found 518 collision(s)\n",
      "  [N=120] Too many collisions - reverting to baseline\n",
      "  [N=120] Cumulative Score: 15.376908 | Total Improvements: 81\n",
      "\n",
      "--- Processing N=119 ---\n",
      "\n",
      "--- Processing N=119 ---\n",
      "  [N=119] Launching 55 parallel tasks...\n",
      "  [N=119] Launching 55 parallel tasks...\n",
      "  [N=119] Best candidate score: 0.174286\n",
      "  [N=119] Baseline score: 0.368494, Candidate score: 0.174286\n",
      "  [N=119] ✓ IMPROVED over baseline: 0.368494 -> 0.174286 (Δ=0.194208, 52.70%)\n",
      "  [N=119] Cumulative Score: 15.551194 | Total Improvements: 82\n",
      "\n",
      "--- Processing N=118 ---\n",
      "  [N=118] Launching 55 parallel tasks...\n",
      "  [N=119] Best candidate score: 0.174286\n",
      "  [N=119] Baseline score: 0.368494, Candidate score: 0.174286\n",
      "  [N=119] ✓ IMPROVED over baseline: 0.368494 -> 0.174286 (Δ=0.194208, 52.70%)\n",
      "  [N=119] Cumulative Score: 15.551194 | Total Improvements: 82\n",
      "\n",
      "--- Processing N=118 ---\n",
      "  [N=118] Launching 55 parallel tasks...\n",
      "  [N=118] Best candidate score: 0.174796\n",
      "  [N=118] Baseline score: 0.371546, Candidate score: 0.174796\n",
      "  [N=118] ✓ IMPROVED over baseline: 0.371546 -> 0.174796 (Δ=0.196750, 52.95%)\n",
      "  [N=118] Cumulative Score: 15.725990 | Total Improvements: 83\n",
      "\n",
      "--- Processing N=117 ---\n",
      "  [N=117] Launching 55 parallel tasks...\n",
      "  [N=118] Best candidate score: 0.174796\n",
      "  [N=118] Baseline score: 0.371546, Candidate score: 0.174796\n",
      "  [N=118] ✓ IMPROVED over baseline: 0.371546 -> 0.174796 (Δ=0.196750, 52.95%)\n",
      "  [N=118] Cumulative Score: 15.725990 | Total Improvements: 83\n",
      "\n",
      "--- Processing N=117 ---\n",
      "  [N=117] Launching 55 parallel tasks...\n",
      "  [N=117] Best candidate score: 0.174785\n",
      "  [N=117] Baseline score: 0.368160, Candidate score: 0.174785\n",
      "  [N=117] ✓ IMPROVED over baseline: 0.368160 -> 0.174785 (Δ=0.193375, 52.52%)\n",
      "  [N=117] Cumulative Score: 15.900775 | Total Improvements: 84\n",
      "\n",
      "--- Processing N=116 ---\n",
      "  [N=116] Launching 60 parallel tasks...\n",
      "  [N=117] Best candidate score: 0.174785\n",
      "  [N=117] Baseline score: 0.368160, Candidate score: 0.174785\n",
      "  [N=117] ✓ IMPROVED over baseline: 0.368160 -> 0.174785 (Δ=0.193375, 52.52%)\n",
      "  [N=117] Cumulative Score: 15.900775 | Total Improvements: 84\n",
      "\n",
      "--- Processing N=116 ---\n",
      "  [N=116] Launching 60 parallel tasks...\n",
      "  [N=116] Best candidate score: 0.175383\n",
      "  [N=116] Baseline score: 0.371090, Candidate score: 0.175383\n",
      "  [N=116] ✓ IMPROVED over baseline: 0.371090 -> 0.175383 (Δ=0.195708, 52.74%)\n",
      "  [N=116] Cumulative Score: 16.076158 | Total Improvements: 85\n",
      "\n",
      "--- Processing N=115 ---\n",
      "  [N=115] Launching 60 parallel tasks...\n",
      "  [N=116] Best candidate score: 0.175383\n",
      "  [N=116] Baseline score: 0.371090, Candidate score: 0.175383\n",
      "  [N=116] ✓ IMPROVED over baseline: 0.371090 -> 0.175383 (Δ=0.195708, 52.74%)\n",
      "  [N=116] Cumulative Score: 16.076158 | Total Improvements: 85\n",
      "\n",
      "--- Processing N=115 ---\n",
      "  [N=115] Launching 60 parallel tasks...\n",
      "  [N=115] Best candidate score: 0.176434\n",
      "  [N=115] Baseline score: 0.369227, Candidate score: 0.176434\n",
      "  [N=115] ✓ IMPROVED over baseline: 0.369227 -> 0.176434 (Δ=0.192793, 52.22%)\n",
      "  [N=115] Cumulative Score: 16.252592 | Total Improvements: 86\n",
      "  [N=115] Best candidate score: 0.176434\n",
      "  [N=115] Baseline score: 0.369227, Candidate score: 0.176434\n",
      "  [N=115] ✓ IMPROVED over baseline: 0.369227 -> 0.176434 (Δ=0.192793, 52.22%)\n",
      "  [N=115] Cumulative Score: 16.252592 | Total Improvements: 86\n",
      "\n",
      "--- Processing N=114 ---\n",
      "\n",
      "--- Processing N=114 ---\n",
      "  [N=114] Launching 60 parallel tasks...\n",
      "  [N=114] Launching 60 parallel tasks...\n",
      "  [N=114] Best candidate score: 0.177982\n",
      "  [N=114] Baseline score: 0.369848, Candidate score: 0.177982\n",
      "  [N=114] ✓ IMPROVED over baseline: 0.369848 -> 0.177982 (Δ=0.191866, 51.88%)\n",
      "  [N=114] Cumulative Score: 16.430574 | Total Improvements: 87\n",
      "\n",
      "--- Processing N=113 ---\n",
      "  [N=113] Launching 60 parallel tasks...\n",
      "  [N=114] Best candidate score: 0.177982\n",
      "  [N=114] Baseline score: 0.369848, Candidate score: 0.177982\n",
      "  [N=114] ✓ IMPROVED over baseline: 0.369848 -> 0.177982 (Δ=0.191866, 51.88%)\n",
      "  [N=114] Cumulative Score: 16.430574 | Total Improvements: 87\n",
      "\n",
      "--- Processing N=113 ---\n",
      "  [N=113] Launching 60 parallel tasks...\n",
      "  [N=113] Best candidate score: 0.179423\n",
      "  [N=113] Baseline score: 0.370136, Candidate score: 0.179423\n",
      "  [N=113] ✓ IMPROVED over baseline: 0.370136 -> 0.179423 (Δ=0.190713, 51.52%)\n",
      "  [N=113] Cumulative Score: 16.609997 | Total Improvements: 88\n",
      "\n",
      "--- Processing N=112 ---\n",
      "  [N=112] Launching 60 parallel tasks...\n",
      "  [N=113] Best candidate score: 0.179423\n",
      "  [N=113] Baseline score: 0.370136, Candidate score: 0.179423\n",
      "  [N=113] ✓ IMPROVED over baseline: 0.370136 -> 0.179423 (Δ=0.190713, 51.52%)\n",
      "  [N=113] Cumulative Score: 16.609997 | Total Improvements: 88\n",
      "\n",
      "--- Processing N=112 ---\n",
      "  [N=112] Launching 60 parallel tasks...\n",
      "  [N=112] Best candidate score: 0.181000\n",
      "  [N=112] Baseline score: 0.369100, Candidate score: 0.181000\n",
      "  [N=112] ✓ IMPROVED over baseline: 0.369100 -> 0.181000 (Δ=0.188099, 50.96%)\n",
      "  [N=112] Cumulative Score: 16.790997 | Total Improvements: 89\n",
      "\n",
      "--- Processing N=111 ---\n",
      "  [N=111] Launching 60 parallel tasks...\n",
      "  [N=112] Best candidate score: 0.181000\n",
      "  [N=112] Baseline score: 0.369100, Candidate score: 0.181000\n",
      "  [N=112] ✓ IMPROVED over baseline: 0.369100 -> 0.181000 (Δ=0.188099, 50.96%)\n",
      "  [N=112] Cumulative Score: 16.790997 | Total Improvements: 89\n",
      "\n",
      "--- Processing N=111 ---\n",
      "  [N=111] Launching 60 parallel tasks...\n",
      "  [N=111] Best candidate score: 0.182631\n",
      "  [N=111] Baseline score: 0.372326, Candidate score: 0.182631\n",
      "  [N=111] ✓ IMPROVED over baseline: 0.372326 -> 0.182631 (Δ=0.189695, 50.95%)\n",
      "  [N=111] Cumulative Score: 16.973628 | Total Improvements: 90\n",
      "\n",
      "--- Processing N=110 ---\n",
      "  [N=110] Launching 60 parallel tasks...\n",
      "  [N=111] Best candidate score: 0.182631\n",
      "  [N=111] Baseline score: 0.372326, Candidate score: 0.182631\n",
      "  [N=111] ✓ IMPROVED over baseline: 0.372326 -> 0.182631 (Δ=0.189695, 50.95%)\n",
      "  [N=111] Cumulative Score: 16.973628 | Total Improvements: 90\n",
      "\n",
      "--- Processing N=110 ---\n",
      "  [N=110] Launching 60 parallel tasks...\n",
      "  [N=110] Best candidate score: 0.184203\n",
      "  [N=110] Baseline score: 0.370014, Candidate score: 0.184203\n",
      "  [N=110] ✓ IMPROVED over baseline: 0.370014 -> 0.184203 (Δ=0.185811, 50.22%)\n",
      "⚠️  Collision at N=110 between trees 0 and 14 (overlap area=1.182419e-01)\n",
      "  [N=110] Found 455 collision(s)\n",
      "  [N=110] Too many collisions - reverting to baseline\n",
      "  [N=110] Cumulative Score: 17.343642 | Total Improvements: 91\n",
      "  [N=110] Best candidate score: 0.184203\n",
      "  [N=110] Baseline score: 0.370014, Candidate score: 0.184203\n",
      "  [N=110] ✓ IMPROVED over baseline: 0.370014 -> 0.184203 (Δ=0.185811, 50.22%)\n",
      "⚠️  Collision at N=110 between trees 0 and 14 (overlap area=1.182419e-01)\n",
      "  [N=110] Found 455 collision(s)\n",
      "  [N=110] Too many collisions - reverting to baseline\n",
      "  [N=110] Cumulative Score: 17.343642 | Total Improvements: 91\n",
      "\n",
      "--- Processing N=109 ---\n",
      "\n",
      "--- Processing N=109 ---\n",
      "  [N=109] Launching 60 parallel tasks...\n",
      "  [N=109] Launching 60 parallel tasks...\n",
      "  [N=109] Best candidate score: 0.185893\n",
      "  [N=109] Baseline score: 0.368816, Candidate score: 0.185893\n",
      "  [N=109] ✓ IMPROVED over baseline: 0.368816 -> 0.185893 (Δ=0.182923, 49.60%)\n",
      "  [N=109] Cumulative Score: 17.529535 | Total Improvements: 92\n",
      "\n",
      "--- Processing N=108 ---\n",
      "  [N=108] Launching 60 parallel tasks...\n",
      "  [N=109] Best candidate score: 0.185893\n",
      "  [N=109] Baseline score: 0.368816, Candidate score: 0.185893\n",
      "  [N=109] ✓ IMPROVED over baseline: 0.368816 -> 0.185893 (Δ=0.182923, 49.60%)\n",
      "  [N=109] Cumulative Score: 17.529535 | Total Improvements: 92\n",
      "\n",
      "--- Processing N=108 ---\n",
      "  [N=108] Launching 60 parallel tasks...\n",
      "  [N=108] Best candidate score: 0.187614\n",
      "  [N=108] Baseline score: 0.372070, Candidate score: 0.187614\n",
      "  [N=108] ✓ IMPROVED over baseline: 0.372070 -> 0.187614 (Δ=0.184456, 49.58%)\n",
      "  [N=108] Cumulative Score: 17.717149 | Total Improvements: 93\n",
      "\n",
      "--- Processing N=107 ---\n",
      "  [N=107] Launching 60 parallel tasks...\n",
      "  [N=108] Best candidate score: 0.187614\n",
      "  [N=108] Baseline score: 0.372070, Candidate score: 0.187614\n",
      "  [N=108] ✓ IMPROVED over baseline: 0.372070 -> 0.187614 (Δ=0.184456, 49.58%)\n",
      "  [N=108] Cumulative Score: 17.717149 | Total Improvements: 93\n",
      "\n",
      "--- Processing N=107 ---\n",
      "  [N=107] Launching 60 parallel tasks...\n",
      "  [N=107] Best candidate score: 0.189005\n",
      "  [N=107] Baseline score: 0.367625, Candidate score: 0.189005\n",
      "  [N=107] ✓ IMPROVED over baseline: 0.367625 -> 0.189005 (Δ=0.178620, 48.59%)\n",
      "  [N=107] Cumulative Score: 17.906153 | Total Improvements: 94\n",
      "\n",
      "--- Processing N=106 ---\n",
      "  [N=106] Launching 60 parallel tasks...\n",
      "  [N=107] Best candidate score: 0.189005\n",
      "  [N=107] Baseline score: 0.367625, Candidate score: 0.189005\n",
      "  [N=107] ✓ IMPROVED over baseline: 0.367625 -> 0.189005 (Δ=0.178620, 48.59%)\n",
      "  [N=107] Cumulative Score: 17.906153 | Total Improvements: 94\n",
      "\n",
      "--- Processing N=106 ---\n",
      "  [N=106] Launching 60 parallel tasks...\n",
      "  [N=106] Best candidate score: 0.190788\n",
      "  [N=106] Baseline score: 0.371093, Candidate score: 0.190788\n",
      "  [N=106] ✓ IMPROVED over baseline: 0.371093 -> 0.190788 (Δ=0.180305, 48.59%)\n",
      "  [N=106] Cumulative Score: 18.096941 | Total Improvements: 95\n",
      "\n",
      "--- Processing N=105 ---\n",
      "  [N=105] Launching 60 parallel tasks...\n",
      "  [N=106] Best candidate score: 0.190788\n",
      "  [N=106] Baseline score: 0.371093, Candidate score: 0.190788\n",
      "  [N=106] ✓ IMPROVED over baseline: 0.371093 -> 0.190788 (Δ=0.180305, 48.59%)\n",
      "  [N=106] Cumulative Score: 18.096941 | Total Improvements: 95\n",
      "\n",
      "--- Processing N=105 ---\n",
      "  [N=105] Launching 60 parallel tasks...\n",
      "  [N=105] Best candidate score: 0.192605\n",
      "  [N=105] Baseline score: 0.366568, Candidate score: 0.192605\n",
      "  [N=105] ✓ IMPROVED over baseline: 0.366568 -> 0.192605 (Δ=0.173964, 47.46%)\n",
      "  [N=105] Cumulative Score: 18.289545 | Total Improvements: 96\n",
      "  [N=105] Best candidate score: 0.192605\n",
      "  [N=105] Baseline score: 0.366568, Candidate score: 0.192605\n",
      "  [N=105] ✓ IMPROVED over baseline: 0.366568 -> 0.192605 (Δ=0.173964, 47.46%)\n",
      "  [N=105] Cumulative Score: 18.289545 | Total Improvements: 96\n",
      "\n",
      "--- Processing N=104 ---\n",
      "\n",
      "--- Processing N=104 ---\n",
      "  [N=104] Launching 60 parallel tasks...\n",
      "  [N=104] Launching 60 parallel tasks...\n",
      "  [N=104] Best candidate score: 0.192660\n",
      "  [N=104] Baseline score: 0.369094, Candidate score: 0.192660\n",
      "  [N=104] ✓ IMPROVED over baseline: 0.369094 -> 0.192660 (Δ=0.176434, 47.80%)\n",
      "  [N=104] Cumulative Score: 18.482205 | Total Improvements: 97\n",
      "\n",
      "--- Processing N=103 ---\n",
      "  [N=103] Launching 60 parallel tasks...\n",
      "  [N=104] Best candidate score: 0.192660\n",
      "  [N=104] Baseline score: 0.369094, Candidate score: 0.192660\n",
      "  [N=104] ✓ IMPROVED over baseline: 0.369094 -> 0.192660 (Δ=0.176434, 47.80%)\n",
      "  [N=104] Cumulative Score: 18.482205 | Total Improvements: 97\n",
      "\n",
      "--- Processing N=103 ---\n",
      "  [N=103] Launching 60 parallel tasks...\n",
      "  [N=103] Best candidate score: 0.192649\n",
      "  [N=103] Baseline score: 0.370607, Candidate score: 0.192649\n",
      "  [N=103] ✓ IMPROVED over baseline: 0.370607 -> 0.192649 (Δ=0.177958, 48.02%)\n",
      "  [N=103] Cumulative Score: 18.674854 | Total Improvements: 98\n",
      "\n",
      "--- Processing N=102 ---\n",
      "  [N=102] Launching 60 parallel tasks...\n",
      "  [N=103] Best candidate score: 0.192649\n",
      "  [N=103] Baseline score: 0.370607, Candidate score: 0.192649\n",
      "  [N=103] ✓ IMPROVED over baseline: 0.370607 -> 0.192649 (Δ=0.177958, 48.02%)\n",
      "  [N=103] Cumulative Score: 18.674854 | Total Improvements: 98\n",
      "\n",
      "--- Processing N=102 ---\n",
      "  [N=102] Launching 60 parallel tasks...\n",
      "  [N=102] Best candidate score: 0.183388\n",
      "  [N=102] Baseline score: 0.370100, Candidate score: 0.183388\n",
      "  [N=102] ✓ IMPROVED over baseline: 0.370100 -> 0.183388 (Δ=0.186711, 50.45%)\n",
      "  [N=102] Cumulative Score: 18.858243 | Total Improvements: 99\n",
      "\n",
      "--- Processing N=101 ---\n",
      "  [N=101] Launching 60 parallel tasks...\n",
      "  [N=102] Best candidate score: 0.183388\n",
      "  [N=102] Baseline score: 0.370100, Candidate score: 0.183388\n",
      "  [N=102] ✓ IMPROVED over baseline: 0.370100 -> 0.183388 (Δ=0.186711, 50.45%)\n",
      "  [N=102] Cumulative Score: 18.858243 | Total Improvements: 99\n",
      "\n",
      "--- Processing N=101 ---\n",
      "  [N=101] Launching 60 parallel tasks...\n",
      "  [N=101] Best candidate score: 0.185204\n",
      "  [N=101] Baseline score: 0.367464, Candidate score: 0.185204\n",
      "  [N=101] ✓ IMPROVED over baseline: 0.367464 -> 0.185204 (Δ=0.182259, 49.60%)\n",
      "  [N=101] Cumulative Score: 19.043447 | Total Improvements: 100\n",
      "\n",
      "--- Processing N=100 ---\n",
      "  [N=100] Critical N! Widening beam to 24\n",
      "  [N=100] Launching 60 parallel tasks...\n",
      "  [N=101] Best candidate score: 0.185204\n",
      "  [N=101] Baseline score: 0.367464, Candidate score: 0.185204\n",
      "  [N=101] ✓ IMPROVED over baseline: 0.367464 -> 0.185204 (Δ=0.182259, 49.60%)\n",
      "  [N=101] Cumulative Score: 19.043447 | Total Improvements: 100\n",
      "\n",
      "--- Processing N=100 ---\n",
      "  [N=100] Critical N! Widening beam to 24\n",
      "  [N=100] Launching 60 parallel tasks...\n",
      "  [N=100] Best candidate score: 0.185290\n",
      "  [N=100] Baseline score: 0.369160, Candidate score: 0.185290\n",
      "  [N=100] ✓ IMPROVED over baseline: 0.369160 -> 0.185290 (Δ=0.183870, 49.81%)\n",
      "⚠️  Collision at N=100 between trees 0 and 14 (overlap area=1.182419e-01)\n",
      "  [N=100] Found 403 collision(s)\n",
      "  [N=100] Too many collisions - reverting to baseline\n",
      "  [N=100] Cumulative Score: 19.412607 | Total Improvements: 101\n",
      "  [N=100] Best candidate score: 0.185290\n",
      "  [N=100] Baseline score: 0.369160, Candidate score: 0.185290\n",
      "  [N=100] ✓ IMPROVED over baseline: 0.369160 -> 0.185290 (Δ=0.183870, 49.81%)\n",
      "⚠️  Collision at N=100 between trees 0 and 14 (overlap area=1.182419e-01)\n",
      "  [N=100] Found 403 collision(s)\n",
      "  [N=100] Too many collisions - reverting to baseline\n",
      "  [N=100] Cumulative Score: 19.412607 | Total Improvements: 101\n",
      "\n",
      "--- Processing N=99 ---\n",
      "\n",
      "--- Processing N=99 ---\n",
      "  [N=99] Launching 100 parallel tasks...\n",
      "  [N=99] Launching 100 parallel tasks...\n",
      "  [N=99] Best candidate score: 0.178182\n",
      "  [N=99] Baseline score: 0.367318, Candidate score: 0.178182\n",
      "  [N=99] ✓ IMPROVED over baseline: 0.367318 -> 0.178182 (Δ=0.189136, 51.49%)\n",
      "  [N=99] Cumulative Score: 19.590789 | Total Improvements: 102\n",
      "\n",
      "--- Processing N=98 ---\n",
      "  [N=98] Launching 60 parallel tasks...\n",
      "  [N=99] Best candidate score: 0.178182\n",
      "  [N=99] Baseline score: 0.367318, Candidate score: 0.178182\n",
      "  [N=99] ✓ IMPROVED over baseline: 0.367318 -> 0.178182 (Δ=0.189136, 51.49%)\n",
      "  [N=99] Cumulative Score: 19.590789 | Total Improvements: 102\n",
      "\n",
      "--- Processing N=98 ---\n",
      "  [N=98] Launching 60 parallel tasks...\n",
      "  [N=98] Best candidate score: 0.180000\n",
      "  [N=98] Baseline score: 0.371066, Candidate score: 0.180000\n",
      "  [N=98] ✓ IMPROVED over baseline: 0.371066 -> 0.180000 (Δ=0.191066, 51.49%)\n",
      "  [N=98] Cumulative Score: 19.770789 | Total Improvements: 103\n",
      "\n",
      "--- Processing N=97 ---\n",
      "  [N=97] Launching 60 parallel tasks...\n",
      "  [N=98] Best candidate score: 0.180000\n",
      "  [N=98] Baseline score: 0.371066, Candidate score: 0.180000\n",
      "  [N=98] ✓ IMPROVED over baseline: 0.371066 -> 0.180000 (Δ=0.191066, 51.49%)\n",
      "  [N=98] Cumulative Score: 19.770789 | Total Improvements: 103\n",
      "\n",
      "--- Processing N=97 ---\n",
      "  [N=97] Launching 60 parallel tasks...\n",
      "  [N=97] Best candidate score: 0.181856\n",
      "  [N=97] Baseline score: 0.371455, Candidate score: 0.181856\n",
      "  [N=97] ✓ IMPROVED over baseline: 0.371455 -> 0.181856 (Δ=0.189600, 51.04%)\n",
      "  [N=97] Cumulative Score: 19.952644 | Total Improvements: 104\n",
      "\n",
      "--- Processing N=96 ---\n",
      "  [N=96] Launching 60 parallel tasks...\n",
      "  [N=97] Best candidate score: 0.181856\n",
      "  [N=97] Baseline score: 0.371455, Candidate score: 0.181856\n",
      "  [N=97] ✓ IMPROVED over baseline: 0.371455 -> 0.181856 (Δ=0.189600, 51.04%)\n",
      "  [N=97] Cumulative Score: 19.952644 | Total Improvements: 104\n",
      "\n",
      "--- Processing N=96 ---\n",
      "  [N=96] Launching 60 parallel tasks...\n",
      "  [N=96] Best candidate score: 0.172975\n",
      "  [N=96] Baseline score: 0.367015, Candidate score: 0.172975\n",
      "  [N=96] ✓ IMPROVED over baseline: 0.367015 -> 0.172975 (Δ=0.194040, 52.87%)\n",
      "  [N=96] Cumulative Score: 20.125620 | Total Improvements: 105\n",
      "\n",
      "--- Processing N=95 ---\n",
      "  [N=95] Launching 60 parallel tasks...\n",
      "  [N=96] Best candidate score: 0.172975\n",
      "  [N=96] Baseline score: 0.367015, Candidate score: 0.172975\n",
      "  [N=96] ✓ IMPROVED over baseline: 0.367015 -> 0.172975 (Δ=0.194040, 52.87%)\n",
      "  [N=96] Cumulative Score: 20.125620 | Total Improvements: 105\n",
      "\n",
      "--- Processing N=95 ---\n",
      "  [N=95] Launching 60 parallel tasks...\n",
      "  [N=95] Best candidate score: 0.174796\n",
      "  [N=95] Baseline score: 0.370878, Candidate score: 0.174796\n",
      "  [N=95] ✓ IMPROVED over baseline: 0.370878 -> 0.174796 (Δ=0.196082, 52.87%)\n",
      "  [N=95] Cumulative Score: 20.300416 | Total Improvements: 106\n",
      "  [N=95] Best candidate score: 0.174796\n",
      "  [N=95] Baseline score: 0.370878, Candidate score: 0.174796\n",
      "  [N=95] ✓ IMPROVED over baseline: 0.370878 -> 0.174796 (Δ=0.196082, 52.87%)\n",
      "  [N=95] Cumulative Score: 20.300416 | Total Improvements: 106\n",
      "\n",
      "--- Processing N=94 ---\n",
      "\n",
      "--- Processing N=94 ---\n",
      "  [N=94] Launching 60 parallel tasks...\n",
      "  [N=94] Launching 60 parallel tasks...\n",
      "  [N=94] Best candidate score: 0.176656\n",
      "  [N=94] Baseline score: 0.366224, Candidate score: 0.176656\n",
      "  [N=94] ✓ IMPROVED over baseline: 0.366224 -> 0.176656 (Δ=0.189568, 51.76%)\n",
      "  [N=94] Cumulative Score: 20.477071 | Total Improvements: 107\n",
      "\n",
      "--- Processing N=93 ---\n",
      "  [N=93] Launching 60 parallel tasks...\n",
      "  [N=94] Best candidate score: 0.176656\n",
      "  [N=94] Baseline score: 0.366224, Candidate score: 0.176656\n",
      "  [N=94] ✓ IMPROVED over baseline: 0.366224 -> 0.176656 (Δ=0.189568, 51.76%)\n",
      "  [N=94] Cumulative Score: 20.477071 | Total Improvements: 107\n",
      "\n",
      "--- Processing N=93 ---\n",
      "  [N=93] Launching 60 parallel tasks...\n",
      "  [N=93] Best candidate score: 0.178555\n",
      "  [N=93] Baseline score: 0.366836, Candidate score: 0.178555\n",
      "  [N=93] ✓ IMPROVED over baseline: 0.366836 -> 0.178555 (Δ=0.188281, 51.33%)\n",
      "  [N=93] Cumulative Score: 20.655626 | Total Improvements: 108\n",
      "\n",
      "--- Processing N=92 ---\n",
      "  [N=92] Launching 60 parallel tasks...\n",
      "  [N=93] Best candidate score: 0.178555\n",
      "  [N=93] Baseline score: 0.366836, Candidate score: 0.178555\n",
      "  [N=93] ✓ IMPROVED over baseline: 0.366836 -> 0.178555 (Δ=0.188281, 51.33%)\n",
      "  [N=93] Cumulative Score: 20.655626 | Total Improvements: 108\n",
      "\n",
      "--- Processing N=92 ---\n",
      "  [N=92] Launching 60 parallel tasks...\n",
      "  [N=92] Best candidate score: 0.180496\n",
      "  [N=92] Baseline score: 0.370362, Candidate score: 0.180496\n",
      "  [N=92] ✓ IMPROVED over baseline: 0.370362 -> 0.180496 (Δ=0.189866, 51.26%)\n",
      "  [N=92] Cumulative Score: 20.836122 | Total Improvements: 109\n",
      "\n",
      "--- Processing N=91 ---\n",
      "  [N=91] Launching 60 parallel tasks...\n",
      "  [N=92] Best candidate score: 0.180496\n",
      "  [N=92] Baseline score: 0.370362, Candidate score: 0.180496\n",
      "  [N=92] ✓ IMPROVED over baseline: 0.370362 -> 0.180496 (Δ=0.189866, 51.26%)\n",
      "  [N=92] Cumulative Score: 20.836122 | Total Improvements: 109\n",
      "\n",
      "--- Processing N=91 ---\n",
      "  [N=91] Launching 60 parallel tasks...\n",
      "  [N=91] Best candidate score: 0.182479\n",
      "  [N=91] Baseline score: 0.370962, Candidate score: 0.182479\n",
      "  [N=91] ✓ IMPROVED over baseline: 0.370962 -> 0.182479 (Δ=0.188483, 50.81%)\n",
      "  [N=91] Cumulative Score: 21.018602 | Total Improvements: 110\n",
      "\n",
      "--- Processing N=90 ---\n",
      "  [N=90] Launching 60 parallel tasks...\n",
      "  [N=91] Best candidate score: 0.182479\n",
      "  [N=91] Baseline score: 0.370962, Candidate score: 0.182479\n",
      "  [N=91] ✓ IMPROVED over baseline: 0.370962 -> 0.182479 (Δ=0.188483, 50.81%)\n",
      "  [N=91] Cumulative Score: 21.018602 | Total Improvements: 110\n",
      "\n",
      "--- Processing N=90 ---\n",
      "  [N=90] Launching 60 parallel tasks...\n",
      "  [N=90] Best candidate score: 0.184507\n",
      "  [N=90] Baseline score: 0.371187, Candidate score: 0.184507\n",
      "  [N=90] ✓ IMPROVED over baseline: 0.371187 -> 0.184507 (Δ=0.186680, 50.29%)\n",
      "⚠️  Collision at N=90 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=90] Found 352 collision(s)\n",
      "  [N=90] Too many collisions - reverting to baseline\n",
      "  [N=90] Cumulative Score: 21.389788 | Total Improvements: 111\n",
      "  [N=90] Best candidate score: 0.184507\n",
      "  [N=90] Baseline score: 0.371187, Candidate score: 0.184507\n",
      "  [N=90] ✓ IMPROVED over baseline: 0.371187 -> 0.184507 (Δ=0.186680, 50.29%)\n",
      "⚠️  Collision at N=90 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=90] Found 352 collision(s)\n",
      "  [N=90] Too many collisions - reverting to baseline\n",
      "  [N=90] Cumulative Score: 21.389788 | Total Improvements: 111\n",
      "\n",
      "--- Processing N=89 ---\n",
      "\n",
      "--- Processing N=89 ---\n",
      "  [N=89] Launching 60 parallel tasks...\n",
      "  [N=89] Launching 60 parallel tasks...\n",
      "  [N=89] Best candidate score: 0.186580\n",
      "  [N=89] Baseline score: 0.371936, Candidate score: 0.186580\n",
      "  [N=89] ✓ IMPROVED over baseline: 0.371936 -> 0.186580 (Δ=0.185356, 49.84%)\n",
      "  [N=89] Cumulative Score: 21.576368 | Total Improvements: 112\n",
      "\n",
      "--- Processing N=88 ---\n",
      "  [N=88] Launching 60 parallel tasks...\n",
      "  [N=89] Best candidate score: 0.186580\n",
      "  [N=89] Baseline score: 0.371936, Candidate score: 0.186580\n",
      "  [N=89] ✓ IMPROVED over baseline: 0.371936 -> 0.186580 (Δ=0.185356, 49.84%)\n",
      "  [N=89] Cumulative Score: 21.576368 | Total Improvements: 112\n",
      "\n",
      "--- Processing N=88 ---\n",
      "  [N=88] Launching 60 parallel tasks...\n",
      "  [N=88] Best candidate score: 0.188700\n",
      "  [N=88] Baseline score: 0.369558, Candidate score: 0.188700\n",
      "  [N=88] ✓ IMPROVED over baseline: 0.369558 -> 0.188700 (Δ=0.180858, 48.94%)\n",
      "  [N=88] Cumulative Score: 21.765069 | Total Improvements: 113\n",
      "\n",
      "--- Processing N=87 ---\n",
      "  [N=87] Launching 60 parallel tasks...\n",
      "  [N=88] Best candidate score: 0.188700\n",
      "  [N=88] Baseline score: 0.369558, Candidate score: 0.188700\n",
      "  [N=88] ✓ IMPROVED over baseline: 0.369558 -> 0.188700 (Δ=0.180858, 48.94%)\n",
      "  [N=88] Cumulative Score: 21.765069 | Total Improvements: 113\n",
      "\n",
      "--- Processing N=87 ---\n",
      "  [N=87] Launching 60 parallel tasks...\n",
      "  [N=87] Best candidate score: 0.190869\n",
      "  [N=87] Baseline score: 0.372413, Candidate score: 0.190869\n",
      "  [N=87] ✓ IMPROVED over baseline: 0.372413 -> 0.190869 (Δ=0.181544, 48.75%)\n",
      "  [N=87] Cumulative Score: 21.955938 | Total Improvements: 114\n",
      "\n",
      "--- Processing N=86 ---\n",
      "  [N=86] Launching 60 parallel tasks...\n",
      "  [N=87] Best candidate score: 0.190869\n",
      "  [N=87] Baseline score: 0.372413, Candidate score: 0.190869\n",
      "  [N=87] ✓ IMPROVED over baseline: 0.372413 -> 0.190869 (Δ=0.181544, 48.75%)\n",
      "  [N=87] Cumulative Score: 21.955938 | Total Improvements: 114\n",
      "\n",
      "--- Processing N=86 ---\n",
      "  [N=86] Launching 60 parallel tasks...\n",
      "  [N=86] Best candidate score: 0.193089\n",
      "  [N=86] Baseline score: 0.371406, Candidate score: 0.193089\n",
      "  [N=86] ✓ IMPROVED over baseline: 0.371406 -> 0.193089 (Δ=0.178317, 48.01%)\n",
      "  [N=86] Cumulative Score: 22.149026 | Total Improvements: 115\n",
      "\n",
      "--- Processing N=85 ---\n",
      "  [N=85] Launching 60 parallel tasks...\n",
      "  [N=86] Best candidate score: 0.193089\n",
      "  [N=86] Baseline score: 0.371406, Candidate score: 0.193089\n",
      "  [N=86] ✓ IMPROVED over baseline: 0.371406 -> 0.193089 (Δ=0.178317, 48.01%)\n",
      "  [N=86] Cumulative Score: 22.149026 | Total Improvements: 115\n",
      "\n",
      "--- Processing N=85 ---\n",
      "  [N=85] Launching 60 parallel tasks...\n",
      "  [N=85] Best candidate score: 0.195360\n",
      "  [N=85] Baseline score: 0.370728, Candidate score: 0.195360\n",
      "  [N=85] ✓ IMPROVED over baseline: 0.370728 -> 0.195360 (Δ=0.175367, 47.30%)\n",
      "  [N=85] Cumulative Score: 22.344387 | Total Improvements: 116\n",
      "  [N=85] Best candidate score: 0.195360\n",
      "  [N=85] Baseline score: 0.370728, Candidate score: 0.195360\n",
      "  [N=85] ✓ IMPROVED over baseline: 0.370728 -> 0.195360 (Δ=0.175367, 47.30%)\n",
      "  [N=85] Cumulative Score: 22.344387 | Total Improvements: 116\n",
      "\n",
      "--- Processing N=84 ---\n",
      "  [N=84] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=84 ---\n",
      "  [N=84] Launching 60 parallel tasks...\n",
      "  [N=84] Best candidate score: 0.185744\n",
      "  [N=84] Baseline score: 0.368301, Candidate score: 0.185744\n",
      "  [N=84] ✓ IMPROVED over baseline: 0.368301 -> 0.185744 (Δ=0.182557, 49.57%)\n",
      "  [N=84] Cumulative Score: 22.530131 | Total Improvements: 117\n",
      "\n",
      "--- Processing N=83 ---\n",
      "  [N=83] Launching 60 parallel tasks...\n",
      "  [N=84] Best candidate score: 0.185744\n",
      "  [N=84] Baseline score: 0.368301, Candidate score: 0.185744\n",
      "  [N=84] ✓ IMPROVED over baseline: 0.368301 -> 0.185744 (Δ=0.182557, 49.57%)\n",
      "  [N=84] Cumulative Score: 22.530131 | Total Improvements: 117\n",
      "\n",
      "--- Processing N=83 ---\n",
      "  [N=83] Launching 60 parallel tasks...\n",
      "  [N=83] Best candidate score: 0.187982\n",
      "  [N=83] Baseline score: 0.371701, Candidate score: 0.187982\n",
      "  [N=83] ✓ IMPROVED over baseline: 0.371701 -> 0.187982 (Δ=0.183719, 49.43%)\n",
      "  [N=83] Cumulative Score: 22.718113 | Total Improvements: 118\n",
      "\n",
      "--- Processing N=82 ---\n",
      "  [N=82] Launching 60 parallel tasks...\n",
      "  [N=83] Best candidate score: 0.187982\n",
      "  [N=83] Baseline score: 0.371701, Candidate score: 0.187982\n",
      "  [N=83] ✓ IMPROVED over baseline: 0.371701 -> 0.187982 (Δ=0.183719, 49.43%)\n",
      "  [N=83] Cumulative Score: 22.718113 | Total Improvements: 118\n",
      "\n",
      "--- Processing N=82 ---\n",
      "  [N=82] Launching 60 parallel tasks...\n",
      "  [N=82] Best candidate score: 0.190274\n",
      "  [N=82] Baseline score: 0.365054, Candidate score: 0.190274\n",
      "  [N=82] ✓ IMPROVED over baseline: 0.365054 -> 0.190274 (Δ=0.174779, 47.88%)\n",
      "  [N=82] Cumulative Score: 22.908387 | Total Improvements: 119\n",
      "\n",
      "--- Processing N=81 ---\n",
      "  [N=81] Launching 60 parallel tasks...\n",
      "  [N=82] Best candidate score: 0.190274\n",
      "  [N=82] Baseline score: 0.365054, Candidate score: 0.190274\n",
      "  [N=82] ✓ IMPROVED over baseline: 0.365054 -> 0.190274 (Δ=0.174779, 47.88%)\n",
      "  [N=82] Cumulative Score: 22.908387 | Total Improvements: 119\n",
      "\n",
      "--- Processing N=81 ---\n",
      "  [N=81] Launching 60 parallel tasks...\n",
      "  [N=81] Best candidate score: 0.192623\n",
      "  [N=81] Baseline score: 0.369423, Candidate score: 0.192623\n",
      "  [N=81] ✓ IMPROVED over baseline: 0.369423 -> 0.192623 (Δ=0.176799, 47.86%)\n",
      "  [N=81] Cumulative Score: 23.101011 | Total Improvements: 120\n",
      "\n",
      "--- Processing N=80 ---\n",
      "  [N=80] Launching 60 parallel tasks...\n",
      "  [N=81] Best candidate score: 0.192623\n",
      "  [N=81] Baseline score: 0.369423, Candidate score: 0.192623\n",
      "  [N=81] ✓ IMPROVED over baseline: 0.369423 -> 0.192623 (Δ=0.176799, 47.86%)\n",
      "  [N=81] Cumulative Score: 23.101011 | Total Improvements: 120\n",
      "\n",
      "--- Processing N=80 ---\n",
      "  [N=80] Launching 60 parallel tasks...\n",
      "  [N=80] Best candidate score: 0.195031\n",
      "  [N=80] Baseline score: 0.369953, Candidate score: 0.195031\n",
      "  [N=80] ✓ IMPROVED over baseline: 0.369953 -> 0.195031 (Δ=0.174922, 47.28%)\n",
      "⚠️  Collision at N=80 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=80] Found 295 collision(s)\n",
      "  [N=80] Too many collisions - reverting to baseline\n",
      "  [N=80] Cumulative Score: 23.470964 | Total Improvements: 121\n",
      "  [N=80] Best candidate score: 0.195031\n",
      "  [N=80] Baseline score: 0.369953, Candidate score: 0.195031\n",
      "  [N=80] ✓ IMPROVED over baseline: 0.369953 -> 0.195031 (Δ=0.174922, 47.28%)\n",
      "⚠️  Collision at N=80 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=80] Found 295 collision(s)\n",
      "  [N=80] Too many collisions - reverting to baseline\n",
      "  [N=80] Cumulative Score: 23.470964 | Total Improvements: 121\n",
      "\n",
      "--- Processing N=79 ---\n",
      "\n",
      "--- Processing N=79 ---\n",
      "  [N=79] Launching 60 parallel tasks...\n",
      "  [N=79] Launching 60 parallel tasks...\n",
      "  [N=79] Best candidate score: 0.185198\n",
      "  [N=79] Baseline score: 0.370350, Candidate score: 0.185198\n",
      "  [N=79] ✓ IMPROVED over baseline: 0.370350 -> 0.185198 (Δ=0.185153, 49.99%)\n",
      "  [N=79] Cumulative Score: 23.656161 | Total Improvements: 122\n",
      "\n",
      "--- Processing N=78 ---\n",
      "  [N=78] Launching 60 parallel tasks...\n",
      "  [N=79] Best candidate score: 0.185198\n",
      "  [N=79] Baseline score: 0.370350, Candidate score: 0.185198\n",
      "  [N=79] ✓ IMPROVED over baseline: 0.370350 -> 0.185198 (Δ=0.185153, 49.99%)\n",
      "  [N=79] Cumulative Score: 23.656161 | Total Improvements: 122\n",
      "\n",
      "--- Processing N=78 ---\n",
      "  [N=78] Launching 60 parallel tasks...\n",
      "  [N=78] Best candidate score: 0.185483\n",
      "  [N=78] Baseline score: 0.367830, Candidate score: 0.185483\n",
      "  [N=78] ✓ IMPROVED over baseline: 0.367830 -> 0.185483 (Δ=0.182347, 49.57%)\n",
      "  [N=78] Cumulative Score: 23.841644 | Total Improvements: 123\n",
      "\n",
      "--- Processing N=77 ---\n",
      "  [N=77] Launching 60 parallel tasks...\n",
      "  [N=78] Best candidate score: 0.185483\n",
      "  [N=78] Baseline score: 0.367830, Candidate score: 0.185483\n",
      "  [N=78] ✓ IMPROVED over baseline: 0.367830 -> 0.185483 (Δ=0.182347, 49.57%)\n",
      "  [N=78] Cumulative Score: 23.841644 | Total Improvements: 123\n",
      "\n",
      "--- Processing N=77 ---\n",
      "  [N=77] Launching 60 parallel tasks...\n",
      "  [N=77] Best candidate score: 0.177792\n",
      "  [N=77] Baseline score: 0.368573, Candidate score: 0.177792\n",
      "  [N=77] ✓ IMPROVED over baseline: 0.368573 -> 0.177792 (Δ=0.190781, 51.76%)\n",
      "  [N=77] Cumulative Score: 24.019436 | Total Improvements: 124\n",
      "\n",
      "--- Processing N=76 ---\n",
      "  [N=76] Launching 60 parallel tasks...\n",
      "  [N=77] Best candidate score: 0.177792\n",
      "  [N=77] Baseline score: 0.368573, Candidate score: 0.177792\n",
      "  [N=77] ✓ IMPROVED over baseline: 0.368573 -> 0.177792 (Δ=0.190781, 51.76%)\n",
      "  [N=77] Cumulative Score: 24.019436 | Total Improvements: 124\n",
      "\n",
      "--- Processing N=76 ---\n",
      "  [N=76] Launching 60 parallel tasks...\n",
      "  [N=76] Best candidate score: 0.180132\n",
      "  [N=76] Baseline score: 0.372688, Candidate score: 0.180132\n",
      "  [N=76] ✓ IMPROVED over baseline: 0.372688 -> 0.180132 (Δ=0.192557, 51.67%)\n",
      "  [N=76] Cumulative Score: 24.199568 | Total Improvements: 125\n",
      "\n",
      "--- Processing N=75 ---\n",
      "  [N=75] Launching 60 parallel tasks...\n",
      "  [N=76] Best candidate score: 0.180132\n",
      "  [N=76] Baseline score: 0.372688, Candidate score: 0.180132\n",
      "  [N=76] ✓ IMPROVED over baseline: 0.372688 -> 0.180132 (Δ=0.192557, 51.67%)\n",
      "  [N=76] Cumulative Score: 24.199568 | Total Improvements: 125\n",
      "\n",
      "--- Processing N=75 ---\n",
      "  [N=75] Launching 60 parallel tasks...\n",
      "  [N=75] Best candidate score: 0.182533\n",
      "  [N=75] Baseline score: 0.367880, Candidate score: 0.182533\n",
      "  [N=75] ✓ IMPROVED over baseline: 0.367880 -> 0.182533 (Δ=0.185346, 50.38%)\n",
      "  [N=75] Cumulative Score: 24.382101 | Total Improvements: 126\n",
      "  [N=75] Best candidate score: 0.182533\n",
      "  [N=75] Baseline score: 0.367880, Candidate score: 0.182533\n",
      "  [N=75] ✓ IMPROVED over baseline: 0.367880 -> 0.182533 (Δ=0.185346, 50.38%)\n",
      "  [N=75] Cumulative Score: 24.382101 | Total Improvements: 126\n",
      "\n",
      "--- Processing N=74 ---\n",
      "\n",
      "--- Processing N=74 ---\n",
      "  [N=74] Launching 60 parallel tasks...\n",
      "  [N=74] Launching 60 parallel tasks...\n",
      "  [N=74] Best candidate score: 0.185000\n",
      "  [N=74] Baseline score: 0.370587, Candidate score: 0.185000\n",
      "  [N=74] ✓ IMPROVED over baseline: 0.370587 -> 0.185000 (Δ=0.185587, 50.08%)\n",
      "  [N=74] Cumulative Score: 24.567101 | Total Improvements: 127\n",
      "\n",
      "--- Processing N=73 ---\n",
      "  [N=73] Launching 60 parallel tasks...\n",
      "  [N=74] Best candidate score: 0.185000\n",
      "  [N=74] Baseline score: 0.370587, Candidate score: 0.185000\n",
      "  [N=74] ✓ IMPROVED over baseline: 0.370587 -> 0.185000 (Δ=0.185587, 50.08%)\n",
      "  [N=74] Cumulative Score: 24.567101 | Total Improvements: 127\n",
      "\n",
      "--- Processing N=73 ---\n",
      "  [N=73] Launching 60 parallel tasks...\n",
      "  [N=73] Best candidate score: 0.187534\n",
      "  [N=73] Baseline score: 0.372556, Candidate score: 0.187534\n",
      "  [N=73] ✓ IMPROVED over baseline: 0.372556 -> 0.187534 (Δ=0.185022, 49.66%)\n",
      "  [N=73] Cumulative Score: 24.754636 | Total Improvements: 128\n",
      "\n",
      "--- Processing N=72 ---\n",
      "  [N=72] Launching 60 parallel tasks...\n",
      "  [N=73] Best candidate score: 0.187534\n",
      "  [N=73] Baseline score: 0.372556, Candidate score: 0.187534\n",
      "  [N=73] ✓ IMPROVED over baseline: 0.372556 -> 0.187534 (Δ=0.185022, 49.66%)\n",
      "  [N=73] Cumulative Score: 24.754636 | Total Improvements: 128\n",
      "\n",
      "--- Processing N=72 ---\n",
      "  [N=72] Launching 60 parallel tasks...\n",
      "  [N=72] Best candidate score: 0.190139\n",
      "  [N=72] Baseline score: 0.369280, Candidate score: 0.190139\n",
      "  [N=72] ✓ IMPROVED over baseline: 0.369280 -> 0.190139 (Δ=0.179141, 48.51%)\n",
      "  [N=72] Cumulative Score: 24.944774 | Total Improvements: 129\n",
      "\n",
      "--- Processing N=71 ---\n",
      "  [N=71] Launching 60 parallel tasks...\n",
      "  [N=72] Best candidate score: 0.190139\n",
      "  [N=72] Baseline score: 0.369280, Candidate score: 0.190139\n",
      "  [N=72] ✓ IMPROVED over baseline: 0.369280 -> 0.190139 (Δ=0.179141, 48.51%)\n",
      "  [N=72] Cumulative Score: 24.944774 | Total Improvements: 129\n",
      "\n",
      "--- Processing N=71 ---\n",
      "  [N=71] Launching 60 parallel tasks...\n",
      "  [N=71] Best candidate score: 0.192817\n",
      "  [N=71] Baseline score: 0.370594, Candidate score: 0.192817\n",
      "  [N=71] ✓ IMPROVED over baseline: 0.370594 -> 0.192817 (Δ=0.177777, 47.97%)\n",
      "  [N=71] Cumulative Score: 25.137591 | Total Improvements: 130\n",
      "\n",
      "--- Processing N=70 ---\n",
      "  [N=70] Launching 55 parallel tasks...\n",
      "  [N=71] Best candidate score: 0.192817\n",
      "  [N=71] Baseline score: 0.370594, Candidate score: 0.192817\n",
      "  [N=71] ✓ IMPROVED over baseline: 0.370594 -> 0.192817 (Δ=0.177777, 47.97%)\n",
      "  [N=71] Cumulative Score: 25.137591 | Total Improvements: 130\n",
      "\n",
      "--- Processing N=70 ---\n",
      "  [N=70] Launching 55 parallel tasks...\n",
      "  [N=70] Best candidate score: 0.195571\n",
      "  [N=70] Baseline score: 0.372079, Candidate score: 0.195571\n",
      "  [N=70] ✓ IMPROVED over baseline: 0.372079 -> 0.195571 (Δ=0.176508, 47.44%)\n",
      "⚠️  Collision at N=70 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=70] Found 278 collision(s)\n",
      "  [N=70] Too many collisions - reverting to baseline\n",
      "  [N=70] Cumulative Score: 25.509670 | Total Improvements: 131\n",
      "  [N=70] Best candidate score: 0.195571\n",
      "  [N=70] Baseline score: 0.372079, Candidate score: 0.195571\n",
      "  [N=70] ✓ IMPROVED over baseline: 0.372079 -> 0.195571 (Δ=0.176508, 47.44%)\n",
      "⚠️  Collision at N=70 between trees 0 and 2 (overlap area=1.000000e-02)\n",
      "  [N=70] Found 278 collision(s)\n",
      "  [N=70] Too many collisions - reverting to baseline\n",
      "  [N=70] Cumulative Score: 25.509670 | Total Improvements: 131\n",
      "\n",
      "--- Processing N=69 ---\n",
      "\n",
      "--- Processing N=69 ---\n",
      "  [N=69] Launching 60 parallel tasks...\n",
      "  [N=69] Launching 60 parallel tasks...\n",
      "  [N=69] Best candidate score: 0.198406\n",
      "  [N=69] Baseline score: 0.367506, Candidate score: 0.198406\n",
      "  [N=69] ✓ IMPROVED over baseline: 0.367506 -> 0.198406 (Δ=0.169100, 46.01%)\n",
      "  [N=69] Cumulative Score: 25.708076 | Total Improvements: 132\n",
      "\n",
      "--- Processing N=68 ---\n",
      "  [N=68] Launching 60 parallel tasks...\n",
      "  [N=69] Best candidate score: 0.198406\n",
      "  [N=69] Baseline score: 0.367506, Candidate score: 0.198406\n",
      "  [N=69] ✓ IMPROVED over baseline: 0.367506 -> 0.198406 (Δ=0.169100, 46.01%)\n",
      "  [N=69] Cumulative Score: 25.708076 | Total Improvements: 132\n",
      "\n",
      "--- Processing N=68 ---\n",
      "  [N=68] Launching 60 parallel tasks...\n",
      "  [N=68] Best candidate score: 0.201324\n",
      "  [N=68] Baseline score: 0.370141, Candidate score: 0.201324\n",
      "  [N=68] ✓ IMPROVED over baseline: 0.370141 -> 0.201324 (Δ=0.168818, 45.61%)\n",
      "  [N=68] Cumulative Score: 25.909400 | Total Improvements: 133\n",
      "\n",
      "--- Processing N=67 ---\n",
      "  [N=67] Launching 60 parallel tasks...\n",
      "  [N=68] Best candidate score: 0.201324\n",
      "  [N=68] Baseline score: 0.370141, Candidate score: 0.201324\n",
      "  [N=68] ✓ IMPROVED over baseline: 0.370141 -> 0.201324 (Δ=0.168818, 45.61%)\n",
      "  [N=68] Cumulative Score: 25.909400 | Total Improvements: 133\n",
      "\n",
      "--- Processing N=67 ---\n",
      "  [N=67] Launching 60 parallel tasks...\n",
      "  [N=67] Best candidate score: 0.204328\n",
      "  [N=67] Baseline score: 0.367032, Candidate score: 0.204328\n",
      "  [N=67] ✓ IMPROVED over baseline: 0.367032 -> 0.204328 (Δ=0.162704, 44.33%)\n",
      "  [N=67] Cumulative Score: 26.113728 | Total Improvements: 134\n",
      "\n",
      "--- Processing N=66 ---\n",
      "  [N=66] Launching 60 parallel tasks...\n",
      "  [N=67] Best candidate score: 0.204328\n",
      "  [N=67] Baseline score: 0.367032, Candidate score: 0.204328\n",
      "  [N=67] ✓ IMPROVED over baseline: 0.367032 -> 0.204328 (Δ=0.162704, 44.33%)\n",
      "  [N=67] Cumulative Score: 26.113728 | Total Improvements: 134\n",
      "\n",
      "--- Processing N=66 ---\n",
      "  [N=66] Launching 60 parallel tasks...\n",
      "  [N=66] Best candidate score: 0.207424\n",
      "  [N=66] Baseline score: 0.365910, Candidate score: 0.207424\n",
      "  [N=66] ✓ IMPROVED over baseline: 0.365910 -> 0.207424 (Δ=0.158485, 43.31%)\n",
      "  [N=66] Cumulative Score: 26.321152 | Total Improvements: 135\n",
      "\n",
      "--- Processing N=65 ---\n",
      "  [N=65] Launching 60 parallel tasks...\n",
      "  [N=66] Best candidate score: 0.207424\n",
      "  [N=66] Baseline score: 0.365910, Candidate score: 0.207424\n",
      "  [N=66] ✓ IMPROVED over baseline: 0.365910 -> 0.207424 (Δ=0.158485, 43.31%)\n",
      "  [N=66] Cumulative Score: 26.321152 | Total Improvements: 135\n",
      "\n",
      "--- Processing N=65 ---\n",
      "  [N=65] Launching 60 parallel tasks...\n",
      "  [N=65] Best candidate score: 0.208513\n",
      "  [N=65] Baseline score: 0.371393, Candidate score: 0.208513\n",
      "  [N=65] ✓ IMPROVED over baseline: 0.371393 -> 0.208513 (Δ=0.162880, 43.86%)\n",
      "  [N=65] Cumulative Score: 26.529665 | Total Improvements: 136\n",
      "  [N=65] Best candidate score: 0.208513\n",
      "  [N=65] Baseline score: 0.371393, Candidate score: 0.208513\n",
      "  [N=65] ✓ IMPROVED over baseline: 0.371393 -> 0.208513 (Δ=0.162880, 43.86%)\n",
      "  [N=65] Cumulative Score: 26.529665 | Total Improvements: 136\n",
      "\n",
      "--- Processing N=64 ---\n",
      "  [N=64] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=64 ---\n",
      "  [N=64] Launching 60 parallel tasks...\n",
      "  [N=64] Best candidate score: 0.206912\n",
      "  [N=64] Baseline score: 0.356102, Candidate score: 0.206912\n",
      "  [N=64] ✓ IMPROVED over baseline: 0.356102 -> 0.206912 (Δ=0.149190, 41.90%)\n",
      "  [N=64] Cumulative Score: 26.736577 | Total Improvements: 137\n",
      "\n",
      "--- Processing N=63 ---\n",
      "  [N=63] Launching 60 parallel tasks...\n",
      "  [N=64] Best candidate score: 0.206912\n",
      "  [N=64] Baseline score: 0.356102, Candidate score: 0.206912\n",
      "  [N=64] ✓ IMPROVED over baseline: 0.356102 -> 0.206912 (Δ=0.149190, 41.90%)\n",
      "  [N=64] Cumulative Score: 26.736577 | Total Improvements: 137\n",
      "\n",
      "--- Processing N=63 ---\n",
      "  [N=63] Launching 60 parallel tasks...\n",
      "  [N=63] Best candidate score: 0.208300\n",
      "  [N=63] Baseline score: 0.361687, Candidate score: 0.208300\n",
      "  [N=63] ✓ IMPROVED over baseline: 0.361687 -> 0.208300 (Δ=0.153387, 42.41%)\n",
      "  [N=63] Cumulative Score: 26.944877 | Total Improvements: 138\n",
      "\n",
      "--- Processing N=62 ---\n",
      "  [N=62] Launching 60 parallel tasks...\n",
      "  [N=63] Best candidate score: 0.208300\n",
      "  [N=63] Baseline score: 0.361687, Candidate score: 0.208300\n",
      "  [N=63] ✓ IMPROVED over baseline: 0.361687 -> 0.208300 (Δ=0.153387, 42.41%)\n",
      "  [N=63] Cumulative Score: 26.944877 | Total Improvements: 138\n",
      "\n",
      "--- Processing N=62 ---\n",
      "  [N=62] Launching 60 parallel tasks...\n",
      "  [N=62] Best candidate score: 0.206139\n",
      "  [N=62] Baseline score: 0.366077, Candidate score: 0.206139\n",
      "  [N=62] ✓ IMPROVED over baseline: 0.366077 -> 0.206139 (Δ=0.159938, 43.69%)\n",
      "  [N=62] Cumulative Score: 27.151016 | Total Improvements: 139\n",
      "\n",
      "--- Processing N=61 ---\n",
      "  [N=61] Launching 60 parallel tasks...\n",
      "  [N=62] Best candidate score: 0.206139\n",
      "  [N=62] Baseline score: 0.366077, Candidate score: 0.206139\n",
      "  [N=62] ✓ IMPROVED over baseline: 0.366077 -> 0.206139 (Δ=0.159938, 43.69%)\n",
      "  [N=62] Cumulative Score: 27.151016 | Total Improvements: 139\n",
      "\n",
      "--- Processing N=61 ---\n",
      "  [N=61] Launching 60 parallel tasks...\n",
      "  [N=61] Best candidate score: 0.209518\n",
      "  [N=61] Baseline score: 0.371869, Candidate score: 0.209518\n",
      "  [N=61] ✓ IMPROVED over baseline: 0.371869 -> 0.209518 (Δ=0.162351, 43.66%)\n",
      "  [N=61] Cumulative Score: 27.360534 | Total Improvements: 140\n",
      "\n",
      "--- Processing N=60 ---\n",
      "  [N=60] Launching 60 parallel tasks...\n",
      "  [N=61] Best candidate score: 0.209518\n",
      "  [N=61] Baseline score: 0.371869, Candidate score: 0.209518\n",
      "  [N=61] ✓ IMPROVED over baseline: 0.371869 -> 0.209518 (Δ=0.162351, 43.66%)\n",
      "  [N=61] Cumulative Score: 27.360534 | Total Improvements: 140\n",
      "\n",
      "--- Processing N=60 ---\n",
      "  [N=60] Launching 60 parallel tasks...\n",
      "  [N=60] Best candidate score: 0.213010\n",
      "  [N=60] Baseline score: 0.370494, Candidate score: 0.213010\n",
      "  [N=60] ✓ IMPROVED over baseline: 0.370494 -> 0.213010 (Δ=0.157484, 42.51%)\n",
      "⚠️  Collision at N=60 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=60] Found 220 collision(s)\n",
      "  [N=60] Too many collisions - reverting to baseline\n",
      "  [N=60] Cumulative Score: 27.731028 | Total Improvements: 141\n",
      "  [N=60] Best candidate score: 0.213010\n",
      "  [N=60] Baseline score: 0.370494, Candidate score: 0.213010\n",
      "  [N=60] ✓ IMPROVED over baseline: 0.370494 -> 0.213010 (Δ=0.157484, 42.51%)\n",
      "⚠️  Collision at N=60 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=60] Found 220 collision(s)\n",
      "  [N=60] Too many collisions - reverting to baseline\n",
      "  [N=60] Cumulative Score: 27.731028 | Total Improvements: 141\n",
      "\n",
      "--- Processing N=59 ---\n",
      "  [N=59] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=59 ---\n",
      "  [N=59] Launching 60 parallel tasks...\n",
      "  [N=59] Best candidate score: 0.203551\n",
      "  [N=59] Baseline score: 0.369838, Candidate score: 0.203551\n",
      "  [N=59] ✓ IMPROVED over baseline: 0.369838 -> 0.203551 (Δ=0.166287, 44.96%)\n",
      "  [N=59] Cumulative Score: 27.934579 | Total Improvements: 142\n",
      "\n",
      "--- Processing N=58 ---\n",
      "  [N=58] Launching 60 parallel tasks...\n",
      "  [N=59] Best candidate score: 0.203551\n",
      "  [N=59] Baseline score: 0.369838, Candidate score: 0.203551\n",
      "  [N=59] ✓ IMPROVED over baseline: 0.369838 -> 0.203551 (Δ=0.166287, 44.96%)\n",
      "  [N=59] Cumulative Score: 27.934579 | Total Improvements: 142\n",
      "\n",
      "--- Processing N=58 ---\n",
      "  [N=58] Launching 60 parallel tasks...\n",
      "  [N=58] Best candidate score: 0.205216\n",
      "  [N=58] Baseline score: 0.371247, Candidate score: 0.205216\n",
      "  [N=58] ✓ IMPROVED over baseline: 0.371247 -> 0.205216 (Δ=0.166031, 44.72%)\n",
      "  [N=58] Cumulative Score: 28.139795 | Total Improvements: 143\n",
      "\n",
      "--- Processing N=57 ---\n",
      "  [N=57] Launching 60 parallel tasks...\n",
      "  [N=58] Best candidate score: 0.205216\n",
      "  [N=58] Baseline score: 0.371247, Candidate score: 0.205216\n",
      "  [N=58] ✓ IMPROVED over baseline: 0.371247 -> 0.205216 (Δ=0.166031, 44.72%)\n",
      "  [N=58] Cumulative Score: 28.139795 | Total Improvements: 143\n",
      "\n",
      "--- Processing N=57 ---\n",
      "  [N=57] Launching 60 parallel tasks...\n",
      "  [N=57] Best candidate score: 0.208816\n",
      "  [N=57] Baseline score: 0.370055, Candidate score: 0.208816\n",
      "  [N=57] ✓ IMPROVED over baseline: 0.370055 -> 0.208816 (Δ=0.161240, 43.57%)\n",
      "  [N=57] Cumulative Score: 28.348610 | Total Improvements: 144\n",
      "\n",
      "--- Processing N=56 ---\n",
      "  [N=56] Launching 60 parallel tasks...\n",
      "  [N=57] Best candidate score: 0.208816\n",
      "  [N=57] Baseline score: 0.370055, Candidate score: 0.208816\n",
      "  [N=57] ✓ IMPROVED over baseline: 0.370055 -> 0.208816 (Δ=0.161240, 43.57%)\n",
      "  [N=57] Cumulative Score: 28.348610 | Total Improvements: 144\n",
      "\n",
      "--- Processing N=56 ---\n",
      "  [N=56] Launching 60 parallel tasks...\n",
      "  [N=56] Best candidate score: 0.212545\n",
      "  [N=56] Baseline score: 0.374836, Candidate score: 0.212545\n",
      "  [N=56] ✓ IMPROVED over baseline: 0.374836 -> 0.212545 (Δ=0.162292, 43.30%)\n",
      "  [N=56] Cumulative Score: 28.561155 | Total Improvements: 145\n",
      "\n",
      "--- Processing N=55 ---\n",
      "  [N=55] Launching 60 parallel tasks...\n",
      "  [N=56] Best candidate score: 0.212545\n",
      "  [N=56] Baseline score: 0.374836, Candidate score: 0.212545\n",
      "  [N=56] ✓ IMPROVED over baseline: 0.374836 -> 0.212545 (Δ=0.162292, 43.30%)\n",
      "  [N=56] Cumulative Score: 28.561155 | Total Improvements: 145\n",
      "\n",
      "--- Processing N=55 ---\n",
      "  [N=55] Launching 60 parallel tasks...\n",
      "  [N=55] Best candidate score: 0.215731\n",
      "  [N=55] Baseline score: 0.367450, Candidate score: 0.215731\n",
      "  [N=55] ✓ IMPROVED over baseline: 0.367450 -> 0.215731 (Δ=0.151719, 41.29%)\n",
      "  [N=55] Cumulative Score: 28.776886 | Total Improvements: 146\n",
      "  [N=55] Best candidate score: 0.215731\n",
      "  [N=55] Baseline score: 0.367450, Candidate score: 0.215731\n",
      "  [N=55] ✓ IMPROVED over baseline: 0.367450 -> 0.215731 (Δ=0.151719, 41.29%)\n",
      "  [N=55] Cumulative Score: 28.776886 | Total Improvements: 146\n",
      "\n",
      "--- Processing N=54 ---\n",
      "  [N=54] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=54 ---\n",
      "  [N=54] Launching 60 parallel tasks...\n",
      "  [N=54] Best candidate score: 0.219726\n",
      "  [N=54] Baseline score: 0.374160, Candidate score: 0.219726\n",
      "  [N=54] ✓ IMPROVED over baseline: 0.374160 -> 0.219726 (Δ=0.154434, 41.27%)\n",
      "  [N=54] Cumulative Score: 28.996613 | Total Improvements: 147\n",
      "\n",
      "--- Processing N=53 ---\n",
      "  [N=53] Launching 60 parallel tasks...\n",
      "  [N=54] Best candidate score: 0.219726\n",
      "  [N=54] Baseline score: 0.374160, Candidate score: 0.219726\n",
      "  [N=54] ✓ IMPROVED over baseline: 0.374160 -> 0.219726 (Δ=0.154434, 41.27%)\n",
      "  [N=54] Cumulative Score: 28.996613 | Total Improvements: 147\n",
      "\n",
      "--- Processing N=53 ---\n",
      "  [N=53] Launching 60 parallel tasks...\n",
      "  [N=53] Best candidate score: 0.223872\n",
      "  [N=53] Baseline score: 0.364453, Candidate score: 0.223872\n",
      "  [N=53] ✓ IMPROVED over baseline: 0.364453 -> 0.223872 (Δ=0.140581, 38.57%)\n",
      "  [N=53] Cumulative Score: 29.220485 | Total Improvements: 148\n",
      "\n",
      "--- Processing N=52 ---\n",
      "  [N=52] Launching 60 parallel tasks...\n",
      "  [N=53] Best candidate score: 0.223872\n",
      "  [N=53] Baseline score: 0.364453, Candidate score: 0.223872\n",
      "  [N=53] ✓ IMPROVED over baseline: 0.364453 -> 0.223872 (Δ=0.140581, 38.57%)\n",
      "  [N=53] Cumulative Score: 29.220485 | Total Improvements: 148\n",
      "\n",
      "--- Processing N=52 ---\n",
      "  [N=52] Launching 60 parallel tasks...\n",
      "  [N=52] Best candidate score: 0.228177\n",
      "  [N=52] Baseline score: 0.368940, Candidate score: 0.228177\n",
      "  [N=52] ✓ IMPROVED over baseline: 0.368940 -> 0.228177 (Δ=0.140763, 38.15%)\n",
      "  [N=52] Cumulative Score: 29.448663 | Total Improvements: 149\n",
      "\n",
      "--- Processing N=51 ---\n",
      "  [N=51] Launching 60 parallel tasks...\n",
      "  [N=52] Best candidate score: 0.228177\n",
      "  [N=52] Baseline score: 0.368940, Candidate score: 0.228177\n",
      "  [N=52] ✓ IMPROVED over baseline: 0.368940 -> 0.228177 (Δ=0.140763, 38.15%)\n",
      "  [N=52] Cumulative Score: 29.448663 | Total Improvements: 149\n",
      "\n",
      "--- Processing N=51 ---\n",
      "  [N=51] Launching 60 parallel tasks...\n",
      "  [N=51] Best candidate score: 0.232652\n",
      "  [N=51] Baseline score: 0.370995, Candidate score: 0.232652\n",
      "  [N=51] ✓ IMPROVED over baseline: 0.370995 -> 0.232652 (Δ=0.138343, 37.29%)\n",
      "  [N=51] Cumulative Score: 29.681314 | Total Improvements: 150\n",
      "\n",
      "--- Processing N=50 ---\n",
      "  [N=50] Critical N! Widening beam to 24\n",
      "  [N=50] Launching 60 parallel tasks...\n",
      "  [N=51] Best candidate score: 0.232652\n",
      "  [N=51] Baseline score: 0.370995, Candidate score: 0.232652\n",
      "  [N=51] ✓ IMPROVED over baseline: 0.370995 -> 0.232652 (Δ=0.138343, 37.29%)\n",
      "  [N=51] Cumulative Score: 29.681314 | Total Improvements: 150\n",
      "\n",
      "--- Processing N=50 ---\n",
      "  [N=50] Critical N! Widening beam to 24\n",
      "  [N=50] Launching 60 parallel tasks...\n",
      "  [N=50] Best candidate score: 0.237305\n",
      "  [N=50] Baseline score: 0.371964, Candidate score: 0.237305\n",
      "  [N=50] ✓ IMPROVED over baseline: 0.371964 -> 0.237305 (Δ=0.134659, 36.20%)\n",
      "⚠️  Collision at N=50 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=50] Found 188 collision(s)\n",
      "  [N=50] Too many collisions - reverting to baseline\n",
      "  [N=50] Cumulative Score: 30.053278 | Total Improvements: 151\n",
      "  [N=50] Best candidate score: 0.237305\n",
      "  [N=50] Baseline score: 0.371964, Candidate score: 0.237305\n",
      "  [N=50] ✓ IMPROVED over baseline: 0.371964 -> 0.237305 (Δ=0.134659, 36.20%)\n",
      "⚠️  Collision at N=50 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=50] Found 188 collision(s)\n",
      "  [N=50] Too many collisions - reverting to baseline\n",
      "  [N=50] Cumulative Score: 30.053278 | Total Improvements: 151\n",
      "\n",
      "--- Processing N=49 ---\n",
      "  [N=49] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=49 ---\n",
      "  [N=49] Launching 60 parallel tasks...\n",
      "  [N=49] Best candidate score: 0.242147\n",
      "  [N=49] Baseline score: 0.370890, Candidate score: 0.242147\n",
      "  [N=49] ✓ IMPROVED over baseline: 0.370890 -> 0.242147 (Δ=0.128742, 34.71%)\n",
      "  [N=49] Cumulative Score: 30.295426 | Total Improvements: 152\n",
      "\n",
      "--- Processing N=48 ---\n",
      "  [N=48] Launching 60 parallel tasks...\n",
      "  [N=49] Best candidate score: 0.242147\n",
      "  [N=49] Baseline score: 0.370890, Candidate score: 0.242147\n",
      "  [N=49] ✓ IMPROVED over baseline: 0.370890 -> 0.242147 (Δ=0.128742, 34.71%)\n",
      "  [N=49] Cumulative Score: 30.295426 | Total Improvements: 152\n",
      "\n",
      "--- Processing N=48 ---\n",
      "  [N=48] Launching 60 parallel tasks...\n",
      "  [N=48] Best candidate score: 0.247192\n",
      "  [N=48] Baseline score: 0.374823, Candidate score: 0.247192\n",
      "  [N=48] ✓ IMPROVED over baseline: 0.374823 -> 0.247192 (Δ=0.127631, 34.05%)\n",
      "  [N=48] Cumulative Score: 30.542618 | Total Improvements: 153\n",
      "\n",
      "--- Processing N=47 ---\n",
      "  [N=47] Launching 60 parallel tasks...\n",
      "  [N=48] Best candidate score: 0.247192\n",
      "  [N=48] Baseline score: 0.374823, Candidate score: 0.247192\n",
      "  [N=48] ✓ IMPROVED over baseline: 0.374823 -> 0.247192 (Δ=0.127631, 34.05%)\n",
      "  [N=48] Cumulative Score: 30.542618 | Total Improvements: 153\n",
      "\n",
      "--- Processing N=47 ---\n",
      "  [N=47] Launching 60 parallel tasks...\n",
      "  [N=47] Best candidate score: 0.249117\n",
      "  [N=47] Baseline score: 0.374996, Candidate score: 0.249117\n",
      "  [N=47] ✓ IMPROVED over baseline: 0.374996 -> 0.249117 (Δ=0.125880, 33.57%)\n",
      "  [N=47] Cumulative Score: 30.791734 | Total Improvements: 154\n",
      "\n",
      "--- Processing N=46 ---\n",
      "  [N=46] Launching 60 parallel tasks...\n",
      "  [N=47] Best candidate score: 0.249117\n",
      "  [N=47] Baseline score: 0.374996, Candidate score: 0.249117\n",
      "  [N=47] ✓ IMPROVED over baseline: 0.374996 -> 0.249117 (Δ=0.125880, 33.57%)\n",
      "  [N=47] Cumulative Score: 30.791734 | Total Improvements: 154\n",
      "\n",
      "--- Processing N=46 ---\n",
      "  [N=46] Launching 60 parallel tasks...\n",
      "  [N=46] Best candidate score: 0.240340\n",
      "  [N=46] Baseline score: 0.368678, Candidate score: 0.240340\n",
      "  [N=46] ✓ IMPROVED over baseline: 0.368678 -> 0.240340 (Δ=0.128339, 34.81%)\n",
      "  [N=46] Cumulative Score: 31.032074 | Total Improvements: 155\n",
      "\n",
      "--- Processing N=45 ---\n",
      "  [N=45] Launching 60 parallel tasks...\n",
      "  [N=46] Best candidate score: 0.240340\n",
      "  [N=46] Baseline score: 0.368678, Candidate score: 0.240340\n",
      "  [N=46] ✓ IMPROVED over baseline: 0.368678 -> 0.240340 (Δ=0.128339, 34.81%)\n",
      "  [N=46] Cumulative Score: 31.032074 | Total Improvements: 155\n",
      "\n",
      "--- Processing N=45 ---\n",
      "  [N=45] Launching 60 parallel tasks...\n",
      "  [N=45] Best candidate score: 0.245681\n",
      "  [N=45] Baseline score: 0.367004, Candidate score: 0.245681\n",
      "  [N=45] ✓ IMPROVED over baseline: 0.367004 -> 0.245681 (Δ=0.121323, 33.06%)\n",
      "  [N=45] Cumulative Score: 31.277755 | Total Improvements: 156\n",
      "  [N=45] Best candidate score: 0.245681\n",
      "  [N=45] Baseline score: 0.367004, Candidate score: 0.245681\n",
      "  [N=45] ✓ IMPROVED over baseline: 0.367004 -> 0.245681 (Δ=0.121323, 33.06%)\n",
      "  [N=45] Cumulative Score: 31.277755 | Total Improvements: 156\n",
      "\n",
      "--- Processing N=44 ---\n",
      "  [N=44] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=44 ---\n",
      "  [N=44] Launching 60 parallel tasks...\n",
      "  [N=44] Best candidate score: 0.245081\n",
      "  [N=44] Baseline score: 0.371489, Candidate score: 0.245081\n",
      "  [N=44] ✓ IMPROVED over baseline: 0.371489 -> 0.245081 (Δ=0.126408, 34.03%)\n",
      "  [N=44] Cumulative Score: 31.522835 | Total Improvements: 157\n",
      "\n",
      "--- Processing N=43 ---\n",
      "  [N=43] Launching 60 parallel tasks...\n",
      "  [N=44] Best candidate score: 0.245081\n",
      "  [N=44] Baseline score: 0.371489, Candidate score: 0.245081\n",
      "  [N=44] ✓ IMPROVED over baseline: 0.371489 -> 0.245081 (Δ=0.126408, 34.03%)\n",
      "  [N=44] Cumulative Score: 31.522835 | Total Improvements: 157\n",
      "\n",
      "--- Processing N=43 ---\n",
      "  [N=43] Launching 60 parallel tasks...\n",
      "  [N=43] Best candidate score: 0.238140\n",
      "  [N=43] Baseline score: 0.375325, Candidate score: 0.238140\n",
      "  [N=43] ✓ IMPROVED over baseline: 0.375325 -> 0.238140 (Δ=0.137185, 36.55%)\n",
      "  [N=43] Cumulative Score: 31.760975 | Total Improvements: 158\n",
      "\n",
      "--- Processing N=42 ---\n",
      "  [N=42] Launching 60 parallel tasks...\n",
      "  [N=43] Best candidate score: 0.238140\n",
      "  [N=43] Baseline score: 0.375325, Candidate score: 0.238140\n",
      "  [N=43] ✓ IMPROVED over baseline: 0.375325 -> 0.238140 (Δ=0.137185, 36.55%)\n",
      "  [N=43] Cumulative Score: 31.760975 | Total Improvements: 158\n",
      "\n",
      "--- Processing N=42 ---\n",
      "  [N=42] Launching 60 parallel tasks...\n",
      "  [N=42] Best candidate score: 0.230818\n",
      "  [N=42] Baseline score: 0.370436, Candidate score: 0.230818\n",
      "  [N=42] ✓ IMPROVED over baseline: 0.370436 -> 0.230818 (Δ=0.139618, 37.69%)\n",
      "  [N=42] Cumulative Score: 31.991793 | Total Improvements: 159\n",
      "\n",
      "--- Processing N=41 ---\n",
      "  [N=41] Launching 60 parallel tasks...\n",
      "  [N=42] Best candidate score: 0.230818\n",
      "  [N=42] Baseline score: 0.370436, Candidate score: 0.230818\n",
      "  [N=42] ✓ IMPROVED over baseline: 0.370436 -> 0.230818 (Δ=0.139618, 37.69%)\n",
      "  [N=42] Cumulative Score: 31.991793 | Total Improvements: 159\n",
      "\n",
      "--- Processing N=41 ---\n",
      "  [N=41] Launching 60 parallel tasks...\n",
      "  [N=41] Best candidate score: 0.236369\n",
      "  [N=41] Baseline score: 0.371983, Candidate score: 0.236369\n",
      "  [N=41] ✓ IMPROVED over baseline: 0.371983 -> 0.236369 (Δ=0.135614, 36.46%)\n",
      "  [N=41] Cumulative Score: 32.228161 | Total Improvements: 160\n",
      "\n",
      "--- Processing N=40 ---\n",
      "  [N=40] Launching 60 parallel tasks...\n",
      "  [N=41] Best candidate score: 0.236369\n",
      "  [N=41] Baseline score: 0.371983, Candidate score: 0.236369\n",
      "  [N=41] ✓ IMPROVED over baseline: 0.371983 -> 0.236369 (Δ=0.135614, 36.46%)\n",
      "  [N=41] Cumulative Score: 32.228161 | Total Improvements: 160\n",
      "\n",
      "--- Processing N=40 ---\n",
      "  [N=40] Launching 60 parallel tasks...\n",
      "  [N=40] Best candidate score: 0.236391\n",
      "  [N=40] Baseline score: 0.373969, Candidate score: 0.236391\n",
      "  [N=40] ✓ IMPROVED over baseline: 0.373969 -> 0.236391 (Δ=0.137578, 36.79%)\n",
      "⚠️  Collision at N=40 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=40] Found 142 collision(s)\n",
      "  [N=40] Too many collisions - reverting to baseline\n",
      "  [N=40] Cumulative Score: 32.602130 | Total Improvements: 161\n",
      "  [N=40] Best candidate score: 0.236391\n",
      "  [N=40] Baseline score: 0.373969, Candidate score: 0.236391\n",
      "  [N=40] ✓ IMPROVED over baseline: 0.373969 -> 0.236391 (Δ=0.137578, 36.79%)\n",
      "⚠️  Collision at N=40 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=40] Found 142 collision(s)\n",
      "  [N=40] Too many collisions - reverting to baseline\n",
      "  [N=40] Cumulative Score: 32.602130 | Total Improvements: 161\n",
      "\n",
      "--- Processing N=39 ---\n",
      "  [N=39] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=39 ---\n",
      "  [N=39] Launching 60 parallel tasks...\n",
      "  [N=39] Best candidate score: 0.242452\n",
      "  [N=39] Baseline score: 0.363710, Candidate score: 0.242452\n",
      "  [N=39] ✓ IMPROVED over baseline: 0.363710 -> 0.242452 (Δ=0.121258, 33.34%)\n",
      "  [N=39] Cumulative Score: 32.844582 | Total Improvements: 162\n",
      "\n",
      "--- Processing N=38 ---\n",
      "  [N=38] Launching 60 parallel tasks...\n",
      "  [N=39] Best candidate score: 0.242452\n",
      "  [N=39] Baseline score: 0.363710, Candidate score: 0.242452\n",
      "  [N=39] ✓ IMPROVED over baseline: 0.363710 -> 0.242452 (Δ=0.121258, 33.34%)\n",
      "  [N=39] Cumulative Score: 32.844582 | Total Improvements: 162\n",
      "\n",
      "--- Processing N=38 ---\n",
      "  [N=38] Launching 60 parallel tasks...\n",
      "  [N=38] Best candidate score: 0.248832\n",
      "  [N=38] Baseline score: 0.372975, Candidate score: 0.248832\n",
      "  [N=38] ✓ IMPROVED over baseline: 0.372975 -> 0.248832 (Δ=0.124142, 33.28%)\n",
      "  [N=38] Cumulative Score: 33.093414 | Total Improvements: 163\n",
      "\n",
      "--- Processing N=37 ---\n",
      "  [N=37] Launching 60 parallel tasks...\n",
      "  [N=38] Best candidate score: 0.248832\n",
      "  [N=38] Baseline score: 0.372975, Candidate score: 0.248832\n",
      "  [N=38] ✓ IMPROVED over baseline: 0.372975 -> 0.248832 (Δ=0.124142, 33.28%)\n",
      "  [N=38] Cumulative Score: 33.093414 | Total Improvements: 163\n",
      "\n",
      "--- Processing N=37 ---\n",
      "  [N=37] Launching 60 parallel tasks...\n",
      "  [N=37] Best candidate score: 0.255557\n",
      "  [N=37] Baseline score: 0.371591, Candidate score: 0.255557\n",
      "  [N=37] ✓ IMPROVED over baseline: 0.371591 -> 0.255557 (Δ=0.116033, 31.23%)\n",
      "  [N=37] Cumulative Score: 33.348972 | Total Improvements: 164\n",
      "\n",
      "--- Processing N=36 ---\n",
      "  [N=36] Launching 60 parallel tasks...\n",
      "  [N=37] Best candidate score: 0.255557\n",
      "  [N=37] Baseline score: 0.371591, Candidate score: 0.255557\n",
      "  [N=37] ✓ IMPROVED over baseline: 0.371591 -> 0.255557 (Δ=0.116033, 31.23%)\n",
      "  [N=37] Cumulative Score: 33.348972 | Total Improvements: 164\n",
      "\n",
      "--- Processing N=36 ---\n",
      "  [N=36] Launching 60 parallel tasks...\n",
      "  [N=36] Best candidate score: 0.262656\n",
      "  [N=36] Baseline score: 0.366038, Candidate score: 0.262656\n",
      "  [N=36] ✓ IMPROVED over baseline: 0.366038 -> 0.262656 (Δ=0.103382, 28.24%)\n",
      "  [N=36] Cumulative Score: 33.611628 | Total Improvements: 165\n",
      "\n",
      "--- Processing N=35 ---\n",
      "  [N=35] Launching 60 parallel tasks...\n",
      "  [N=36] Best candidate score: 0.262656\n",
      "  [N=36] Baseline score: 0.366038, Candidate score: 0.262656\n",
      "  [N=36] ✓ IMPROVED over baseline: 0.366038 -> 0.262656 (Δ=0.103382, 28.24%)\n",
      "  [N=36] Cumulative Score: 33.611628 | Total Improvements: 165\n",
      "\n",
      "--- Processing N=35 ---\n",
      "  [N=35] Launching 60 parallel tasks...\n",
      "  [N=35] Best candidate score: 0.249440\n",
      "  [N=35] Baseline score: 0.376023, Candidate score: 0.249440\n",
      "  [N=35] ✓ IMPROVED over baseline: 0.376023 -> 0.249440 (Δ=0.126583, 33.66%)\n",
      "  [N=35] Cumulative Score: 33.861068 | Total Improvements: 166\n",
      "  [N=35] Best candidate score: 0.249440\n",
      "  [N=35] Baseline score: 0.376023, Candidate score: 0.249440\n",
      "  [N=35] ✓ IMPROVED over baseline: 0.376023 -> 0.249440 (Δ=0.126583, 33.66%)\n",
      "  [N=35] Cumulative Score: 33.861068 | Total Improvements: 166\n",
      "\n",
      "--- Processing N=34 ---\n",
      "  [N=34] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=34 ---\n",
      "  [N=34] Launching 60 parallel tasks...\n",
      "  [N=34] Best candidate score: 0.255956\n",
      "  [N=34] Baseline score: 0.372236, Candidate score: 0.255956\n",
      "  [N=34] ✓ IMPROVED over baseline: 0.372236 -> 0.255956 (Δ=0.116280, 31.24%)\n",
      "  [N=34] Cumulative Score: 34.117024 | Total Improvements: 167\n",
      "\n",
      "--- Processing N=33 ---\n",
      "  [N=33] Launching 60 parallel tasks...\n",
      "  [N=34] Best candidate score: 0.255956\n",
      "  [N=34] Baseline score: 0.372236, Candidate score: 0.255956\n",
      "  [N=34] ✓ IMPROVED over baseline: 0.372236 -> 0.255956 (Δ=0.116280, 31.24%)\n",
      "  [N=34] Cumulative Score: 34.117024 | Total Improvements: 167\n",
      "\n",
      "--- Processing N=33 ---\n",
      "  [N=33] Launching 60 parallel tasks...\n",
      "  [N=33] Best candidate score: 0.262079\n",
      "  [N=33] Baseline score: 0.372843, Candidate score: 0.262079\n",
      "  [N=33] ✓ IMPROVED over baseline: 0.372843 -> 0.262079 (Δ=0.110764, 29.71%)\n",
      "  [N=33] Cumulative Score: 34.379103 | Total Improvements: 168\n",
      "\n",
      "--- Processing N=32 ---\n",
      "  [N=32] Launching 60 parallel tasks...\n",
      "  [N=33] Best candidate score: 0.262079\n",
      "  [N=33] Baseline score: 0.372843, Candidate score: 0.262079\n",
      "  [N=33] ✓ IMPROVED over baseline: 0.372843 -> 0.262079 (Δ=0.110764, 29.71%)\n",
      "  [N=33] Cumulative Score: 34.379103 | Total Improvements: 168\n",
      "\n",
      "--- Processing N=32 ---\n",
      "  [N=32] Launching 60 parallel tasks...\n",
      "  [N=32] Best candidate score: 0.254125\n",
      "  [N=32] Baseline score: 0.367760, Candidate score: 0.254125\n",
      "  [N=32] ✓ IMPROVED over baseline: 0.367760 -> 0.254125 (Δ=0.113635, 30.90%)\n",
      "  [N=32] Cumulative Score: 34.633227 | Total Improvements: 169\n",
      "\n",
      "--- Processing N=31 ---\n",
      "  [N=31] Launching 60 parallel tasks...\n",
      "  [N=32] Best candidate score: 0.254125\n",
      "  [N=32] Baseline score: 0.367760, Candidate score: 0.254125\n",
      "  [N=32] ✓ IMPROVED over baseline: 0.367760 -> 0.254125 (Δ=0.113635, 30.90%)\n",
      "  [N=32] Cumulative Score: 34.633227 | Total Improvements: 169\n",
      "\n",
      "--- Processing N=31 ---\n",
      "  [N=31] Launching 60 parallel tasks...\n",
      "  [N=31] Best candidate score: 0.257440\n",
      "  [N=31] Baseline score: 0.373142, Candidate score: 0.257440\n",
      "  [N=31] ✓ IMPROVED over baseline: 0.373142 -> 0.257440 (Δ=0.115702, 31.01%)\n",
      "  [N=31] Cumulative Score: 34.890667 | Total Improvements: 170\n",
      "\n",
      "--- Processing N=30 ---\n",
      "  [N=30] Launching 60 parallel tasks...\n",
      "  [N=31] Best candidate score: 0.257440\n",
      "  [N=31] Baseline score: 0.373142, Candidate score: 0.257440\n",
      "  [N=31] ✓ IMPROVED over baseline: 0.373142 -> 0.257440 (Δ=0.115702, 31.01%)\n",
      "  [N=31] Cumulative Score: 34.890667 | Total Improvements: 170\n",
      "\n",
      "--- Processing N=30 ---\n",
      "  [N=30] Launching 60 parallel tasks...\n",
      "  [N=30] Best candidate score: 0.266021\n",
      "  [N=30] Baseline score: 0.375481, Candidate score: 0.266021\n",
      "  [N=30] ✓ IMPROVED over baseline: 0.375481 -> 0.266021 (Δ=0.109460, 29.15%)\n",
      "⚠️  Collision at N=30 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=30] Found 91 collision(s)\n",
      "  [N=30] Too many collisions - reverting to baseline\n",
      "  [N=30] Cumulative Score: 35.266147 | Total Improvements: 171\n",
      "  [N=30] Best candidate score: 0.266021\n",
      "  [N=30] Baseline score: 0.375481, Candidate score: 0.266021\n",
      "  [N=30] ✓ IMPROVED over baseline: 0.375481 -> 0.266021 (Δ=0.109460, 29.15%)\n",
      "⚠️  Collision at N=30 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=30] Found 91 collision(s)\n",
      "  [N=30] Too many collisions - reverting to baseline\n",
      "  [N=30] Cumulative Score: 35.266147 | Total Improvements: 171\n",
      "\n",
      "--- Processing N=29 ---\n",
      "  [N=29] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=29 ---\n",
      "  [N=29] Launching 60 parallel tasks...\n",
      "  [N=29] Best candidate score: 0.271315\n",
      "  [N=29] Baseline score: 0.377788, Candidate score: 0.271315\n",
      "  [N=29] ✓ IMPROVED over baseline: 0.377788 -> 0.271315 (Δ=0.106472, 28.18%)\n",
      "  [N=29] Cumulative Score: 35.537463 | Total Improvements: 172\n",
      "\n",
      "--- Processing N=28 ---\n",
      "  [N=28] Launching 60 parallel tasks...\n",
      "  [N=29] Best candidate score: 0.271315\n",
      "  [N=29] Baseline score: 0.377788, Candidate score: 0.271315\n",
      "  [N=29] ✓ IMPROVED over baseline: 0.377788 -> 0.271315 (Δ=0.106472, 28.18%)\n",
      "  [N=29] Cumulative Score: 35.537463 | Total Improvements: 172\n",
      "\n",
      "--- Processing N=28 ---\n",
      "  [N=28] Launching 60 parallel tasks...\n",
      "  [N=28] Best candidate score: 0.271548\n",
      "  [N=28] Baseline score: 0.374450, Candidate score: 0.271548\n",
      "  [N=28] ✓ IMPROVED over baseline: 0.374450 -> 0.271548 (Δ=0.102902, 27.48%)\n",
      "  [N=28] Cumulative Score: 35.809011 | Total Improvements: 173\n",
      "\n",
      "--- Processing N=27 ---\n",
      "  [N=27] Launching 60 parallel tasks...\n",
      "  [N=28] Best candidate score: 0.271548\n",
      "  [N=28] Baseline score: 0.374450, Candidate score: 0.271548\n",
      "  [N=28] ✓ IMPROVED over baseline: 0.374450 -> 0.271548 (Δ=0.102902, 27.48%)\n",
      "  [N=28] Cumulative Score: 35.809011 | Total Improvements: 173\n",
      "\n",
      "--- Processing N=27 ---\n",
      "  [N=27] Launching 60 parallel tasks...\n",
      "  [N=27] Best candidate score: 0.270000\n",
      "  [N=27] Baseline score: 0.378277, Candidate score: 0.270000\n",
      "  [N=27] ✓ IMPROVED over baseline: 0.378277 -> 0.270000 (Δ=0.108277, 28.62%)\n",
      "  [N=27] Cumulative Score: 36.079011 | Total Improvements: 174\n",
      "\n",
      "--- Processing N=26 ---\n",
      "  [N=26] Launching 60 parallel tasks...\n",
      "  [N=27] Best candidate score: 0.270000\n",
      "  [N=27] Baseline score: 0.378277, Candidate score: 0.270000\n",
      "  [N=27] ✓ IMPROVED over baseline: 0.378277 -> 0.270000 (Δ=0.108277, 28.62%)\n",
      "  [N=27] Cumulative Score: 36.079011 | Total Improvements: 174\n",
      "\n",
      "--- Processing N=26 ---\n",
      "  [N=26] Launching 60 parallel tasks...\n",
      "  [N=26] Best candidate score: 0.255024\n",
      "  [N=26] Baseline score: 0.376668, Candidate score: 0.255024\n",
      "  [N=26] ✓ IMPROVED over baseline: 0.376668 -> 0.255024 (Δ=0.121644, 32.29%)\n",
      "  [N=26] Cumulative Score: 36.334035 | Total Improvements: 175\n",
      "\n",
      "--- Processing N=25 ---\n",
      "  [N=25] Critical N! Widening beam to 24\n",
      "  [N=25] Launching 60 parallel tasks...\n",
      "  [N=26] Best candidate score: 0.255024\n",
      "  [N=26] Baseline score: 0.376668, Candidate score: 0.255024\n",
      "  [N=26] ✓ IMPROVED over baseline: 0.376668 -> 0.255024 (Δ=0.121644, 32.29%)\n",
      "  [N=26] Cumulative Score: 36.334035 | Total Improvements: 175\n",
      "\n",
      "--- Processing N=25 ---\n",
      "  [N=25] Critical N! Widening beam to 24\n",
      "  [N=25] Launching 60 parallel tasks...\n",
      "  [N=25] Hybrid Search: Generating forward candidates...\n",
      "  [N=25] Hybrid Search: Generating forward candidates...\n",
      "  [N=25] Added 3 forward candidates.\n",
      "  [N=25] Best candidate score: 0.265225\n",
      "  [N=25] Baseline score: 0.373242, Candidate score: 0.265225\n",
      "  [N=25] ✓ IMPROVED over baseline: 0.373242 -> 0.265225 (Δ=0.108017, 28.94%)\n",
      "  [N=25] Cumulative Score: 36.599260 | Total Improvements: 176\n",
      "  [N=25] Added 3 forward candidates.\n",
      "  [N=25] Best candidate score: 0.265225\n",
      "  [N=25] Baseline score: 0.373242, Candidate score: 0.265225\n",
      "  [N=25] ✓ IMPROVED over baseline: 0.373242 -> 0.265225 (Δ=0.108017, 28.94%)\n",
      "  [N=25] Cumulative Score: 36.599260 | Total Improvements: 176\n",
      "\n",
      "--- Processing N=24 ---\n",
      "  [N=24] Launching 105 parallel tasks...\n",
      "\n",
      "--- Processing N=24 ---\n",
      "  [N=24] Launching 105 parallel tasks...\n",
      "  [N=24] Hybrid Search: Generating forward candidates...\n",
      "  [N=24] Hybrid Search: Generating forward candidates...\n",
      "  [N=24] Added 3 forward candidates.\n",
      "  [N=24] Best candidate score: 0.250104\n",
      "  [N=24] Baseline score: 0.367225, Candidate score: 0.250104\n",
      "  [N=24] ✓ IMPROVED over baseline: 0.367225 -> 0.250104 (Δ=0.117121, 31.89%)\n",
      "  [N=24] Cumulative Score: 36.849364 | Total Improvements: 177\n",
      "\n",
      "--- Processing N=23 ---\n",
      "  [N=23] Launching 60 parallel tasks...\n",
      "  [N=24] Added 3 forward candidates.\n",
      "  [N=24] Best candidate score: 0.250104\n",
      "  [N=24] Baseline score: 0.367225, Candidate score: 0.250104\n",
      "  [N=24] ✓ IMPROVED over baseline: 0.367225 -> 0.250104 (Δ=0.117121, 31.89%)\n",
      "  [N=24] Cumulative Score: 36.849364 | Total Improvements: 177\n",
      "\n",
      "--- Processing N=23 ---\n",
      "  [N=23] Launching 60 parallel tasks...\n",
      "  [N=23] Hybrid Search: Generating forward candidates...\n",
      "  [N=23] Hybrid Search: Generating forward candidates...\n",
      "  [N=23] Added 3 forward candidates.\n",
      "  [N=23] Best candidate score: 0.260978\n",
      "  [N=23] Baseline score: 0.370418, Candidate score: 0.260978\n",
      "  [N=23] ✓ IMPROVED over baseline: 0.370418 -> 0.260978 (Δ=0.109440, 29.54%)\n",
      "  [N=23] Cumulative Score: 37.110342 | Total Improvements: 178\n",
      "\n",
      "--- Processing N=22 ---\n",
      "  [N=22] Launching 60 parallel tasks...\n",
      "  [N=23] Added 3 forward candidates.\n",
      "  [N=23] Best candidate score: 0.260978\n",
      "  [N=23] Baseline score: 0.370418, Candidate score: 0.260978\n",
      "  [N=23] ✓ IMPROVED over baseline: 0.370418 -> 0.260978 (Δ=0.109440, 29.54%)\n",
      "  [N=23] Cumulative Score: 37.110342 | Total Improvements: 178\n",
      "\n",
      "--- Processing N=22 ---\n",
      "  [N=22] Launching 60 parallel tasks...\n",
      "  [N=22] Hybrid Search: Generating forward candidates...\n",
      "  [N=22] Hybrid Search: Generating forward candidates...\n",
      "  [N=22] Added 3 forward candidates.\n",
      "  [N=22] Best candidate score: 0.272841\n",
      "  [N=22] Baseline score: 0.380405, Candidate score: 0.272841\n",
      "  [N=22] ✓ IMPROVED over baseline: 0.380405 -> 0.272841 (Δ=0.107564, 28.28%)\n",
      "  [N=22] Cumulative Score: 37.383183 | Total Improvements: 179\n",
      "\n",
      "--- Processing N=21 ---\n",
      "  [N=21] Launching 60 parallel tasks...\n",
      "  [N=22] Added 3 forward candidates.\n",
      "  [N=22] Best candidate score: 0.272841\n",
      "  [N=22] Baseline score: 0.380405, Candidate score: 0.272841\n",
      "  [N=22] ✓ IMPROVED over baseline: 0.380405 -> 0.272841 (Δ=0.107564, 28.28%)\n",
      "  [N=22] Cumulative Score: 37.383183 | Total Improvements: 179\n",
      "\n",
      "--- Processing N=21 ---\n",
      "  [N=21] Launching 60 parallel tasks...\n",
      "  [N=21] Hybrid Search: Generating forward candidates...\n",
      "  [N=21] Hybrid Search: Generating forward candidates...\n",
      "  [N=21] Added 3 forward candidates.\n",
      "  [N=21] Best candidate score: 0.285833\n",
      "  [N=21] Baseline score: 0.378365, Candidate score: 0.285833\n",
      "  [N=21] ✓ IMPROVED over baseline: 0.378365 -> 0.285833 (Δ=0.092531, 24.46%)\n",
      "  [N=21] Cumulative Score: 37.669017 | Total Improvements: 180\n",
      "\n",
      "--- Processing N=20 ---\n",
      "  [N=20] Launching 60 parallel tasks...\n",
      "  [N=21] Added 3 forward candidates.\n",
      "  [N=21] Best candidate score: 0.285833\n",
      "  [N=21] Baseline score: 0.378365, Candidate score: 0.285833\n",
      "  [N=21] ✓ IMPROVED over baseline: 0.378365 -> 0.285833 (Δ=0.092531, 24.46%)\n",
      "  [N=21] Cumulative Score: 37.669017 | Total Improvements: 180\n",
      "\n",
      "--- Processing N=20 ---\n",
      "  [N=20] Launching 60 parallel tasks...\n",
      "  [N=20] Hybrid Search: Generating forward candidates...\n",
      "  [N=20] Hybrid Search: Generating forward candidates...\n",
      "  [N=20] Added 3 forward candidates.\n",
      "  [N=20] Best candidate score: 0.300125\n",
      "  [N=20] Baseline score: 0.378768, Candidate score: 0.300125\n",
      "  [N=20] ✓ IMPROVED over baseline: 0.378768 -> 0.300125 (Δ=0.078643, 20.76%)\n",
      "⚠️  Collision at N=20 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=20] Found 62 collision(s)\n",
      "  [N=20] Too many collisions - reverting to baseline\n",
      "  [N=20] Cumulative Score: 38.047785 | Total Improvements: 181\n",
      "  [N=20] Added 3 forward candidates.\n",
      "  [N=20] Best candidate score: 0.300125\n",
      "  [N=20] Baseline score: 0.378768, Candidate score: 0.300125\n",
      "  [N=20] ✓ IMPROVED over baseline: 0.378768 -> 0.300125 (Δ=0.078643, 20.76%)\n",
      "⚠️  Collision at N=20 between trees 0 and 1 (overlap area=6.085227e-02)\n",
      "  [N=20] Found 62 collision(s)\n",
      "  [N=20] Too many collisions - reverting to baseline\n",
      "  [N=20] Cumulative Score: 38.047785 | Total Improvements: 181\n",
      "\n",
      "--- Processing N=19 ---\n",
      "  [N=19] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=19 ---\n",
      "  [N=19] Launching 60 parallel tasks...\n",
      "  [N=19] Hybrid Search: Generating forward candidates...\n",
      "  [N=19] Hybrid Search: Generating forward candidates...\n",
      "  [N=19] Added 3 forward candidates.\n",
      "  [N=19] Best candidate score: 0.315921\n",
      "  [N=19] Baseline score: 0.379252, Candidate score: 0.315921\n",
      "  [N=19] ✓ IMPROVED over baseline: 0.379252 -> 0.315921 (Δ=0.063331, 16.70%)\n",
      "  [N=19] Cumulative Score: 38.363706 | Total Improvements: 182\n",
      "\n",
      "--- Processing N=18 ---\n",
      "  [N=18] Launching 60 parallel tasks...\n",
      "  [N=19] Added 3 forward candidates.\n",
      "  [N=19] Best candidate score: 0.315921\n",
      "  [N=19] Baseline score: 0.379252, Candidate score: 0.315921\n",
      "  [N=19] ✓ IMPROVED over baseline: 0.379252 -> 0.315921 (Δ=0.063331, 16.70%)\n",
      "  [N=19] Cumulative Score: 38.363706 | Total Improvements: 182\n",
      "\n",
      "--- Processing N=18 ---\n",
      "  [N=18] Launching 60 parallel tasks...\n",
      "  [N=18] Hybrid Search: Generating forward candidates...\n",
      "  [N=18] Hybrid Search: Generating forward candidates...\n",
      "  [N=18] Added 3 forward candidates.\n",
      "  [N=18] Best candidate score: 0.333472\n",
      "  [N=18] Baseline score: 0.371208, Candidate score: 0.333472\n",
      "  [N=18] ✓ IMPROVED over baseline: 0.371208 -> 0.333472 (Δ=0.037736, 10.17%)\n",
      "  [N=18] Cumulative Score: 38.697178 | Total Improvements: 183\n",
      "\n",
      "--- Processing N=17 ---\n",
      "  [N=17] Launching 60 parallel tasks...\n",
      "  [N=18] Added 3 forward candidates.\n",
      "  [N=18] Best candidate score: 0.333472\n",
      "  [N=18] Baseline score: 0.371208, Candidate score: 0.333472\n",
      "  [N=18] ✓ IMPROVED over baseline: 0.371208 -> 0.333472 (Δ=0.037736, 10.17%)\n",
      "  [N=18] Cumulative Score: 38.697178 | Total Improvements: 183\n",
      "\n",
      "--- Processing N=17 ---\n",
      "  [N=17] Launching 60 parallel tasks...\n",
      "  [N=17] Hybrid Search: Generating forward candidates...\n",
      "  [N=17] Hybrid Search: Generating forward candidates...\n",
      "  [N=17] Added 3 forward candidates.\n",
      "  [N=17] Best candidate score: 0.353088\n",
      "  [N=17] Baseline score: 0.370877, Candidate score: 0.353088\n",
      "  [N=17] ✓ IMPROVED over baseline: 0.370877 -> 0.353088 (Δ=0.017789, 4.80%)\n",
      "  [N=17] Cumulative Score: 39.050266 | Total Improvements: 184\n",
      "\n",
      "--- Processing N=16 ---\n",
      "  [N=16] Launching 60 parallel tasks...\n",
      "  [N=17] Added 3 forward candidates.\n",
      "  [N=17] Best candidate score: 0.353088\n",
      "  [N=17] Baseline score: 0.370877, Candidate score: 0.353088\n",
      "  [N=17] ✓ IMPROVED over baseline: 0.370877 -> 0.353088 (Δ=0.017789, 4.80%)\n",
      "  [N=17] Cumulative Score: 39.050266 | Total Improvements: 184\n",
      "\n",
      "--- Processing N=16 ---\n",
      "  [N=16] Launching 60 parallel tasks...\n",
      "  [N=16] Hybrid Search: Generating forward candidates...\n",
      "  [N=16] Hybrid Search: Generating forward candidates...\n",
      "  [N=16] Added 3 forward candidates.\n",
      "  [N=16] Best candidate score: 0.337852\n",
      "  [N=16] Baseline score: 0.380282, Candidate score: 0.337852\n",
      "  [N=16] ✓ IMPROVED over baseline: 0.380282 -> 0.337852 (Δ=0.042431, 11.16%)\n",
      "  [N=16] Cumulative Score: 39.388118 | Total Improvements: 185\n",
      "\n",
      "--- Processing N=15 ---\n",
      "  [N=15] Launching 60 parallel tasks...\n",
      "  [N=16] Added 3 forward candidates.\n",
      "  [N=16] Best candidate score: 0.337852\n",
      "  [N=16] Baseline score: 0.380282, Candidate score: 0.337852\n",
      "  [N=16] ✓ IMPROVED over baseline: 0.380282 -> 0.337852 (Δ=0.042431, 11.16%)\n",
      "  [N=16] Cumulative Score: 39.388118 | Total Improvements: 185\n",
      "\n",
      "--- Processing N=15 ---\n",
      "  [N=15] Launching 60 parallel tasks...\n",
      "  [N=15] Hybrid Search: Generating forward candidates...\n",
      "  [N=15] Hybrid Search: Generating forward candidates...\n",
      "  [N=15] Added 3 forward candidates.\n",
      "  [N=15] Best candidate score: 0.322667\n",
      "  [N=15] Baseline score: 0.379961, Candidate score: 0.322667\n",
      "  [N=15] ✓ IMPROVED over baseline: 0.379961 -> 0.322667 (Δ=0.057294, 15.08%)\n",
      "  [N=15] Cumulative Score: 39.710784 | Total Improvements: 186\n",
      "  [N=15] Added 3 forward candidates.\n",
      "  [N=15] Best candidate score: 0.322667\n",
      "  [N=15] Baseline score: 0.379961, Candidate score: 0.322667\n",
      "  [N=15] ✓ IMPROVED over baseline: 0.379961 -> 0.322667 (Δ=0.057294, 15.08%)\n",
      "  [N=15] Cumulative Score: 39.710784 | Total Improvements: 186\n",
      "\n",
      "--- Processing N=14 ---\n",
      "  [N=14] Launching 60 parallel tasks...\n",
      "\n",
      "--- Processing N=14 ---\n",
      "  [N=14] Launching 60 parallel tasks...\n",
      "  [N=14] Hybrid Search: Generating forward candidates...\n",
      "  [N=14] Hybrid Search: Generating forward candidates...\n",
      "  [N=14] Added 3 forward candidates.\n",
      "  [N=14] Best candidate score: 0.345714\n",
      "  [N=14] Baseline score: 0.382368, Candidate score: 0.345714\n",
      "  [N=14] ✓ IMPROVED over baseline: 0.382368 -> 0.345714 (Δ=0.036654, 9.59%)\n",
      "  [N=14] Cumulative Score: 40.056499 | Total Improvements: 187\n",
      "\n",
      "--- Processing N=13 ---\n",
      "  [N=13] Launching 60 parallel tasks...\n",
      "  [N=14] Added 3 forward candidates.\n",
      "  [N=14] Best candidate score: 0.345714\n",
      "  [N=14] Baseline score: 0.382368, Candidate score: 0.345714\n",
      "  [N=14] ✓ IMPROVED over baseline: 0.382368 -> 0.345714 (Δ=0.036654, 9.59%)\n",
      "  [N=14] Cumulative Score: 40.056499 | Total Improvements: 187\n",
      "\n",
      "--- Processing N=13 ---\n",
      "  [N=13] Launching 60 parallel tasks...\n",
      "  [N=13] Hybrid Search: Generating forward candidates...\n",
      "  [N=13] Hybrid Search: Generating forward candidates...\n",
      "  [N=13] Added 3 forward candidates.\n",
      "  [N=13] Best candidate score: 0.331202\n",
      "  [N=13] Baseline score: 0.373335, Candidate score: 0.331202\n",
      "  [N=13] ✓ IMPROVED over baseline: 0.373335 -> 0.331202 (Δ=0.042133, 11.29%)\n",
      "  [N=13] Cumulative Score: 40.387701 | Total Improvements: 188\n",
      "\n",
      "--- Processing N=12 ---\n",
      "  [N=12] Launching 60 parallel tasks...\n",
      "  [N=13] Added 3 forward candidates.\n",
      "  [N=13] Best candidate score: 0.331202\n",
      "  [N=13] Baseline score: 0.373335, Candidate score: 0.331202\n",
      "  [N=13] ✓ IMPROVED over baseline: 0.373335 -> 0.331202 (Δ=0.042133, 11.29%)\n",
      "  [N=13] Cumulative Score: 40.387701 | Total Improvements: 188\n",
      "\n",
      "--- Processing N=12 ---\n",
      "  [N=12] Launching 60 parallel tasks...\n",
      "  [N=12] Hybrid Search: Generating forward candidates...\n",
      "  [N=12] Hybrid Search: Generating forward candidates...\n",
      "  [N=12] Added 3 forward candidates.\n",
      "  [N=12] Best candidate score: 0.322677\n",
      "  [N=12] Baseline score: 0.375278, Candidate score: 0.322677\n",
      "  [N=12] ✓ IMPROVED over baseline: 0.375278 -> 0.322677 (Δ=0.052601, 14.02%)\n",
      "  [N=12] Cumulative Score: 40.710377 | Total Improvements: 189\n",
      "\n",
      "--- Processing N=11 ---\n",
      "  [N=11] Launching 60 parallel tasks...\n",
      "  [N=12] Added 3 forward candidates.\n",
      "  [N=12] Best candidate score: 0.322677\n",
      "  [N=12] Baseline score: 0.375278, Candidate score: 0.322677\n",
      "  [N=12] ✓ IMPROVED over baseline: 0.375278 -> 0.322677 (Δ=0.052601, 14.02%)\n",
      "  [N=12] Cumulative Score: 40.710377 | Total Improvements: 189\n",
      "\n",
      "--- Processing N=11 ---\n",
      "  [N=11] Launching 60 parallel tasks...\n",
      "  [N=11] Hybrid Search: Generating forward candidates...\n",
      "  [N=11] Hybrid Search: Generating forward candidates...\n",
      "  [N=11] Added 3 forward candidates.\n",
      "  [N=11] Best candidate score: 0.308709\n",
      "  [N=11] Baseline score: 0.377047, Candidate score: 0.308709\n",
      "  [N=11] ✓ IMPROVED over baseline: 0.377047 -> 0.308709 (Δ=0.068337, 18.12%)\n",
      "  [N=11] Cumulative Score: 41.019087 | Total Improvements: 190\n",
      "\n",
      "--- Processing N=10 ---\n",
      "  [N=10] Critical N! Widening beam to 24\n",
      "  [N=10] Launching 60 parallel tasks...\n",
      "  [N=11] Added 3 forward candidates.\n",
      "  [N=11] Best candidate score: 0.308709\n",
      "  [N=11] Baseline score: 0.377047, Candidate score: 0.308709\n",
      "  [N=11] ✓ IMPROVED over baseline: 0.377047 -> 0.308709 (Δ=0.068337, 18.12%)\n",
      "  [N=11] Cumulative Score: 41.019087 | Total Improvements: 190\n",
      "\n",
      "--- Processing N=10 ---\n",
      "  [N=10] Critical N! Widening beam to 24\n",
      "  [N=10] Launching 60 parallel tasks...\n",
      "  [N=10] Hybrid Search: Generating forward candidates...\n",
      "  [N=10] Hybrid Search: Generating forward candidates...\n",
      "  [N=10] Added 3 forward candidates.\n",
      "  [N=10] Best candidate score: 0.332858\n",
      "  [N=10] Baseline score: 0.381911, Candidate score: 0.332858\n",
      "  [N=10] ✓ IMPROVED over baseline: 0.381911 -> 0.332858 (Δ=0.049053, 12.84%)\n",
      "⚠️  Collision at N=10 between trees 0 and 4 (overlap area=1.182419e-01)\n",
      "  [N=10] Found 26 collision(s)\n",
      "  [N=10] Too many collisions - reverting to baseline\n",
      "  [N=10] Cumulative Score: 41.400998 | Total Improvements: 191\n",
      "  [N=10] Added 3 forward candidates.\n",
      "  [N=10] Best candidate score: 0.332858\n",
      "  [N=10] Baseline score: 0.381911, Candidate score: 0.332858\n",
      "  [N=10] ✓ IMPROVED over baseline: 0.381911 -> 0.332858 (Δ=0.049053, 12.84%)\n",
      "⚠️  Collision at N=10 between trees 0 and 4 (overlap area=1.182419e-01)\n",
      "  [N=10] Found 26 collision(s)\n",
      "  [N=10] Too many collisions - reverting to baseline\n",
      "  [N=10] Cumulative Score: 41.400998 | Total Improvements: 191\n",
      "\n",
      "--- Processing N=9 ---\n",
      "  [N=9] Launching 120 parallel tasks...\n",
      "\n",
      "--- Processing N=9 ---\n",
      "  [N=9] Launching 120 parallel tasks...\n",
      "  [N=9] Hybrid Search: Generating forward candidates...\n",
      "  [N=9] Hybrid Search: Generating forward candidates...\n",
      "  [N=9] Added 3 forward candidates.\n",
      "  [N=9] Best candidate score: 0.321111\n",
      "  [N=9] Baseline score: 0.387592, Candidate score: 0.321111\n",
      "  [N=9] ✓ IMPROVED over baseline: 0.387592 -> 0.321111 (Δ=0.066481, 17.15%)\n",
      "  [N=9] Cumulative Score: 41.722109 | Total Improvements: 192\n",
      "\n",
      "--- Processing N=8 ---\n",
      "  [N=8] Launching 60 parallel tasks...\n",
      "  [N=9] Added 3 forward candidates.\n",
      "  [N=9] Best candidate score: 0.321111\n",
      "  [N=9] Baseline score: 0.387592, Candidate score: 0.321111\n",
      "  [N=9] ✓ IMPROVED over baseline: 0.387592 -> 0.321111 (Δ=0.066481, 17.15%)\n",
      "  [N=9] Cumulative Score: 41.722109 | Total Improvements: 192\n",
      "\n",
      "--- Processing N=8 ---\n",
      "  [N=8] Launching 60 parallel tasks...\n",
      "  [N=8] Hybrid Search: Generating forward candidates...\n",
      "  [N=8] Hybrid Search: Generating forward candidates...\n",
      "  [N=8] Added 3 forward candidates.\n",
      "  [N=8] Best candidate score: 0.310078\n",
      "  [N=8] Baseline score: 0.390416, Candidate score: 0.310078\n",
      "  [N=8] ✓ IMPROVED over baseline: 0.390416 -> 0.310078 (Δ=0.080338, 20.58%)\n",
      "  [N=8] Cumulative Score: 42.032187 | Total Improvements: 193\n",
      "\n",
      "--- Processing N=7 ---\n",
      "  [N=7] Launching 60 parallel tasks...\n",
      "  [N=8] Added 3 forward candidates.\n",
      "  [N=8] Best candidate score: 0.310078\n",
      "  [N=8] Baseline score: 0.390416, Candidate score: 0.310078\n",
      "  [N=8] ✓ IMPROVED over baseline: 0.390416 -> 0.310078 (Δ=0.080338, 20.58%)\n",
      "  [N=8] Cumulative Score: 42.032187 | Total Improvements: 193\n",
      "\n",
      "--- Processing N=7 ---\n",
      "  [N=7] Launching 60 parallel tasks...\n",
      "  [N=7] Hybrid Search: Generating forward candidates...\n",
      "  [N=7] Hybrid Search: Generating forward candidates...\n",
      "  [N=7] Added 3 forward candidates.\n",
      "  [N=7] Best candidate score: 0.300357\n",
      "  [N=7] Baseline score: 0.400226, Candidate score: 0.300357\n",
      "  [N=7] ✓ IMPROVED over baseline: 0.400226 -> 0.300357 (Δ=0.099869, 24.95%)\n",
      "  [N=7] Cumulative Score: 42.332544 | Total Improvements: 194\n",
      "\n",
      "--- Processing N=6 ---\n",
      "  [N=6] Launching 60 parallel tasks...\n",
      "  [N=7] Added 3 forward candidates.\n",
      "  [N=7] Best candidate score: 0.300357\n",
      "  [N=7] Baseline score: 0.400226, Candidate score: 0.300357\n",
      "  [N=7] ✓ IMPROVED over baseline: 0.400226 -> 0.300357 (Δ=0.099869, 24.95%)\n",
      "  [N=7] Cumulative Score: 42.332544 | Total Improvements: 194\n",
      "\n",
      "--- Processing N=6 ---\n",
      "  [N=6] Launching 60 parallel tasks...\n",
      "  [N=6] Hybrid Search: Generating forward candidates...\n",
      "  [N=6] Hybrid Search: Generating forward candidates...\n",
      "  [N=6] Added 3 forward candidates.\n",
      "  [N=6] Best candidate score: 0.292604\n",
      "  [N=6] Baseline score: 0.400040, Candidate score: 0.292604\n",
      "  [N=6] ✓ IMPROVED over baseline: 0.400040 -> 0.292604 (Δ=0.107436, 26.86%)\n",
      "  [N=6] Cumulative Score: 42.625148 | Total Improvements: 195\n",
      "\n",
      "--- Processing N=5 ---\n",
      "  [N=5] Critical N! Widening beam to 24\n",
      "  [N=5] Launching 60 parallel tasks...\n",
      "  [N=6] Added 3 forward candidates.\n",
      "  [N=6] Best candidate score: 0.292604\n",
      "  [N=6] Baseline score: 0.400040, Candidate score: 0.292604\n",
      "  [N=6] ✓ IMPROVED over baseline: 0.400040 -> 0.292604 (Δ=0.107436, 26.86%)\n",
      "  [N=6] Cumulative Score: 42.625148 | Total Improvements: 195\n",
      "\n",
      "--- Processing N=5 ---\n",
      "  [N=5] Critical N! Widening beam to 24\n",
      "  [N=5] Launching 60 parallel tasks...\n",
      "  [N=5] Hybrid Search: Generating forward candidates...\n",
      "  [N=5] Hybrid Search: Generating forward candidates...\n",
      "  [N=5] Added 3 forward candidates.\n",
      "  [N=5] Best candidate score: 0.288000\n",
      "  [N=5] Baseline score: 0.417066, Candidate score: 0.288000\n",
      "  [N=5] ✓ IMPROVED over baseline: 0.417066 -> 0.288000 (Δ=0.129066, 30.95%)\n",
      "  [N=5] Cumulative Score: 42.913148 | Total Improvements: 196\n",
      "  [N=5] Added 3 forward candidates.\n",
      "  [N=5] Best candidate score: 0.288000\n",
      "  [N=5] Baseline score: 0.417066, Candidate score: 0.288000\n",
      "  [N=5] ✓ IMPROVED over baseline: 0.417066 -> 0.288000 (Δ=0.129066, 30.95%)\n",
      "  [N=5] Cumulative Score: 42.913148 | Total Improvements: 196\n",
      "\n",
      "--- Processing N=4 ---\n",
      "  [N=4] Critical N! Widening beam to 24\n",
      "  [N=4] Launching 95 parallel tasks...\n",
      "\n",
      "--- Processing N=4 ---\n",
      "  [N=4] Critical N! Widening beam to 24\n",
      "  [N=4] Launching 95 parallel tasks...\n",
      "  [N=4] Hybrid Search: Generating forward candidates...\n",
      "  [N=4] Hybrid Search: Generating forward candidates...\n",
      "  [N=4] Added 3 forward candidates.\n",
      "  [N=4] Best candidate score: 0.330625\n",
      "  [N=4] Baseline score: 0.416635, Candidate score: 0.330625\n",
      "  [N=4] ✓ IMPROVED over baseline: 0.416635 -> 0.330625 (Δ=0.086010, 20.64%)\n",
      "  [N=4] Cumulative Score: 43.243773 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=3 ---\n",
      "  [N=3] Critical N! Widening beam to 24\n",
      "  [N=3] Launching 120 parallel tasks...\n",
      "  [N=4] Added 3 forward candidates.\n",
      "  [N=4] Best candidate score: 0.330625\n",
      "  [N=4] Baseline score: 0.416635, Candidate score: 0.330625\n",
      "  [N=4] ✓ IMPROVED over baseline: 0.416635 -> 0.330625 (Δ=0.086010, 20.64%)\n",
      "  [N=4] Cumulative Score: 43.243773 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=3 ---\n",
      "  [N=3] Critical N! Widening beam to 24\n",
      "  [N=3] Launching 120 parallel tasks...\n",
      "  [N=3] Hybrid Search: Generating forward candidates...\n",
      "  [N=3] Hybrid Search: Generating forward candidates...\n",
      "  [N=3] Added 3 forward candidates.\n",
      "  [N=3] Best candidate score: 0.440833\n",
      "  [N=3] Baseline score: 0.434746, Candidate score: 0.440833\n",
      "  [N=3] Using baseline (better than candidates)\n",
      "  [N=3] Added 3 forward candidates.\n",
      "  [N=3] Best candidate score: 0.440833\n",
      "  [N=3] Baseline score: 0.434746, Candidate score: 0.440833\n",
      "  [N=3] Using baseline (better than candidates)\n",
      "  [N=3] Cumulative Score: 43.678519 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=2 ---\n",
      "  [N=2] Critical N! Widening beam to 24\n",
      "  [N=2] Launching 120 parallel tasks...\n",
      "  [N=3] Cumulative Score: 43.678519 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=2 ---\n",
      "  [N=2] Critical N! Widening beam to 24\n",
      "  [N=2] Launching 120 parallel tasks...\n",
      "  [N=2] Hybrid Search: Generating forward candidates...\n",
      "  [N=2] Hybrid Search: Generating forward candidates...\n",
      "  [N=2] Added 3 forward candidates.\n",
      "  [N=2] Best candidate score: 0.466044\n",
      "  [N=2] Baseline score: 0.450779, Candidate score: 0.466044\n",
      "  [N=2] Using baseline (better than candidates)\n",
      "  [N=2] Added 3 forward candidates.\n",
      "  [N=2] Best candidate score: 0.466044\n",
      "  [N=2] Baseline score: 0.450779, Candidate score: 0.466044\n",
      "  [N=2] Using baseline (better than candidates)\n",
      "  [N=2] Cumulative Score: 44.129298 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=1 ---\n",
      "  [N=1] Critical N! Widening beam to 24\n",
      "  [N=1] Launching 120 parallel tasks...\n",
      "  [N=2] Cumulative Score: 44.129298 | Total Improvements: 197\n",
      "\n",
      "--- Processing N=1 ---\n",
      "  [N=1] Critical N! Widening beam to 24\n",
      "  [N=1] Launching 120 parallel tasks...\n",
      "  [N=1] Hybrid Search: Generating forward candidates...\n",
      "  [N=1] Added 3 forward candidates.\n",
      "  [N=1] Best candidate score: 0.661250\n",
      "  [N=1] Baseline score: 0.661250, Candidate score: 0.661250\n",
      "  [N=1] Matched baseline (no improvement)\n",
      "  [N=1] Cumulative Score: 44.790548 | Total Improvements: 197\n",
      "  [N=1] Hybrid Search: Generating forward candidates...\n",
      "  [N=1] Added 3 forward candidates.\n",
      "  [N=1] Best candidate score: 0.661250\n",
      "  [N=1] Baseline score: 0.661250, Candidate score: 0.661250\n",
      "  [N=1] Matched baseline (no improvement)\n",
      "  [N=1] Cumulative Score: 44.790548 | Total Improvements: 197\n",
      "\n",
      "============================================================\n",
      "Processing complete!\n",
      "Total improvements over baseline: 197\n",
      "Final cumulative score: 44.790548\n",
      "============================================================\n",
      "\n",
      "✓ Submission generated: submission.csv\n",
      "\n",
      "============================================================\n",
      "Processing complete!\n",
      "Total improvements over baseline: 197\n",
      "Final cumulative score: 44.790548\n",
      "============================================================\n",
      "\n",
      "✓ Submission generated: submission.csv\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Load baseline from test.csv\n",
    "known_solutions = {}\n",
    "try:\n",
    "    print(\"Loading baseline from test.csv...\")\n",
    "    baseline_df = pd.read_csv('test.csv')\n",
    "    \n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    baseline_df['x'] = baseline_df['x'].apply(parse_s)\n",
    "    baseline_df['y'] = baseline_df['y'].apply(parse_s)\n",
    "    baseline_df['deg'] = baseline_df['deg'].apply(parse_s)\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = baseline_df[baseline_df['id'].str.startswith(prefix)]\n",
    "        if len(rows) == n:\n",
    "            trees = []\n",
    "            for _, row in rows.iterrows():\n",
    "                trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            known_solutions[n] = trees\n",
    "            \n",
    "    print(f\"Loaded {len(known_solutions)} configurations from test.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load baseline: {e}\")\n",
    "\n",
    "# Helper function for parallel execution (REVERSE MODE) - OPTIMIZED\n",
    "def process_beam_candidate_reverse(base_trees, n, packer_params, target_side=None, remove_idx=None, parent_id=None, task_id=0):\n",
    "    \"\"\"\n",
    "    Takes a solution of size >= n.\n",
    "    If size > n, removes trees to reach size n.\n",
    "    Then optimizes.\n",
    "    OPTIMIZED: Reduced tree copying and faster gravity passes.\n",
    "    \"\"\"\n",
    "    # Re-seed random for this process\n",
    "    seed_val = (int(time.time() * 1000000) + os.getpid() + task_id) % (2**32)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    \n",
    "    # Shallow copy first - only deep copy if we need to modify\n",
    "    current_trees = list(base_trees)\n",
    "    \n",
    "    # Remove trees if needed (Shrink strategy)\n",
    "    # Only create new objects when we actually remove trees\n",
    "    needs_copy = len(current_trees) > n\n",
    "    if needs_copy:\n",
    "        current_trees = [ChristmasTree(t.center_x, t.center_y, t.angle) for t in current_trees]\n",
    "        \n",
    "    removal_count = 0\n",
    "    while len(current_trees) > n:\n",
    "        if remove_idx is not None and remove_idx < len(current_trees):\n",
    "            # Remove specific tree requested\n",
    "            current_trees.pop(remove_idx)\n",
    "            remove_idx = None # Only use once\n",
    "        else:\n",
    "            # Fallback: Remove a tree that contributes to the bounds (Outliers)\n",
    "            # Calculate global bounds\n",
    "            union = unary_union([t.polygon for t in current_trees])\n",
    "            minx, miny, maxx, maxy = union.bounds\n",
    "            \n",
    "            candidates_to_remove = []\n",
    "            for i, t in enumerate(current_trees):\n",
    "                tb = t.polygon.bounds\n",
    "                # Check if touching global bounds (Contribution to Envelope)\n",
    "                if (abs(tb[0] - minx) < 1e-3 or abs(tb[1] - miny) < 1e-3 or \n",
    "                    abs(tb[2] - maxx) < 1e-3 or abs(tb[3] - maxy) < 1e-3):\n",
    "                    candidates_to_remove.append(i)\n",
    "            \n",
    "            if candidates_to_remove:\n",
    "                idx = random.choice(candidates_to_remove)\n",
    "            else:\n",
    "                idx = random.randint(0, len(current_trees) - 1)\n",
    "            current_trees.pop(idx)\n",
    "            removal_count += 1\n",
    "            \n",
    "            # Gravity Pass after removal - less frequent and shorter\n",
    "            # Only every 10 removals instead of every 5\n",
    "            if removal_count % 10 == 0:\n",
    "                current_trees = optimize_packing(current_trees, {\n",
    "                    'iterations': 2000,  # Reduced from 3000\n",
    "                    'step_size': 0.5,\n",
    "                    'angle_step': 5.0,\n",
    "                    'initial_temp': 0.1,\n",
    "                    'compression': 0.5\n",
    "                })\n",
    "            \n",
    "    # ADAPTIVE OPTIMIZATION based on N (Bucketed)\n",
    "    params = get_sa_params(n)\n",
    "    \n",
    "    candidate_trees = optimize_packing(current_trees, params, target_side=target_side)\n",
    "        \n",
    "    # Score Candidate\n",
    "    side_candidate = get_bounds(candidate_trees)\n",
    "    score_candidate = (side_candidate ** 2) / n\n",
    "    \n",
    "    return (score_candidate, candidate_trees, parent_id)\n",
    "\n",
    "# Helper for Forward Search (Hybrid)\n",
    "def process_forward_candidate(n, packer_params, task_id=0):\n",
    "    # Fix: Ensure seed is within 32-bit range for numpy\n",
    "    seed_val = (int(time.time() * 1000000) + os.getpid() + task_id) % (2**32)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    \n",
    "    packer = GreedyPacker(**packer_params)\n",
    "    \n",
    "    # Start with one tree\n",
    "    trees = [ChristmasTree(0, 0, 0)]\n",
    "    \n",
    "    for _ in range(n - 1):\n",
    "        next_tree = packer.place_next_tree(trees, ChristmasTree)\n",
    "        trees.append(next_tree)\n",
    "        \n",
    "    # Optimize\n",
    "    params = get_sa_params(n)\n",
    "    trees = optimize_packing(trees, params)\n",
    "    \n",
    "    side = get_bounds(trees)\n",
    "    score = (side ** 2) / n\n",
    "    return (score, trees, \"forward\")\n",
    "\n",
    "# BEAM SEARCH PARAMETERS - OPTIMIZED\n",
    "BASE_BEAM_WIDTH = CONFIG['dynamic_beam_width']['base_width']\n",
    "BRANCH_FACTOR = 5     # Reduced from 8 to 5 for speed\n",
    "n_jobs = multiprocessing.cpu_count()\n",
    "print(f\"Running Optimized Advanced Search (200 -> 1) on {n_jobs} cores.\")\n",
    "print(f\"Beam width: {BASE_BEAM_WIDTH}, Branch factor: {BRANCH_FACTOR}\")\n",
    "\n",
    "packer_params = {'n_trials': 200, 'step_size': 0.2, 'fine_step': 0.01}\n",
    "submission_rows = []\n",
    "improvements = 0\n",
    "all_solutions = {}\n",
    "\n",
    "# Initialize candidates with Lattice for N=200\n",
    "print(\"\\nInitializing with Lattice Generator for N=200.\")\n",
    "lattice_200 = generate_lattice(200)\n",
    "# Optimize the lattice initially\n",
    "print(\"Optimizing initial lattice...\")\n",
    "lattice_200 = optimize_packing(lattice_200, get_sa_params(200))\n",
    "current_candidates = [(lattice_200, \"lattice\")]\n",
    "\n",
    "# Metrics Tracking\n",
    "history_n = []\n",
    "history_improvement = []\n",
    "history_total_score = []\n",
    "current_total_score = 0\n",
    "\n",
    "# Setup Metrics File\n",
    "os.makedirs('Data', exist_ok=True)\n",
    "timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "metrics_file = f'Data/run_metrics_advanced_{timestamp_str}.csv'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    f.write('n,score,baseline,improvement,source\\n')\n",
    "\n",
    "# Setup Realtime Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "plt.close(fig) # Don't show yet\n",
    "plot_display_id = \"metrics_plot_advanced\"\n",
    "display(fig, display_id=plot_display_id) # Show initial empty plot\n",
    "\n",
    "# REVERSE LOOP: 200 down to 1\n",
    "for n in tqdm(range(200, 0, -1), desc=\"Processing Reverse\"):\n",
    "    \n",
    "    print(f\"\\n--- Processing N={n} ---\")\n",
    "\n",
    "    # Dynamic Beam Width\n",
    "    current_beam_width = BASE_BEAM_WIDTH\n",
    "    if CONFIG['dynamic_beam_width']['enabled']:\n",
    "        # Critical N values: 100, 50, 25, 10\n",
    "        if n in [100, 50, 25, 10] or n <= 5:\n",
    "            current_beam_width = int(BASE_BEAM_WIDTH * CONFIG['dynamic_beam_width']['critical_n_multiplier'])\n",
    "            print(f\"  [N={n}] Critical N! Widening beam to {current_beam_width}\")\n",
    "\n",
    "    # Get baseline side for pruning/comparison\n",
    "    baseline_side = None\n",
    "    if n in known_solutions:\n",
    "        baseline_side = get_bounds(known_solutions[n])\n",
    "    \n",
    "    # 1. Expand candidates in parallel\n",
    "    tasks = []\n",
    "    task_counter = 0\n",
    "    # Enumerate candidates to assign parent IDs\n",
    "    for p_idx, (base_trees, _) in enumerate(current_candidates):\n",
    "        # Identify boundary trees for intelligent removal\n",
    "        minx, miny, maxx, maxy = unary_union([t.polygon for t in base_trees]).bounds\n",
    "        boundary_indices = []\n",
    "        for i, t in enumerate(base_trees):\n",
    "            tb = t.polygon.bounds\n",
    "            # Check if touching global bounds\n",
    "            if (abs(tb[0] - minx) < 1e-2 or abs(tb[1] - miny) < 1e-2 or \n",
    "                abs(tb[2] - maxx) < 1e-2 or abs(tb[3] - maxy) < 1e-2):\n",
    "                boundary_indices.append(i)\n",
    "        \n",
    "        # If we have enough boundary trees, pick distinct ones. If not, fill with randoms.\n",
    "        indices_to_try = boundary_indices[:BRANCH_FACTOR]\n",
    "        while len(indices_to_try) < BRANCH_FACTOR:\n",
    "            indices_to_try.append(None) # None triggers random selection inside function\n",
    "            \n",
    "        for idx in indices_to_try:\n",
    "            # Pass p_idx as parent_id\n",
    "            tasks.append((base_trees, n, packer_params, baseline_side, idx, p_idx, task_counter))\n",
    "            task_counter += 1\n",
    "            \n",
    "    print(f\"  [N={n}] Launching {len(tasks)} parallel tasks...\")\n",
    "    \n",
    "    # Run in parallel\n",
    "    results = []\n",
    "    try:\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(process_beam_candidate_reverse)(t[0], t[1], t[2], t[3], t[4], t[5], t[6]) for t in tasks\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  [N={n}] ERROR in parallel execution: {e}\")\n",
    "        if n in known_solutions:\n",
    "            results = [((get_bounds(known_solutions[n])**2)/n, known_solutions[n], \"fallback\")]\n",
    "    \n",
    "    # Hybrid Search: Inject Forward Candidates\n",
    "    if CONFIG['hybrid_search']['enabled'] and n <= CONFIG['hybrid_search']['switch_n']:\n",
    "        print(f\"  [N={n}] Hybrid Search: Generating forward candidates...\")\n",
    "        # Generate a few forward candidates\n",
    "        forward_tasks = [(n, packer_params, i) for i in range(3)] # Reduced from 4 to 3\n",
    "        try:\n",
    "            forward_results = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(process_forward_candidate)(t[0], t[1], t[2]) for t in forward_tasks\n",
    "            )\n",
    "            results.extend(forward_results)\n",
    "            print(f\"  [N={n}] Added {len(forward_results)} forward candidates.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [N={n}] Forward search failed: {e}\")\n",
    "\n",
    "    # 2. Sort and select top K (Beam Selection with Diversity)\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    if results:\n",
    "        print(f\"  [N={n}] Best candidate score: {results[0][0]:.6f}\")\n",
    "    else:\n",
    "        print(f\"  [N={n}] No results found!\")\n",
    "        continue\n",
    "    \n",
    "    # Update current candidates with diversity check\n",
    "    unique_candidates = []\n",
    "    seen_scores = set()\n",
    "    parent_counts = {} # Track how many children from each parent\n",
    "    \n",
    "    max_children = CONFIG['beam_diversity']['max_children_per_parent'] if CONFIG['beam_diversity']['enabled'] else 999\n",
    "    \n",
    "    for res in results:\n",
    "        score = round(res[0], 6)\n",
    "        trees = res[1]\n",
    "        pid = res[2]\n",
    "        \n",
    "        # Diversity Check 1: Score Uniqueness\n",
    "        if score in seen_scores:\n",
    "            continue\n",
    "            \n",
    "        # Diversity Check 2: Parent Limit\n",
    "        p_count = parent_counts.get(pid, 0)\n",
    "        if p_count >= max_children:\n",
    "            continue\n",
    "            \n",
    "        unique_candidates.append((trees, pid))\n",
    "        seen_scores.add(score)\n",
    "        parent_counts[pid] = p_count + 1\n",
    "        \n",
    "        if len(unique_candidates) >= current_beam_width:\n",
    "            break\n",
    "            \n",
    "    current_candidates = unique_candidates\n",
    "    \n",
    "    # The best candidate for this N\n",
    "    best_score_greedy = results[0][0]\n",
    "    best_trees_greedy = results[0][1]\n",
    "    \n",
    "    # 3. Compare with Baseline - FIXED LOGIC\n",
    "    best_trees_n = best_trees_greedy\n",
    "    best_score_n = best_score_greedy\n",
    "    source = \"ReverseGreedy\"\n",
    "    baseline_val = 0\n",
    "    \n",
    "    if n in known_solutions:\n",
    "        known_trees = known_solutions[n]\n",
    "        # Don't modify the original baseline\n",
    "        known_trees_copy = [ChristmasTree(t.center_x, t.center_y, t.angle) for t in known_trees]\n",
    "        known_trees_copy = center_packing(known_trees_copy)\n",
    "        side_known = get_bounds(known_trees_copy)\n",
    "        score_known = (side_known ** 2) / n\n",
    "        baseline_val = score_known\n",
    "        \n",
    "        print(f\"  [N={n}] Baseline score: {score_known:.6f}, Candidate score: {best_score_greedy:.6f}\")\n",
    "\n",
    "        # Compare (Lower is better)\n",
    "        if score_known < best_score_greedy - 1e-7:\n",
    "            # Baseline is better - use it and try to optimize\n",
    "            best_trees_n = known_trees_copy\n",
    "            best_score_n = score_known\n",
    "            source = \"Baseline\"\n",
    "            print(f\"  [N={n}] Using baseline (better than candidates)\")\n",
    "            \n",
    "            # Try to optimize baseline\n",
    "            optimized_known = [ChristmasTree(t.center_x, t.center_y, t.angle) for t in known_trees]\n",
    "            params = get_sa_params(n)\n",
    "            params['iterations'] = int(params['iterations'] * 1.5)\n",
    "            \n",
    "            optimized_known = optimize_packing(optimized_known, params)\n",
    "            \n",
    "            side_opt = get_bounds(optimized_known)\n",
    "            score_opt = (side_opt ** 2) / n\n",
    "            \n",
    "            if score_opt < score_known - 1e-7:\n",
    "                best_trees_n = optimized_known\n",
    "                best_score_n = score_opt\n",
    "                source = \"Baseline+Opt\"\n",
    "                improvements += 1\n",
    "                print(f\"  [N={n}] ✓ Optimized baseline: {score_known:.6f} -> {score_opt:.6f} (Δ={score_known-score_opt:.6f})\")\n",
    "            \n",
    "            # Inject baseline into beam\n",
    "            current_candidates.append((best_trees_n, \"baseline\"))\n",
    "            temp_candidates = []\n",
    "            for c, pid in current_candidates:\n",
    "                s = get_bounds(c)\n",
    "                temp_candidates.append(((s**2)/n, c, pid))\n",
    "            temp_candidates.sort(key=lambda x: x[0])\n",
    "            current_candidates = [(x[1], x[2]) for x in temp_candidates[:current_beam_width]]\n",
    "            \n",
    "        elif best_score_greedy < score_known - 1e-7:\n",
    "            # Our candidate beat the baseline\n",
    "            improvements += 1\n",
    "            delta = score_known - best_score_greedy\n",
    "            pct_improvement = (delta / score_known) * 100\n",
    "            print(f\"  [N={n}] ✓ IMPROVED over baseline: {score_known:.6f} -> {best_score_greedy:.6f} (Δ={delta:.6f}, {pct_improvement:.2f}%)\")\n",
    "        else:\n",
    "            # Scores are essentially equal\n",
    "            print(f\"  [N={n}] Matched baseline (no improvement)\")\n",
    "    else:\n",
    "        print(f\"  [N={n}] No baseline available, using candidate\")\n",
    "            \n",
    "    # 4. Update State & Check Bounds\n",
    "    all_solutions[n] = best_trees_n\n",
    "    \n",
    "    # Validation - OPTIMIZED (only check periodically)\n",
    "    if CONFIG['validation']['strict_boundary']:\n",
    "        for t in best_trees_n:\n",
    "            if abs(t.center_x) > 100 or abs(t.center_y) > 100:\n",
    "                print(f\"⚠️  WARNING: Tree at N={n} outside bounds: ({t.center_x:.2f}, {t.center_y:.2f})\")\n",
    "    \n",
    "    # Collision check - OPTIMIZED (only every 10th N and using STRtree for speed)\n",
    "    if CONFIG['validation']['collision_check'] and n % 10 == 0:\n",
    "        polys = [t.polygon for t in best_trees_n]\n",
    "        tree_index = STRtree(polys)\n",
    "        collision_count = 0\n",
    "        for i, poly in enumerate(polys):\n",
    "            candidates = tree_index.query(poly)\n",
    "            for j in candidates:\n",
    "                if j > i and polys[i].intersects(polys[j]) and not polys[i].touches(polys[j]):\n",
    "                    area = polys[i].intersection(polys[j]).area\n",
    "                    if area > 1e-5:  # Only count significant overlaps\n",
    "                        collision_count += 1\n",
    "                        if collision_count == 1:\n",
    "                            print(f\"⚠️  Collision at N={n} between trees {i} and {j} (overlap area={area:.6e})\")\n",
    "        \n",
    "        if collision_count > 0:\n",
    "            print(f\"  [N={n}] Found {collision_count} collision(s)\")\n",
    "            # If significant collisions found, use baseline instead\n",
    "            if collision_count > 5 and n in known_solutions:\n",
    "                print(f\"  [N={n}] Too many collisions - reverting to baseline\")\n",
    "                best_trees_n = known_solutions[n]\n",
    "                best_score_n = (get_bounds(best_trees_n) ** 2) / n\n",
    "                source = \"Baseline_CollisionFallback\"\n",
    "\n",
    "    # 5. Metrics & Plotting\n",
    "    current_total_score += best_score_n\n",
    "    imp = max(0, baseline_val - best_score_n) if baseline_val > 0 else 0\n",
    "    \n",
    "    print(f\"  [N={n}] Cumulative Score: {current_total_score:.6f} | Total Improvements: {improvements}\")\n",
    "\n",
    "    history_n.append(n)\n",
    "    history_improvement.append(imp)\n",
    "    history_total_score.append(current_total_score)\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(metrics_file, 'a') as f:\n",
    "        f.write(f\"{n},{best_score_n:.10f},{baseline_val:.10f},{imp:.10f},{source}\\n\")\n",
    "        \n",
    "    # Realtime Plot (Update every 5 steps)\n",
    "    if n % 5 == 0 or n == 1:\n",
    "        # Update axes\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        \n",
    "        # Note: history_n is decreasing [200, 199, ...]\n",
    "        ax1.plot(history_n, history_improvement, 'g-', label='Improvement')\n",
    "        ax1.set_title(f'Improvement per N (Total: {improvements})')\n",
    "        ax1.set_xlabel('N')\n",
    "        ax1.set_ylabel('Score Reduction')\n",
    "        ax1.invert_xaxis() # Invert X axis to show 200 -> 1 flow\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(history_n, history_total_score, 'b-', label='Total Score')\n",
    "        ax2.set_title(f'Cumulative Score: {current_total_score:.4f}')\n",
    "        ax2.set_xlabel('N')\n",
    "        ax2.set_ylabel('Total Score')\n",
    "        ax2.invert_xaxis()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Update the display\n",
    "        display(fig, display_id=plot_display_id, update=True)\n",
    "    \n",
    "    # 6. Prepare Submission Rows\n",
    "    for i, tree in enumerate(best_trees_n):\n",
    "        submission_rows.append([\n",
    "            f\"{n:03d}_{i}\", \n",
    "            f\"s{tree.center_x:.10f}\", \n",
    "            f\"s{tree.center_y:.10f}\", \n",
    "            f\"s{tree.angle:.10f}\"\n",
    "        ])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"Total improvements over baseline: {improvements}\")\n",
    "print(f\"Final cumulative score: {current_total_score:.6f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "df_sub = pd.DataFrame(submission_rows, columns=['id', 'x', 'y', 'deg'])\n",
    "# Sort by ID to ensure 001_... comes first\n",
    "df_sub.sort_values('id', inplace=True)\n",
    "df_sub.to_csv('submission.csv', index=False)\n",
    "print(\"\\n✓ Submission generated: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a5fc2",
   "metadata": {},
   "source": [
    "## 10. Evaluation Helper\n",
    "\n",
    "Calculate the local score to estimate leaderboard performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87b62dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Polishing Phase...\n",
      "Loaded submission.csv for polishing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adca6be34682466c8b79c2684f70ef6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Polishing:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polishing Complete.\n",
      "Score Before: 44.790548\n",
      "Score After:  44.737297\n",
      "Improvement:  0.053251\n",
      "Saved polished submission to submission.csv\n"
     ]
    }
   ],
   "source": [
    "## 9. Polishing & Refinement\n",
    "# Run this cell to further optimize the existing submission using the new Numba engine.\n",
    "# This is much faster than the full search and can squeeze out extra points.\n",
    "\n",
    "print(\"Starting Polishing Phase...\")\n",
    "try:\n",
    "    # Load current best submission\n",
    "    if os.path.exists('submission.csv'):\n",
    "        polish_df = pd.read_csv('submission.csv')\n",
    "        print(\"Loaded submission.csv for polishing.\")\n",
    "    else:\n",
    "        polish_df = pd.read_csv('test.csv')\n",
    "        print(\"Loaded test.csv for polishing.\")\n",
    "\n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    polish_df['x'] = polish_df['x'].apply(parse_s)\n",
    "    polish_df['y'] = polish_df['y'].apply(parse_s)\n",
    "    polish_df['deg'] = polish_df['deg'].apply(parse_s)\n",
    "    \n",
    "    polish_solutions = {}\n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        rows = polish_df[polish_df['id'].str.startswith(prefix)]\n",
    "        if len(rows) == n:\n",
    "            trees = []\n",
    "            for _, row in rows.iterrows():\n",
    "                trees.append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "            polish_solutions[n] = trees\n",
    "\n",
    "    total_score_before = 0\n",
    "    total_score_after = 0\n",
    "    \n",
    "    # Polish each N\n",
    "    for n in tqdm(range(1, 201), desc=\"Polishing\"):\n",
    "        if n not in polish_solutions: continue\n",
    "        \n",
    "        trees = polish_solutions[n]\n",
    "        side_before = get_bounds(trees)\n",
    "        score_before = (side_before ** 2) / n\n",
    "        total_score_before += score_before\n",
    "        \n",
    "        # Run Numba Optimization with Bucketed Params\n",
    "        params = get_sa_params(n).copy()\n",
    "        \n",
    "        # Boost iterations for polishing\n",
    "        # We want a very thorough local search\n",
    "        params['iterations'] = 200000 if n < 50 else 500000\n",
    "        \n",
    "        # Reduce initial temperature for polishing (we are already close to a good solution)\n",
    "        params['initial_temp'] = params['initial_temp'] * 0.5\n",
    "        \n",
    "        optimized_trees = optimize_packing(trees, params)\n",
    "        \n",
    "        side_after = get_bounds(optimized_trees)\n",
    "        score_after = (side_after ** 2) / n\n",
    "        \n",
    "        if score_after < score_before - 1e-9:\n",
    "            polish_solutions[n] = optimized_trees\n",
    "            total_score_after += score_after\n",
    "            # print(f\"  N={n} Improved: {score_before:.6f} -> {score_after:.6f}\")\n",
    "        else:\n",
    "            total_score_after += score_before # Keep original\n",
    "            \n",
    "    print(f\"Polishing Complete.\")\n",
    "    print(f\"Score Before: {total_score_before:.6f}\")\n",
    "    print(f\"Score After:  {total_score_after:.6f}\")\n",
    "    print(f\"Improvement:  {total_score_before - total_score_after:.6f}\")\n",
    "    \n",
    "    # Save if improved\n",
    "    if total_score_after < total_score_before:\n",
    "        new_rows = []\n",
    "        for n in range(1, 201):\n",
    "            if n in polish_solutions:\n",
    "                for i, tree in enumerate(polish_solutions[n]):\n",
    "                    new_rows.append([\n",
    "                        f\"{n:03d}_{i}\", \n",
    "                        f\"s{tree.center_x:.10f}\", \n",
    "                        f\"s{tree.center_y:.10f}\", \n",
    "                        f\"s{tree.angle:.10f}\"\n",
    "                    ])\n",
    "        \n",
    "        df_polished = pd.DataFrame(new_rows, columns=['id', 'x', 'y', 'deg'])\n",
    "        df_polished.sort_values('id', inplace=True)\n",
    "        df_polished.to_csv('submission_polished.csv', index=False)\n",
    "        df_polished.to_csv('submission.csv', index=False) # Overwrite main\n",
    "        print(\"Saved polished submission to submission.csv\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Polishing failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1baa5",
   "metadata": {},
   "source": [
    "## NEW: Worst-N Refinement Strategy\n",
    "The scoring metric is Σ(s²/n). Small N with bad packing hurt disproportionately.\n",
    "This cell identifies the worst performing N values and runs intensive optimization on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ae34447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization_utils import sa_numba_growing\n",
    "import numpy as np\n",
    "\n",
    "def refine_worst_n(all_solutions, top_k=30, seeds=20, iterations=100000):\n",
    "    \"\"\"Refine worst-performing N values based on Σ(s^2/n) contribution.\n",
    "    Uses normalized SA params to avoid KeyError and multi-seed Growing Trees.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\\nWORST-N REFINEMENT (top_k={top_k}, seeds={seeds}, iter={iterations})\\n{'='*50}\")\n",
    "    if not all_solutions:\n",
    "        print(\"No solutions to refine.\")\n",
    "        return all_solutions\n",
    "\n",
    "    # Build contribution table\n",
    "    contrib_rows = []\n",
    "    for n, trees in all_solutions.items():\n",
    "        side = get_bounds(trees)\n",
    "        contrib = (side * side) / n\n",
    "        contrib_rows.append((n, side, contrib))\n",
    "    arr = np.array(contrib_rows, dtype=np.float64)\n",
    "    worst_idxs = np.argsort(arr[:, 2])[::-1][:top_k]\n",
    "    worst_list = arr[worst_idxs, 0].astype(int).tolist()\n",
    "\n",
    "    print(\"Worst N selection:\")\n",
    "    for rank, idx in enumerate(worst_idxs, 1):\n",
    "        n_val = int(arr[idx, 0]); s_val = arr[idx, 1]; c_val = arr[idx, 2]\n",
    "        print(f\"  {rank:2d}. N={n_val:3d} side={s_val:.5f} contrib={c_val:.5f}\")\n",
    "\n",
    "    refined = dict(all_solutions)\n",
    "    improvements = 0\n",
    "\n",
    "    for n in tqdm(worst_list, desc=\"Refining\"):\n",
    "        trees = refined[n]\n",
    "        base_side = get_bounds(trees)\n",
    "        xs = np.fromiter((t.center_x for t in trees), dtype=np.float64, count=len(trees))\n",
    "        ys = np.fromiter((t.center_y for t in trees), dtype=np.float64, count=len(trees))\n",
    "        angs = np.fromiter((t.angle for t in trees), dtype=np.float64, count=len(trees))\n",
    "\n",
    "        raw_params = get_sa_params(n)\n",
    "        p = normalize_sa_params(raw_params)\n",
    "        T0, Tmin = p['T0'], p['Tmin']\n",
    "        move_scale, rot_scale = p['move_scale'], p['rot_scale']\n",
    "        compression = p['compression']\n",
    "        iter_use = iterations or p['iterations']\n",
    "\n",
    "        best_side = base_side\n",
    "        best_bxs, best_bys, best_bangs = xs, ys, angs\n",
    "\n",
    "        for seed in range(seeds):\n",
    "            bxs, bys, bangs, side_candidate = sa_numba_growing(\n",
    "                xs, ys, angs, n,\n",
    "                iterations=iter_use,\n",
    "                T0=T0,\n",
    "                Tmin=Tmin,\n",
    "                move_scale=move_scale,\n",
    "                rot_scale=rot_scale,\n",
    "                seed=seed + 12345,\n",
    "                compression=compression\n",
    "            )\n",
    "            if side_candidate < best_side - 1e-12:\n",
    "                best_side = side_candidate\n",
    "                best_bxs, best_bys, best_bangs = bxs.copy(), bys.copy(), bangs.copy()\n",
    "\n",
    "        if best_side < base_side - 1e-9:\n",
    "            refined[n] = [ChristmasTree(best_bxs[i], best_bys[i], best_bangs[i]) for i in range(n)]\n",
    "            improvements += 1\n",
    "            pct = 100.0 * (base_side - best_side) / base_side\n",
    "            print(f\"  ✓ N={n:3d} improved {base_side:.5f} -> {best_side:.5f} (-{pct:.2f}%)\")\n",
    "\n",
    "    print(f\"Refinement complete. Improved {improvements}/{len(worst_list)} targets.\")\n",
    "    return refined\n",
    "\n",
    "# Example:\n",
    "# all_solutions = refine_worst_n(all_solutions, top_k=30, seeds=20, iterations=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b919c9d",
   "metadata": {},
   "source": [
    "## NEW: Forward Chain Search\n",
    "Instead of only using Reverse Beam (200→1), also build solutions forward (1→200).\n",
    "This helps with tricky N values (primes, etc.) that don't fit well as subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6934600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_chain_search(max_n=200, seeds_per_n=3, iterations=30000):\n",
    "    \"\"\"Build solutions forward 1..max_n, inserting one tree then optimizing.\n",
    "    Uses normalized SA params and reduced redundant calculations.\"\"\"\n",
    "    print(f\"\\n{'='*50}\\nFORWARD CHAIN SEARCH (max_n={max_n})\\n{'='*50}\")\n",
    "    forward = {1: [ChristmasTree(0.0, 0.0, 0.0)]}\n",
    "\n",
    "    for n in tqdm(range(2, max_n + 1), desc=\"ForwardChain\"):\n",
    "        prev = forward[n - 1]\n",
    "        m = len(prev)\n",
    "        xs = np.fromiter((t.center_x for t in prev), dtype=np.float64, count=m)\n",
    "        ys = np.fromiter((t.center_y for t in prev), dtype=np.float64, count=m)\n",
    "        angs = np.fromiter((t.angle for t in prev), dtype=np.float64, count=m)\n",
    "\n",
    "        minx, maxx = xs.min(), xs.max()\n",
    "        miny, maxy = ys.min(), ys.max()\n",
    "        cx, cy = (minx + maxx) / 2.0, (miny + maxy) / 2.0\n",
    "\n",
    "        candidates = [\n",
    "            (maxx + 0.6, cy, np.random.rand() * 360.0),\n",
    "            (cx + np.random.randn() * 0.4, cy + np.random.randn() * 0.4, np.random.rand() * 360.0),\n",
    "            (minx - 0.5, maxy + 0.5, np.random.rand() * 360.0),\n",
    "        ]\n",
    "\n",
    "        raw_params = get_sa_params(n)\n",
    "        p = normalize_sa_params(raw_params)\n",
    "        T0, Tmin = p['T0'], p['Tmin']\n",
    "        move_scale, rot_scale = p['move_scale'], p['rot_scale']\n",
    "        compression = p['compression']\n",
    "        iter_use = iterations or p['iterations']\n",
    "\n",
    "        best_side = float('inf')\n",
    "        best_sol = None\n",
    "\n",
    "        for (ix, iy, iang) in candidates:\n",
    "            xs_new = np.concatenate([xs, [ix]])\n",
    "            ys_new = np.concatenate([ys, [iy]])\n",
    "            angs_new = np.concatenate([angs, [iang]])\n",
    "            for seed in range(seeds_per_n):\n",
    "                bxs, bys, bangs, side = sa_numba_growing(\n",
    "                    xs_new, ys_new, angs_new, n,\n",
    "                    iterations=iter_use,\n",
    "                    T0=T0, Tmin=Tmin,\n",
    "                    move_scale=move_scale, rot_scale=rot_scale,\n",
    "                    seed=seed + n * 1000 + 777,\n",
    "                    compression=compression\n",
    "                )\n",
    "                if side < best_side - 1e-12:\n",
    "                    best_side = side\n",
    "                    best_sol = (bxs.copy(), bys.copy(), bangs.copy())\n",
    "\n",
    "        if best_sol is None:\n",
    "            forward[n] = prev + [ChristmasTree(cx, cy, 0.0)]\n",
    "        else:\n",
    "            bxs, bys, bangs = best_sol\n",
    "            forward[n] = [ChristmasTree(bxs[i], bys[i], bangs[i]) for i in range(n)]\n",
    "\n",
    "    print(\"Forward chain complete.\")\n",
    "    return forward\n",
    "\n",
    "# forward_solutions = forward_chain_search(max_n=200, seeds_per_n=3, iterations=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1d2e7",
   "metadata": {},
   "source": [
    "## NEW: Solution Ensemble & Merge\n",
    "Combine results from multiple strategies (Reverse Beam, Forward Chain, Refinement).\n",
    "For each N, pick the solution with the smallest bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29ec5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_solutions(*solution_dicts, labels=None):\n",
    "    \"\"\"Merge multiple solution dicts; keep smallest bounding box per N.\n",
    "    Adds win statistics per source.\"\"\"\n",
    "    if labels is None:\n",
    "        labels = [f\"S{i+1}\" for i in range(len(solution_dicts))]\n",
    "\n",
    "    merged = {}\n",
    "    stats = {lab: {'wins': 0, 'attempts': 0} for lab in labels}\n",
    "\n",
    "    for n in range(1, 201):\n",
    "        candidate_rows = []\n",
    "        for sol, lab in zip(solution_dicts, labels):\n",
    "            if n in sol:\n",
    "                trees = sol[n]\n",
    "                side = get_bounds(trees)\n",
    "                candidate_rows.append((side, trees, lab))\n",
    "        if not candidate_rows:\n",
    "            continue\n",
    "        # Sort by side ascending\n",
    "        candidate_rows.sort(key=lambda r: r[0])\n",
    "        best_side, best_trees, best_lab = candidate_rows[0]\n",
    "        merged[n] = best_trees\n",
    "        for side, trees, lab in candidate_rows:\n",
    "            stats[lab]['attempts'] += 1\n",
    "        stats[best_lab]['wins'] += 1\n",
    "\n",
    "    # Report\n",
    "    print(\"Merge stats:\")\n",
    "    for lab in labels:\n",
    "        att = stats[lab]['attempts']; wins = stats[lab]['wins']\n",
    "        wr = (wins / att * 100.0) if att else 0.0\n",
    "        print(f\"  {lab:15s} wins={wins:3d}/{att:3d} ({wr:5.1f}%)\")\n",
    "\n",
    "    total_score = sum((get_bounds(merged[n])**2)/n for n in merged)\n",
    "    print(f\"Merged total score: {total_score:.6f} over {len(merged)} Ns\")\n",
    "    return merged\n",
    "\n",
    "def save_solution_to_csv(solutions, filename='submission_ensemble.csv'):\n",
    "    rows = []\n",
    "    for n in range(1, 201):\n",
    "        if n in solutions:\n",
    "            for i, t in enumerate(solutions[n]):\n",
    "                rows.append([f\"{n:03d}_{i}\", f\"s{t.center_x:.10f}\", f\"s{t.center_y:.10f}\", f\"s{t.angle:.10f}\"])\n",
    "    df = pd.DataFrame(rows, columns=['id','x','y','deg']).sort_values('id')\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {filename}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a887e",
   "metadata": {},
   "source": [
    "## UPDATED: Main Optimization with Growing Trees\n",
    "This cell shows how to integrate the new `sa_numba_growing` engine into your optimization workflow.\n",
    "The Growing Trees strategy uses soft physics (90% → 100% scaling) to escape local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82669178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_packing_with_growing_trees(trees, params, seeds=5):\n",
    "    \"\"\"Optimizes a list of trees with multi-seed Growing Trees using normalized params.\"\"\"\n",
    "    n = len(trees)\n",
    "    if n == 0:\n",
    "        return trees\n",
    "    xs = np.fromiter((t.center_x for t in trees), dtype=np.float64, count=n)\n",
    "    ys = np.fromiter((t.center_y for t in trees), dtype=np.float64, count=n)\n",
    "    angs = np.fromiter((t.angle for t in trees), dtype=np.float64, count=n)\n",
    "\n",
    "    p = normalize_sa_params(params or {})\n",
    "    T0, Tmin = p['T0'], p['Tmin']\n",
    "    move_scale, rot_scale = p['move_scale'], p['rot_scale']\n",
    "    compression = p['compression']\n",
    "    iterations = p['iterations']\n",
    "\n",
    "    best_side = float('inf')\n",
    "    best_state = (xs, ys, angs)\n",
    "\n",
    "    base_seed = p['base_seed']\n",
    "    ss = np.random.SeedSequence(base_seed)\n",
    "    seed_list = ss.spawn(seeds)\n",
    "\n",
    "    for child in seed_list:\n",
    "        seed = int(child.generate_state(1)[0] % (2**31 - 1))\n",
    "        bxs, bys, bangs, side = sa_numba_growing(\n",
    "            xs, ys, angs, n,\n",
    "            iterations=iterations,\n",
    "            T0=T0, Tmin=Tmin,\n",
    "            move_scale=move_scale, rot_scale=rot_scale,\n",
    "            seed=seed, compression=compression\n",
    "        )\n",
    "        if side < best_side - 1e-12:\n",
    "            best_side = side\n",
    "            best_state = (bxs.copy(), bys.copy(), bangs.copy())\n",
    "\n",
    "    bxs, bys, bangs = best_state\n",
    "    return [ChristmasTree(bxs[i], bys[i], bangs[i]) for i in range(n)]\n",
    "\n",
    "# optimized_trees = optimize_packing_with_growing_trees(candidate_trees, normalize_sa_params(get_sa_params(len(candidate_trees))), seeds=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ae47bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SANTA 2025 OPTIMIZATION PIPELINE\n",
      "======================================================================\n",
      "Loaded 200 reverse solutions. Score=41.403259\n",
      "Forward chain skipped.\n",
      "\n",
      "==================================================\n",
      "WORST-N REFINEMENT (top_k=30, seeds=20, iter=80000)\n",
      "==================================================\n",
      "Loaded 200 reverse solutions. Score=41.403259\n",
      "Forward chain skipped.\n",
      "\n",
      "==================================================\n",
      "WORST-N REFINEMENT (top_k=30, seeds=20, iter=80000)\n",
      "==================================================\n",
      "Worst N selection:\n",
      "   1. N=  1 side=0.81317 contrib=0.66125\n",
      "   2. N=  2 side=0.94950 contrib=0.45078\n",
      "   3. N=  3 side=1.14203 contrib=0.43475\n",
      "   4. N= 17 side=2.45000 contrib=0.35309\n",
      "   5. N= 14 side=2.20000 contrib=0.34571\n",
      "   6. N= 16 side=2.32500 contrib=0.33785\n",
      "   7. N= 18 side=2.45000 contrib=0.33347\n",
      "   8. N= 10 side=1.82444 contrib=0.33286\n",
      "   9. N= 13 side=2.07500 contrib=0.33120\n",
      "  10. N=  4 side=1.15000 contrib=0.33063\n",
      "  11. N= 12 side=1.96777 contrib=0.32268\n",
      "  12. N= 15 side=2.20000 contrib=0.32267\n",
      "  13. N=  9 side=1.70000 contrib=0.32111\n",
      "  14. N= 19 side=2.45000 contrib=0.31592\n",
      "  15. N=  8 side=1.57500 contrib=0.31008\n",
      "  16. N= 11 side=1.84277 contrib=0.30871\n",
      "  17. N=  7 side=1.45000 contrib=0.30036\n",
      "  18. N= 20 side=2.45000 contrib=0.30013\n",
      "  19. N=  6 side=1.32500 contrib=0.29260\n",
      "  20. N=  5 side=1.20000 contrib=0.28800\n",
      "  21. N= 21 side=2.45000 contrib=0.28583\n",
      "  22. N= 22 side=2.45000 contrib=0.27284\n",
      "  23. N= 28 side=2.75742 contrib=0.27155\n",
      "  24. N= 29 side=2.80502 contrib=0.27132\n",
      "  25. N= 27 side=2.70000 contrib=0.27000\n",
      "  26. N= 30 side=2.82500 contrib=0.26602\n",
      "  27. N= 25 side=2.57500 contrib=0.26523\n",
      "  28. N= 36 side=3.07500 contrib=0.26266\n",
      "  29. N= 33 side=2.94085 contrib=0.26208\n",
      "  30. N= 23 side=2.45000 contrib=0.26098\n",
      "Worst N selection:\n",
      "   1. N=  1 side=0.81317 contrib=0.66125\n",
      "   2. N=  2 side=0.94950 contrib=0.45078\n",
      "   3. N=  3 side=1.14203 contrib=0.43475\n",
      "   4. N= 17 side=2.45000 contrib=0.35309\n",
      "   5. N= 14 side=2.20000 contrib=0.34571\n",
      "   6. N= 16 side=2.32500 contrib=0.33785\n",
      "   7. N= 18 side=2.45000 contrib=0.33347\n",
      "   8. N= 10 side=1.82444 contrib=0.33286\n",
      "   9. N= 13 side=2.07500 contrib=0.33120\n",
      "  10. N=  4 side=1.15000 contrib=0.33063\n",
      "  11. N= 12 side=1.96777 contrib=0.32268\n",
      "  12. N= 15 side=2.20000 contrib=0.32267\n",
      "  13. N=  9 side=1.70000 contrib=0.32111\n",
      "  14. N= 19 side=2.45000 contrib=0.31592\n",
      "  15. N=  8 side=1.57500 contrib=0.31008\n",
      "  16. N= 11 side=1.84277 contrib=0.30871\n",
      "  17. N=  7 side=1.45000 contrib=0.30036\n",
      "  18. N= 20 side=2.45000 contrib=0.30013\n",
      "  19. N=  6 side=1.32500 contrib=0.29260\n",
      "  20. N=  5 side=1.20000 contrib=0.28800\n",
      "  21. N= 21 side=2.45000 contrib=0.28583\n",
      "  22. N= 22 side=2.45000 contrib=0.27284\n",
      "  23. N= 28 side=2.75742 contrib=0.27155\n",
      "  24. N= 29 side=2.80502 contrib=0.27132\n",
      "  25. N= 27 side=2.70000 contrib=0.27000\n",
      "  26. N= 30 side=2.82500 contrib=0.26602\n",
      "  27. N= 25 side=2.57500 contrib=0.26523\n",
      "  28. N= 36 side=3.07500 contrib=0.26266\n",
      "  29. N= 33 side=2.94085 contrib=0.26208\n",
      "  30. N= 23 side=2.45000 contrib=0.26098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ace0f3c7ddc41b8873a95e3eb5ab6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refining:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ N=  1 improved 0.81317 -> 0.73186 (-10.00%)\n",
      "  ✓ N=  2 improved 0.94950 -> 0.90685 (-4.49%)\n",
      "  ✓ N=  3 improved 1.14203 -> 1.08706 (-4.81%)\n",
      "  ✓ N=  3 improved 1.14203 -> 1.08706 (-4.81%)\n",
      "  ✓ N= 17 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 17 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 14 improved 2.20000 -> 2.13000 (-3.18%)\n",
      "  ✓ N= 14 improved 2.20000 -> 2.13000 (-3.18%)\n",
      "  ✓ N= 16 improved 2.32500 -> 2.25500 (-3.01%)\n",
      "  ✓ N= 16 improved 2.32500 -> 2.25500 (-3.01%)\n",
      "  ✓ N= 18 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 18 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 10 improved 1.82444 -> 1.63146 (-10.58%)\n",
      "  ✓ N= 10 improved 1.82444 -> 1.63146 (-10.58%)\n",
      "  ✓ N= 13 improved 2.07500 -> 2.00500 (-3.37%)\n",
      "  ✓ N= 13 improved 2.07500 -> 2.00500 (-3.37%)\n",
      "  ✓ N=  4 improved 1.15000 -> 1.00500 (-12.61%)\n",
      "  ✓ N=  4 improved 1.15000 -> 1.00500 (-12.61%)\n",
      "  ✓ N= 12 improved 1.96777 -> 1.88000 (-4.46%)\n",
      "  ✓ N= 12 improved 1.96777 -> 1.88000 (-4.46%)\n",
      "  ✓ N= 15 improved 2.20000 -> 2.13000 (-3.18%)\n",
      "  ✓ N= 15 improved 2.20000 -> 2.13000 (-3.18%)\n",
      "  ✓ N=  9 improved 1.70000 -> 1.63000 (-4.12%)\n",
      "  ✓ N=  9 improved 1.70000 -> 1.63000 (-4.12%)\n",
      "  ✓ N= 19 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 19 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N=  8 improved 1.57500 -> 1.50500 (-4.44%)\n",
      "  ✓ N=  8 improved 1.57500 -> 1.50500 (-4.44%)\n",
      "  ✓ N= 11 improved 1.84277 -> 1.75500 (-4.76%)\n",
      "  ✓ N= 11 improved 1.84277 -> 1.75500 (-4.76%)\n",
      "  ✓ N=  7 improved 1.45000 -> 1.38000 (-4.83%)\n",
      "  ✓ N=  7 improved 1.45000 -> 1.38000 (-4.83%)\n",
      "  ✓ N= 20 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 20 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N=  6 improved 1.32500 -> 1.25500 (-5.28%)\n",
      "  ✓ N=  6 improved 1.32500 -> 1.25500 (-5.28%)\n",
      "  ✓ N=  5 improved 1.20000 -> 1.13000 (-5.83%)\n",
      "  ✓ N=  5 improved 1.20000 -> 1.13000 (-5.83%)\n",
      "  ✓ N= 21 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 21 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 22 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 22 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "  ✓ N= 28 improved 2.75742 -> 2.63847 (-4.31%)\n",
      "  ✓ N= 28 improved 2.75742 -> 2.63847 (-4.31%)\n",
      "  ✓ N= 29 improved 2.80502 -> 2.69273 (-4.00%)\n",
      "  ✓ N= 29 improved 2.80502 -> 2.69273 (-4.00%)\n",
      "  ✓ N= 27 improved 2.70000 -> 2.63000 (-2.59%)\n",
      "  ✓ N= 27 improved 2.70000 -> 2.63000 (-2.59%)\n",
      "  ✓ N= 30 improved 2.82500 -> 2.75500 (-2.48%)\n",
      "  ✓ N= 30 improved 2.82500 -> 2.75500 (-2.48%)\n",
      "  ✓ N= 25 improved 2.57500 -> 2.50500 (-2.72%)\n",
      "  ✓ N= 25 improved 2.57500 -> 2.50500 (-2.72%)\n",
      "  ✓ N= 36 improved 3.07500 -> 3.00500 (-2.28%)\n",
      "  ✓ N= 36 improved 3.07500 -> 3.00500 (-2.28%)\n",
      "  ✓ N= 33 improved 2.94085 -> 2.79412 (-4.99%)\n",
      "  ✓ N= 33 improved 2.94085 -> 2.79412 (-4.99%)\n",
      "  ✓ N= 23 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "Refinement complete. Improved 30/30 targets.\n",
      "  ✓ N= 23 improved 2.45000 -> 2.38000 (-2.86%)\n",
      "Refinement complete. Improved 30/30 targets.\n",
      "Refined score=41.363312 (time 48.9s)\n",
      "Refined score=41.363312 (time 48.9s)\n",
      "Merge stats:\n",
      "  Refined_Reverse wins=200/200 (100.0%)\n",
      "Merge stats:\n",
      "  Refined_Reverse wins=200/200 (100.0%)\n",
      "Merged total score: 41.363312 over 200 Ns\n",
      "Merged total score: 41.363312 over 200 Ns\n",
      "Final merged score=41.363312\n",
      "Saved submission_ensemble.csv\n",
      "Saved submission.csv\n",
      "Pipeline time: 56.3s\n",
      "Final merged score=41.363312\n",
      "Saved submission_ensemble.csv\n",
      "Saved submission.csv\n",
      "Pipeline time: 56.3s\n"
     ]
    }
   ],
   "source": [
    "# ========== MASTER WORKFLOW (Refactored & Robust) ==========\n",
    "import time\n",
    "WORKFLOW_CONFIG = {\n",
    "    'run_forward_chain': False,\n",
    "    'run_worst_n_refine': True,\n",
    "    'worst_n_count': 30,\n",
    "    'worst_n_seeds': 20,\n",
    "    'worst_n_iterations': 80000,\n",
    "    'forward_seeds': 3,\n",
    "    'forward_iterations': 25000,\n",
    "}\n",
    "\n",
    "start_global = time.time()\n",
    "print(f\"{'='*70}\\nSANTA 2025 OPTIMIZATION PIPELINE\\n{'='*70}\")\n",
    "\n",
    "reverse_solutions = all_solutions.copy() if 'all_solutions' in locals() else {}\n",
    "if reverse_solutions:\n",
    "    rev_score = sum((get_bounds(reverse_solutions[n])**2)/n for n in reverse_solutions)\n",
    "    print(f\"Loaded {len(reverse_solutions)} reverse solutions. Score={rev_score:.6f}\")\n",
    "else:\n",
    "    print(\"No reverse solutions found; run base search first.\")\n",
    "\n",
    "forward_solutions = {}\n",
    "if WORKFLOW_CONFIG['run_forward_chain']:\n",
    "    t0 = time.time()\n",
    "    forward_solutions = forward_chain_search(\n",
    "        max_n=200,\n",
    "        seeds_per_n=WORKFLOW_CONFIG['forward_seeds'],\n",
    "        iterations=WORKFLOW_CONFIG['forward_iterations']\n",
    "    )\n",
    "    fwd_score = sum((get_bounds(forward_solutions[n])**2)/n for n in forward_solutions)\n",
    "    print(f\"Forward chain score={fwd_score:.6f} (time {time.time()-t0:.1f}s)\")\n",
    "else:\n",
    "    print(\"Forward chain skipped.\")\n",
    "\n",
    "refined_solutions = reverse_solutions\n",
    "if WORKFLOW_CONFIG['run_worst_n_refine'] and reverse_solutions:\n",
    "    t0 = time.time()\n",
    "    refined_solutions = refine_worst_n(\n",
    "        reverse_solutions,\n",
    "        top_k=WORKFLOW_CONFIG['worst_n_count'],\n",
    "        seeds=WORKFLOW_CONFIG['worst_n_seeds'],\n",
    "        iterations=WORKFLOW_CONFIG['worst_n_iterations']\n",
    "    )\n",
    "    ref_score = sum((get_bounds(refined_solutions[n])**2)/n for n in refined_solutions)\n",
    "    print(f\"Refined score={ref_score:.6f} (time {time.time()-t0:.1f}s)\")\n",
    "else:\n",
    "    print(\"Worst-N refinement skipped.\")\n",
    "\n",
    "merge_inputs = [refined_solutions]\n",
    "merge_labels = [\"Refined_Reverse\"]\n",
    "if forward_solutions:\n",
    "    merge_inputs.append(forward_solutions)\n",
    "    merge_labels.append(\"Forward\")\n",
    "final_solutions = merge_solutions(*merge_inputs, labels=merge_labels)\n",
    "final_score = sum((get_bounds(final_solutions[n])**2)/n for n in final_solutions)\n",
    "print(f\"Final merged score={final_score:.6f}\")\n",
    "\n",
    "save_solution_to_csv(final_solutions, 'submission_ensemble.csv')\n",
    "save_solution_to_csv(final_solutions, 'submission.csv')\n",
    "all_solutions = final_solutions\n",
    "print(f\"Pipeline time: {time.time()-start_global:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb4f67",
   "metadata": {},
   "source": [
    "## Quick Test: Verify Growing Trees Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d3785a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Growing Trees optimization engine...\n",
      "--------------------------------------------------\n",
      "✓ Module loaded successfully\n",
      "✓ Test case created: 5 trees\n",
      "✓ Initial bounding box side: 3.150000\n",
      "\n",
      "Running sa_numba_growing (10k iterations)...\n",
      "✓ Optimization complete!\n",
      "  Initial side: 3.150000\n",
      "  Final side:   3.035000\n",
      "  Improvement:  3.65%\n",
      "\n",
      "✅ SUCCESS: Growing Trees engine is working correctly!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the new Growing Trees engine\n",
    "print(\"Testing Growing Trees optimization engine...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # Reload the module to get latest changes\n",
    "    import importlib\n",
    "    import optimization_utils\n",
    "    importlib.reload(optimization_utils)\n",
    "    from optimization_utils import sa_numba_growing\n",
    "    \n",
    "    print(\"✓ Module loaded successfully\")\n",
    "    \n",
    "    # Create a simple test case with 5 trees\n",
    "    test_trees = [\n",
    "        ChristmasTree(0, 0, 0),\n",
    "        ChristmasTree(1, 0, 45),\n",
    "        ChristmasTree(0, 1, 90),\n",
    "        ChristmasTree(-1, 0, 135),\n",
    "        ChristmasTree(0, -1, 180)\n",
    "    ]\n",
    "    \n",
    "    n = len(test_trees)\n",
    "    xs = np.array([t.center_x for t in test_trees], dtype=np.float64)\n",
    "    ys = np.array([t.center_y for t in test_trees], dtype=np.float64)\n",
    "    angs = np.array([t.angle for t in test_trees], dtype=np.float64)\n",
    "    \n",
    "    print(f\"✓ Test case created: {n} trees\")\n",
    "    \n",
    "    # Get initial bounding box\n",
    "    from optimization_utils import get_poly, get_bbox, calc_side_cached\n",
    "    cached_bboxes = np.zeros((n, 4), dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        px, py = get_poly(xs[i], ys[i], angs[i], 1.0)\n",
    "        cached_bboxes[i] = get_bbox(px, py)\n",
    "    \n",
    "    initial_side = calc_side_cached(cached_bboxes, n)\n",
    "    print(f\"✓ Initial bounding box side: {initial_side:.6f}\")\n",
    "    \n",
    "    # Run optimization with Growing Trees\n",
    "    print(\"\\nRunning sa_numba_growing (10k iterations)...\")\n",
    "    bxs, bys, bangs, best_side = sa_numba_growing(\n",
    "        xs, ys, angs, n,\n",
    "        iterations=10000,\n",
    "        T0=1.0,\n",
    "        Tmin=0.001,\n",
    "        move_scale=0.5,\n",
    "        rot_scale=30.0,\n",
    "        seed=42,\n",
    "        compression=0.05\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Optimization complete!\")\n",
    "    print(f\"  Initial side: {initial_side:.6f}\")\n",
    "    print(f\"  Final side:   {best_side:.6f}\")\n",
    "    \n",
    "    improvement = ((initial_side - best_side) / initial_side) * 100\n",
    "    print(f\"  Improvement:  {improvement:.2f}%\")\n",
    "    \n",
    "    if best_side < initial_side:\n",
    "        print(\"\\n✅ SUCCESS: Growing Trees engine is working correctly!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  WARNING: No improvement, but engine executed without errors\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4958dcd5",
   "metadata": {},
   "source": [
    "## Performance Benchmark\n",
    "Benchmark `sa_numba_growing` across varying N and iteration counts to estimate throughput (trees*iterations per second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fb9a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statistics import mean\n",
    "\n",
    "def benchmark_growing_trees(sample_ns=(5, 20, 50, 100), iterations=5000, repeats=3):\n",
    "    print(f\"Benchmark: iterations={iterations}, repeats={repeats}\")\n",
    "    rows = []\n",
    "    for n in sample_ns:\n",
    "        # Random initial layout\n",
    "        rng = np.random.default_rng(n*17 + 42)\n",
    "        xs = rng.uniform(-2, 2, size=n)\n",
    "        ys = rng.uniform(-2, 2, size=n)\n",
    "        angs = rng.uniform(0, 360, size=n)\n",
    "        params = get_sa_params(n)\n",
    "        T0 = params['initial_temp']; Tmin = params['min_temp']\n",
    "        move_scale = params['move_scale']; rot_scale = params['rot_scale']\n",
    "        compression = params.get('compression', 0.05)\n",
    "\n",
    "        times = []\n",
    "        for r in range(repeats):\n",
    "            t0 = time.time()\n",
    "            sa_numba_growing(xs, ys, angs, n, iterations, T0, Tmin, move_scale, rot_scale, seed=r + n*100, compression=compression)\n",
    "            times.append(time.time() - t0)\n",
    "        avg = mean(times)\n",
    "        it_per_sec = iterations / avg\n",
    "        tree_ops = (iterations * n) / avg\n",
    "        rows.append((n, avg, it_per_sec, tree_ops))\n",
    "        print(f\"N={n:3d} avg_time={avg:.3f}s  iter/s={it_per_sec:7.0f}  tree-iter/s={tree_ops:8.0f}\")\n",
    "    return rows\n",
    "\n",
    "# Run benchmark (uncomment to execute):\n",
    "# benchmark_growing_trees(sample_ns=(10, 40, 80, 160), iterations=8000, repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5689c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification: Check actual score of submission.csv\n",
    "print(\"Verifying submission.csv score...\")\n",
    "try:\n",
    "    verify_df = pd.read_csv('submission.csv')\n",
    "    \n",
    "    def parse_s(val):\n",
    "        return float(str(val).replace('s', ''))\n",
    "    \n",
    "    verify_df['x'] = verify_df['x'].apply(parse_s)\n",
    "    verify_df['y'] = verify_df['y'].apply(parse_s)\n",
    "    verify_df['deg'] = verify_df['deg'].apply(parse_s)\n",
    "    \n",
    "    verify_score = 0\n",
    "    verify_configs = {}\n",
    "    \n",
    "    for _, row in verify_df.iterrows():\n",
    "        n_str = row['id'].split('_')[0]\n",
    "        n = int(n_str)\n",
    "        if n not in verify_configs:\n",
    "            verify_configs[n] = []\n",
    "        verify_configs[n].append(ChristmasTree(row['x'], row['y'], row['deg']))\n",
    "    \n",
    "    for n, trees in verify_configs.items():\n",
    "        if len(trees) != n:\n",
    "            print(f\"⚠️ WARNING: N={n} has {len(trees)} trees (expected {n})\")\n",
    "            continue\n",
    "        side = get_bounds(trees)\n",
    "        verify_score += (side ** 2) / n\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Verified Score: {verify_score:.10f}\")\n",
    "    print(f\"Configurations: {len(verify_configs)}/200\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"submission.csv not found. Run the main processing cell first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8122a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20100 submission rows...\n",
      "Calculating scores for 200 configurations...\n",
      "Calculating scores for 200 configurations...\n",
      "\n",
      "============================================================\n",
      "Final Score: 44.7905481598\n",
      "Configurations found: 200/200\n",
      "============================================================\n",
      "\n",
      "Original Score: 74.6611804330\n",
      "✓ SUCCESS: Score improved by 29.8706322732!\n",
      "Saved backup: Data/submission_score44.79_improved29.87_20251124_155633.csv\n",
      "Overwrote test.csv\n",
      "Submitting to Kaggle...\n",
      "\n",
      "============================================================\n",
      "Final Score: 44.7905481598\n",
      "Configurations found: 200/200\n",
      "============================================================\n",
      "\n",
      "Original Score: 74.6611804330\n",
      "✓ SUCCESS: Score improved by 29.8706322732!\n",
      "Saved backup: Data/submission_score44.79_improved29.87_20251124_155633.csv\n",
      "Overwrote test.csv\n",
      "Submitting to Kaggle...\n",
      "100%|██████████████████████████████████████| 0.98M/0.98M [00:00<00:00, 2.98MB/s]\n",
      "100%|██████████████████████████████████████| 0.98M/0.98M [00:00<00:00, 2.98MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "# Calculate final score from submission_rows (more reliable than all_solutions dict)\n",
    "# The all_solutions dict may be incomplete if processing had errors\n",
    "final_score = 0\n",
    "score_by_n = {}\n",
    "\n",
    "print(f\"Processing {len(submission_rows)} submission rows...\")\n",
    "\n",
    "for row in submission_rows:\n",
    "    n_str = row[0].split('_')[0]\n",
    "    n = int(n_str)\n",
    "    if n not in score_by_n:\n",
    "        score_by_n[n] = []\n",
    "    x = float(row[1].replace('s', ''))\n",
    "    y = float(row[2].replace('s', ''))\n",
    "    deg = float(row[3].replace('s', ''))\n",
    "    score_by_n[n].append(ChristmasTree(x, y, deg))\n",
    "\n",
    "print(f\"Calculating scores for {len(score_by_n)} configurations...\")\n",
    "\n",
    "for n in sorted(score_by_n.keys()):\n",
    "    trees = score_by_n[n]\n",
    "    if len(trees) != n:\n",
    "        print(f\"WARNING: N={n} has {len(trees)} trees, expected {n}\")\n",
    "        continue\n",
    "    side = get_bounds(trees)\n",
    "    score_n = (side ** 2) / n\n",
    "    final_score += score_n\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Score: {final_score:.10f}\")\n",
    "print(f\"Configurations found: {len(score_by_n)}/200\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Compare with original\n",
    "if 'total_test_score' in globals():\n",
    "    print(f\"Original Score: {total_test_score:.10f}\")\n",
    "    if final_score < total_test_score:\n",
    "        diff = total_test_score - final_score\n",
    "        print(f\"✓ SUCCESS: Score improved by {diff:.10f}!\")\n",
    "        \n",
    "        # 1. Save copy with detailed name\n",
    "        os.makedirs('Data', exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        detailed_name = f\"Data/submission_score{final_score:.2f}_improved{diff:.2f}_{timestamp}.csv\"\n",
    "        df_sub.to_csv(detailed_name, index=False)\n",
    "        print(f\"Saved backup: {detailed_name}\")\n",
    "        \n",
    "        # 2. Overwrite test.csv\n",
    "        df_sub.to_csv('test.csv', index=False)\n",
    "        print(\"Overwrote test.csv\")\n",
    "        \n",
    "        # 3. Submit to Kaggle\n",
    "        message = f\"Improved score {final_score:.6f} (was {total_test_score:.6f})\"\n",
    "        print(\"Submitting to Kaggle...\")\n",
    "        !kaggle competitions submit -c santa-2025 -f submission.csv -m \"{message}\"\n",
    "\n",
    "        # 4. Git Commit and Push\n",
    "        print(\"Committing and pushing to Git...\")\n",
    "        !git add .\n",
    "        !git commit -m \"{message}\"\n",
    "        !git push\n",
    "        \n",
    "    else:\n",
    "        improvement = final_score - total_test_score\n",
    "        print(f\"⚠ No improvement (Score change: {improvement:+.10f})\")\n",
    "        print(f\"  Current: {final_score:.10f}\")\n",
    "        print(f\"  Original: {total_test_score:.10f}\")\n",
    "else:\n",
    "    print(\"⚠ Original score not found. Run the cell loading test.csv baseline first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
